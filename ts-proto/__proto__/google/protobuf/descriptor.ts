// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v1.178.0
//   protoc               unknown
// source: google/protobuf/descriptor.proto

    /* eslint-disable */
import _m0 from 'protobufjs/minimal.js';
import Long from 'long';

export const protobufPackage = 'google.protobuf';

/** The full set of known editions. */
export const Edition = {
/** UNKNOWN - A placeholder for an unknown edition value. */
UNKNOWN : "EDITION_UNKNOWN",
/**
 * LEGACY - A placeholder edition for specifying default behaviors *before* a feature
 * was first introduced.  This is effectively an "infinite past".
 */
LEGACY : "EDITION_LEGACY",
/**
 * PROTO2 - Legacy syntax "editions".  These pre-date editions, but behave much like
 * distinct editions.  These can't be used to specify the edition of proto
 * files, but feature definitions must supply proto2/proto3 defaults for
 * backwards compatibility.
 */
PROTO2 : "EDITION_PROTO2",
PROTO3 : "EDITION_PROTO3",
/**
 * 2023 - Editions that have been released.  The specific values are arbitrary and
 * should not be depended on, but they will always be time-ordered for easy
 * comparison.
 */
2023 : "EDITION_2023",
2024 : "EDITION_2024",
/**
 * 1_TEST_ONLY - Placeholder editions for testing feature resolution.  These should not be
 * used or relyed on outside of tests.
 */
1_TEST_ONLY : "EDITION_1_TEST_ONLY",
2_TEST_ONLY : "EDITION_2_TEST_ONLY",
99997_TEST_ONLY : "EDITION_99997_TEST_ONLY",
99998_TEST_ONLY : "EDITION_99998_TEST_ONLY",
99999_TEST_ONLY : "EDITION_99999_TEST_ONLY",
/**
 * MAX - Placeholder for specifying unbounded edition support.  This should only
 * ever be used by plugins that can expect to never require any changes to
 * support a new edition.
 */
MAX : "EDITION_MAX",
} as const

export type Edition = typeof Edition[keyof typeof Edition]

export namespace Edition {
export type UNKNOWN = typeof Edition.UNKNOWN;
export type LEGACY = typeof Edition.LEGACY;
export type PROTO2 = typeof Edition.PROTO2;
export type PROTO3 = typeof Edition.PROTO3;
export type 2023 = typeof Edition.2023;
export type 2024 = typeof Edition.2024;
export type 1_TEST_ONLY = typeof Edition.1_TEST_ONLY;
export type 2_TEST_ONLY = typeof Edition.2_TEST_ONLY;
export type 99997_TEST_ONLY = typeof Edition.99997_TEST_ONLY;
export type 99998_TEST_ONLY = typeof Edition.99998_TEST_ONLY;
export type 99999_TEST_ONLY = typeof Edition.99999_TEST_ONLY;
export type MAX = typeof Edition.MAX;
}

export function editionFromJSON(object: any): Edition {
switch (object) {
case 0:
      case "EDITION_UNKNOWN":
        return Edition.UNKNOWN;
case 900:
      case "EDITION_LEGACY":
        return Edition.LEGACY;
case 998:
      case "EDITION_PROTO2":
        return Edition.PROTO2;
case 999:
      case "EDITION_PROTO3":
        return Edition.PROTO3;
case 1000:
      case "EDITION_2023":
        return Edition.2023;
case 1001:
      case "EDITION_2024":
        return Edition.2024;
case 1:
      case "EDITION_1_TEST_ONLY":
        return Edition.1_TEST_ONLY;
case 2:
      case "EDITION_2_TEST_ONLY":
        return Edition.2_TEST_ONLY;
case 99997:
      case "EDITION_99997_TEST_ONLY":
        return Edition.99997_TEST_ONLY;
case 99998:
      case "EDITION_99998_TEST_ONLY":
        return Edition.99998_TEST_ONLY;
case 99999:
      case "EDITION_99999_TEST_ONLY":
        return Edition.99999_TEST_ONLY;
case 2147483647:
      case "EDITION_MAX":
        return Edition.MAX;
default:
          return Edition.UNKNOWN;
}
}

export function editionToJSON(object: Edition): string {
switch (object) {
case Edition.UNKNOWN: return "EDITION_UNKNOWN";
case Edition.LEGACY: return "EDITION_LEGACY";
case Edition.PROTO2: return "EDITION_PROTO2";
case Edition.PROTO3: return "EDITION_PROTO3";
case Edition.2023: return "EDITION_2023";
case Edition.2024: return "EDITION_2024";
case Edition.1_TEST_ONLY: return "EDITION_1_TEST_ONLY";
case Edition.2_TEST_ONLY: return "EDITION_2_TEST_ONLY";
case Edition.99997_TEST_ONLY: return "EDITION_99997_TEST_ONLY";
case Edition.99998_TEST_ONLY: return "EDITION_99998_TEST_ONLY";
case Edition.99999_TEST_ONLY: return "EDITION_99999_TEST_ONLY";
case Edition.MAX: return "EDITION_MAX";
default:
        return "UNKNOWN";
}
}

export function editionToNumber(object: Edition): number {
switch (object) {
case Edition.UNKNOWN: return 0;
case Edition.LEGACY: return 900;
case Edition.PROTO2: return 998;
case Edition.PROTO3: return 999;
case Edition.2023: return 1000;
case Edition.2024: return 1001;
case Edition.1_TEST_ONLY: return 1;
case Edition.2_TEST_ONLY: return 2;
case Edition.99997_TEST_ONLY: return 99997;
case Edition.99998_TEST_ONLY: return 99998;
case Edition.99999_TEST_ONLY: return 99999;
case Edition.MAX: return 2147483647;
default:
          return 0;
}
}

/**
 * The protocol compiler can output a FileDescriptorSet containing the .proto
 * files it parses.
 */
export interface FileDescriptorSet {
file: FileDescriptorProto[],
}

/** Describes a complete .proto file. */
export interface FileDescriptorProto {
/** file name, relative to root of source tree */
name?: string | null ,
/** e.g. "foo", "foo.bar", etc. */
package?: string | null ,
/** Names of files imported by this file. */
dependency: string[],
/** Indexes of the public imported files in the dependency list above. */
public_dependency: number[],
/**
 * Indexes of the weak imported files in the dependency list.
 * For Google-internal migration only. Do not use.
 */
weak_dependency: number[],
/** All top-level definitions in this file. */
message_type: DescriptorProto[],
enum_type: EnumDescriptorProto[],
service: ServiceDescriptorProto[],
extension: FieldDescriptorProto[],
options?: FileOptions | null ,
/**
 * This field contains optional information about the original source code.
 * You may safely remove this entire field without harming runtime
 * functionality of the descriptors -- the information is needed only by
 * development tools.
 */
source_code_info?: SourceCodeInfo | null ,
/**
 * The syntax of the proto file.
 * The supported values are "proto2", "proto3", and "editions".
 * 
 * If `edition` is present, this value must be "editions".
 */
syntax?: string | null ,
/** The edition of the proto file. */
edition?: Edition | null ,
}

/** Describes a message type. */
export interface DescriptorProto {
name?: string | null ,
field: FieldDescriptorProto[],
extension: FieldDescriptorProto[],
nested_type: DescriptorProto[],
enum_type: EnumDescriptorProto[],
extension_range: DescriptorProto_ExtensionRange[],
oneof_decl: OneofDescriptorProto[],
options?: MessageOptions | null ,
reserved_range: DescriptorProto_ReservedRange[],
/**
 * Reserved field names, which may not be used by fields in the same message.
 * A given name may only be reserved once.
 */
reserved_name: string[],
}

export interface DescriptorProto_ExtensionRange {
/** Inclusive. */
start?: number | null ,
/** Exclusive. */
end?: number | null ,
options?: ExtensionRangeOptions | null ,
}

/**
 * Range of reserved tag numbers. Reserved tag numbers may not be used by
 * fields or extension ranges in the same message. Reserved ranges may
 * not overlap.
 */
export interface DescriptorProto_ReservedRange {
/** Inclusive. */
start?: number | null ,
/** Exclusive. */
end?: number | null ,
}

export interface ExtensionRangeOptions {
/** The parser stores options it doesn't recognize here. See above. */
uninterpreted_option: UninterpretedOption[],
/**
 * For external users: DO NOT USE. We are in the process of open sourcing
 * extension declaration and executing internal cleanups before it can be
 * used externally.
 */
declaration: ExtensionRangeOptions_Declaration[],
/** Any features defined in the specific edition. */
features?: FeatureSet | null ,
/**
 * The verification state of the range.
 * TODO: flip the default to DECLARATION once all empty ranges
 * are marked as UNVERIFIED.
 */
verification?: ExtensionRangeOptions_VerificationState | null ,
}

/** The verification state of the extension range. */
export const ExtensionRangeOptions_VerificationState = {
/** DECLARATION - All the extensions of the range must be declared. */
DECLARATION : "DECLARATION",
UNVERIFIED : "UNVERIFIED",
} as const

export type ExtensionRangeOptions_VerificationState = typeof ExtensionRangeOptions_VerificationState[keyof typeof ExtensionRangeOptions_VerificationState]

export namespace ExtensionRangeOptions_VerificationState {
export type DECLARATION = typeof ExtensionRangeOptions_VerificationState.DECLARATION;
export type UNVERIFIED = typeof ExtensionRangeOptions_VerificationState.UNVERIFIED;
}

export function extensionRangeOptions_VerificationStateFromJSON(object: any): ExtensionRangeOptions_VerificationState {
switch (object) {
case 0:
      case "DECLARATION":
        return ExtensionRangeOptions_VerificationState.DECLARATION;
case 1:
      case "UNVERIFIED":
        return ExtensionRangeOptions_VerificationState.UNVERIFIED;
default:
          return ExtensionRangeOptions_VerificationState.DECLARATION;
}
}

export function extensionRangeOptions_VerificationStateToJSON(object: ExtensionRangeOptions_VerificationState): string {
switch (object) {
case ExtensionRangeOptions_VerificationState.DECLARATION: return "DECLARATION";
case ExtensionRangeOptions_VerificationState.UNVERIFIED: return "UNVERIFIED";
default:
        return "DECLARATION";
}
}

export function extensionRangeOptions_VerificationStateToNumber(object: ExtensionRangeOptions_VerificationState): number {
switch (object) {
case ExtensionRangeOptions_VerificationState.DECLARATION: return 0;
case ExtensionRangeOptions_VerificationState.UNVERIFIED: return 1;
default:
          return 0;
}
}

export interface ExtensionRangeOptions_Declaration {
/** The extension number declared within the extension range. */
number?: number | null ,
/**
 * The fully-qualified name of the extension field. There must be a leading
 * dot in front of the full name.
 */
full_name?: string | null ,
/**
 * The fully-qualified type name of the extension field. Unlike
 * Metadata.type, Declaration.type must have a leading dot for messages
 * and enums.
 */
type?: string | null ,
/**
 * If true, indicates that the number is reserved in the extension range,
 * and any extension field with the number will fail to compile. Set this
 * when a declared extension field is deleted.
 */
reserved?: boolean | null ,
/**
 * If true, indicates that the extension must be defined as repeated.
 * Otherwise the extension must be defined as optional.
 */
repeated?: boolean | null ,
}

/** Describes a field within a message. */
export interface FieldDescriptorProto {
name?: string | null ,
number?: number | null ,
label?: FieldDescriptorProto_Label | null ,
/**
 * If type_name is set, this need not be set.  If both this and type_name
 * are set, this must be one of TYPE_ENUM, TYPE_MESSAGE or TYPE_GROUP.
 */
type?: FieldDescriptorProto_Type | null ,
/**
 * For message and enum types, this is the name of the type.  If the name
 * starts with a '.', it is fully-qualified.  Otherwise, C++-like scoping
 * rules are used to find the type (i.e. first the nested types within this
 * message are searched, then within the parent, on up to the root
 * namespace).
 */
type_name?: string | null ,
/**
 * For extensions, this is the name of the type being extended.  It is
 * resolved in the same manner as type_name.
 */
extendee?: string | null ,
/**
 * For numeric types, contains the original text representation of the value.
 * For booleans, "true" or "false".
 * For strings, contains the default text contents (not escaped in any way).
 * For bytes, contains the C escaped value.  All bytes >= 128 are escaped.
 */
default_value?: string | null ,
/**
 * If set, gives the index of a oneof in the containing type's oneof_decl
 * list.  This field is a member of that oneof.
 */
oneof_index?: number | null ,
/**
 * JSON name of this field. The value is set by protocol compiler. If the
 * user has set a "json_name" option on this field, that option's value
 * will be used. Otherwise, it's deduced from the field's name by converting
 * it to camelCase.
 */
json_name?: string | null ,
options?: FieldOptions | null ,
/**
 * If true, this is a proto3 "optional". When a proto3 field is optional, it
 * tracks presence regardless of field type.
 * 
 * When proto3_optional is true, this field must belong to a oneof to signal
 * to old proto3 clients that presence is tracked for this field. This oneof
 * is known as a "synthetic" oneof, and this field must be its sole member
 * (each proto3 optional field gets its own synthetic oneof). Synthetic oneofs
 * exist in the descriptor only, and do not generate any API. Synthetic oneofs
 * must be ordered after all "real" oneofs.
 * 
 * For message fields, proto3_optional doesn't create any semantic change,
 * since non-repeated message fields always track presence. However it still
 * indicates the semantic detail of whether the user wrote "optional" or not.
 * This can be useful for round-tripping the .proto file. For consistency we
 * give message fields a synthetic oneof also, even though it is not required
 * to track presence. This is especially important because the parser can't
 * tell if a field is a message or an enum, so it must always create a
 * synthetic oneof.
 * 
 * Proto2 optional fields do not set this flag, because they already indicate
 * optional with `LABEL_OPTIONAL`.
 */
proto3_optional?: boolean | null ,
}

export const FieldDescriptorProto_Type = {
/**
 * DOUBLE - 0 is reserved for errors.
 * Order is weird for historical reasons.
 */
DOUBLE : "TYPE_DOUBLE",
FLOAT : "TYPE_FLOAT",
/**
 * INT64 - Not ZigZag encoded.  Negative numbers take 10 bytes.  Use TYPE_SINT64 if
 * negative values are likely.
 */
INT64 : "TYPE_INT64",
UINT64 : "TYPE_UINT64",
/**
 * INT32 - Not ZigZag encoded.  Negative numbers take 10 bytes.  Use TYPE_SINT32 if
 * negative values are likely.
 */
INT32 : "TYPE_INT32",
FIXED64 : "TYPE_FIXED64",
FIXED32 : "TYPE_FIXED32",
BOOL : "TYPE_BOOL",
STRING : "TYPE_STRING",
/**
 * GROUP - Tag-delimited aggregate.
 * Group type is deprecated and not supported after google.protobuf. However, Proto3
 * implementations should still be able to parse the group wire format and
 * treat group fields as unknown fields.  In Editions, the group wire format
 * can be enabled via the `message_encoding` feature.
 */
GROUP : "TYPE_GROUP",
/** MESSAGE - Length-delimited aggregate. */
MESSAGE : "TYPE_MESSAGE",
/** BYTES - New in version 2. */
BYTES : "TYPE_BYTES",
UINT32 : "TYPE_UINT32",
ENUM : "TYPE_ENUM",
SFIXED32 : "TYPE_SFIXED32",
SFIXED64 : "TYPE_SFIXED64",
/** SINT32 - Uses ZigZag encoding. */
SINT32 : "TYPE_SINT32",
/** SINT64 - Uses ZigZag encoding. */
SINT64 : "TYPE_SINT64",
UNRECOGNIZED : "UNRECOGNIZED",
} as const

export type FieldDescriptorProto_Type = typeof FieldDescriptorProto_Type[keyof typeof FieldDescriptorProto_Type]

export namespace FieldDescriptorProto_Type {
export type DOUBLE = typeof FieldDescriptorProto_Type.DOUBLE;
export type FLOAT = typeof FieldDescriptorProto_Type.FLOAT;
export type INT64 = typeof FieldDescriptorProto_Type.INT64;
export type UINT64 = typeof FieldDescriptorProto_Type.UINT64;
export type INT32 = typeof FieldDescriptorProto_Type.INT32;
export type FIXED64 = typeof FieldDescriptorProto_Type.FIXED64;
export type FIXED32 = typeof FieldDescriptorProto_Type.FIXED32;
export type BOOL = typeof FieldDescriptorProto_Type.BOOL;
export type STRING = typeof FieldDescriptorProto_Type.STRING;
export type GROUP = typeof FieldDescriptorProto_Type.GROUP;
export type MESSAGE = typeof FieldDescriptorProto_Type.MESSAGE;
export type BYTES = typeof FieldDescriptorProto_Type.BYTES;
export type UINT32 = typeof FieldDescriptorProto_Type.UINT32;
export type ENUM = typeof FieldDescriptorProto_Type.ENUM;
export type SFIXED32 = typeof FieldDescriptorProto_Type.SFIXED32;
export type SFIXED64 = typeof FieldDescriptorProto_Type.SFIXED64;
export type SINT32 = typeof FieldDescriptorProto_Type.SINT32;
export type SINT64 = typeof FieldDescriptorProto_Type.SINT64;
export type UNRECOGNIZED = typeof FieldDescriptorProto_Type.UNRECOGNIZED;
}

export function fieldDescriptorProto_TypeFromJSON(object: any): FieldDescriptorProto_Type {
switch (object) {
case 1:
      case "TYPE_DOUBLE":
        return FieldDescriptorProto_Type.DOUBLE;
case 2:
      case "TYPE_FLOAT":
        return FieldDescriptorProto_Type.FLOAT;
case 3:
      case "TYPE_INT64":
        return FieldDescriptorProto_Type.INT64;
case 4:
      case "TYPE_UINT64":
        return FieldDescriptorProto_Type.UINT64;
case 5:
      case "TYPE_INT32":
        return FieldDescriptorProto_Type.INT32;
case 6:
      case "TYPE_FIXED64":
        return FieldDescriptorProto_Type.FIXED64;
case 7:
      case "TYPE_FIXED32":
        return FieldDescriptorProto_Type.FIXED32;
case 8:
      case "TYPE_BOOL":
        return FieldDescriptorProto_Type.BOOL;
case 9:
      case "TYPE_STRING":
        return FieldDescriptorProto_Type.STRING;
case 10:
      case "TYPE_GROUP":
        return FieldDescriptorProto_Type.GROUP;
case 11:
      case "TYPE_MESSAGE":
        return FieldDescriptorProto_Type.MESSAGE;
case 12:
      case "TYPE_BYTES":
        return FieldDescriptorProto_Type.BYTES;
case 13:
      case "TYPE_UINT32":
        return FieldDescriptorProto_Type.UINT32;
case 14:
      case "TYPE_ENUM":
        return FieldDescriptorProto_Type.ENUM;
case 15:
      case "TYPE_SFIXED32":
        return FieldDescriptorProto_Type.SFIXED32;
case 16:
      case "TYPE_SFIXED64":
        return FieldDescriptorProto_Type.SFIXED64;
case 17:
      case "TYPE_SINT32":
        return FieldDescriptorProto_Type.SINT32;
case 18:
      case "TYPE_SINT64":
        return FieldDescriptorProto_Type.SINT64;
case 0:
        case "UNRECOGNIZED":
        default:
          return FieldDescriptorProto_Type.UNRECOGNIZED;
}
}

export function fieldDescriptorProto_TypeToJSON(object: FieldDescriptorProto_Type): string {
switch (object) {
case FieldDescriptorProto_Type.DOUBLE: return "TYPE_DOUBLE";
case FieldDescriptorProto_Type.FLOAT: return "TYPE_FLOAT";
case FieldDescriptorProto_Type.INT64: return "TYPE_INT64";
case FieldDescriptorProto_Type.UINT64: return "TYPE_UINT64";
case FieldDescriptorProto_Type.INT32: return "TYPE_INT32";
case FieldDescriptorProto_Type.FIXED64: return "TYPE_FIXED64";
case FieldDescriptorProto_Type.FIXED32: return "TYPE_FIXED32";
case FieldDescriptorProto_Type.BOOL: return "TYPE_BOOL";
case FieldDescriptorProto_Type.STRING: return "TYPE_STRING";
case FieldDescriptorProto_Type.GROUP: return "TYPE_GROUP";
case FieldDescriptorProto_Type.MESSAGE: return "TYPE_MESSAGE";
case FieldDescriptorProto_Type.BYTES: return "TYPE_BYTES";
case FieldDescriptorProto_Type.UINT32: return "TYPE_UINT32";
case FieldDescriptorProto_Type.ENUM: return "TYPE_ENUM";
case FieldDescriptorProto_Type.SFIXED32: return "TYPE_SFIXED32";
case FieldDescriptorProto_Type.SFIXED64: return "TYPE_SFIXED64";
case FieldDescriptorProto_Type.SINT32: return "TYPE_SINT32";
case FieldDescriptorProto_Type.SINT64: return "TYPE_SINT64";
case FieldDescriptorProto_Type.UNRECOGNIZED:
default:
          return "UNRECOGNIZED";
}
}

export function fieldDescriptorProto_TypeToNumber(object: FieldDescriptorProto_Type): number {
switch (object) {
case FieldDescriptorProto_Type.DOUBLE: return 1;
case FieldDescriptorProto_Type.FLOAT: return 2;
case FieldDescriptorProto_Type.INT64: return 3;
case FieldDescriptorProto_Type.UINT64: return 4;
case FieldDescriptorProto_Type.INT32: return 5;
case FieldDescriptorProto_Type.FIXED64: return 6;
case FieldDescriptorProto_Type.FIXED32: return 7;
case FieldDescriptorProto_Type.BOOL: return 8;
case FieldDescriptorProto_Type.STRING: return 9;
case FieldDescriptorProto_Type.GROUP: return 10;
case FieldDescriptorProto_Type.MESSAGE: return 11;
case FieldDescriptorProto_Type.BYTES: return 12;
case FieldDescriptorProto_Type.UINT32: return 13;
case FieldDescriptorProto_Type.ENUM: return 14;
case FieldDescriptorProto_Type.SFIXED32: return 15;
case FieldDescriptorProto_Type.SFIXED64: return 16;
case FieldDescriptorProto_Type.SINT32: return 17;
case FieldDescriptorProto_Type.SINT64: return 18;
case FieldDescriptorProto_Type.UNRECOGNIZED:
        default:
          return 0;
}
}

export const FieldDescriptorProto_Label = {
/** OPTIONAL - 0 is reserved for errors */
OPTIONAL : "LABEL_OPTIONAL",
REPEATED : "LABEL_REPEATED",
/**
 * REQUIRED - The required label is only allowed in google.protobuf.  In proto3 and Editions
 * it's explicitly prohibited.  In Editions, the `field_presence` feature
 * can be used to get this behavior.
 */
REQUIRED : "LABEL_REQUIRED",
UNRECOGNIZED : "UNRECOGNIZED",
} as const

export type FieldDescriptorProto_Label = typeof FieldDescriptorProto_Label[keyof typeof FieldDescriptorProto_Label]

export namespace FieldDescriptorProto_Label {
export type OPTIONAL = typeof FieldDescriptorProto_Label.OPTIONAL;
export type REPEATED = typeof FieldDescriptorProto_Label.REPEATED;
export type REQUIRED = typeof FieldDescriptorProto_Label.REQUIRED;
export type UNRECOGNIZED = typeof FieldDescriptorProto_Label.UNRECOGNIZED;
}

export function fieldDescriptorProto_LabelFromJSON(object: any): FieldDescriptorProto_Label {
switch (object) {
case 1:
      case "LABEL_OPTIONAL":
        return FieldDescriptorProto_Label.OPTIONAL;
case 3:
      case "LABEL_REPEATED":
        return FieldDescriptorProto_Label.REPEATED;
case 2:
      case "LABEL_REQUIRED":
        return FieldDescriptorProto_Label.REQUIRED;
case 0:
        case "UNRECOGNIZED":
        default:
          return FieldDescriptorProto_Label.UNRECOGNIZED;
}
}

export function fieldDescriptorProto_LabelToJSON(object: FieldDescriptorProto_Label): string {
switch (object) {
case FieldDescriptorProto_Label.OPTIONAL: return "LABEL_OPTIONAL";
case FieldDescriptorProto_Label.REPEATED: return "LABEL_REPEATED";
case FieldDescriptorProto_Label.REQUIRED: return "LABEL_REQUIRED";
case FieldDescriptorProto_Label.UNRECOGNIZED:
default:
          return "UNRECOGNIZED";
}
}

export function fieldDescriptorProto_LabelToNumber(object: FieldDescriptorProto_Label): number {
switch (object) {
case FieldDescriptorProto_Label.OPTIONAL: return 1;
case FieldDescriptorProto_Label.REPEATED: return 3;
case FieldDescriptorProto_Label.REQUIRED: return 2;
case FieldDescriptorProto_Label.UNRECOGNIZED:
        default:
          return 0;
}
}

/** Describes a oneof. */
export interface OneofDescriptorProto {
name?: string | null ,
options?: OneofOptions | null ,
}

/** Describes an enum type. */
export interface EnumDescriptorProto {
name?: string | null ,
value: EnumValueDescriptorProto[],
options?: EnumOptions | null ,
/**
 * Range of reserved numeric values. Reserved numeric values may not be used
 * by enum values in the same enum declaration. Reserved ranges may not
 * overlap.
 */
reserved_range: EnumDescriptorProto_EnumReservedRange[],
/**
 * Reserved enum value names, which may not be reused. A given name may only
 * be reserved once.
 */
reserved_name: string[],
}

/**
 * Range of reserved numeric values. Reserved values may not be used by
 * entries in the same enum. Reserved ranges may not overlap.
 * 
 * Note that this is distinct from DescriptorProto.ReservedRange in that it
 * is inclusive such that it can appropriately represent the entire int32
 * domain.
 */
export interface EnumDescriptorProto_EnumReservedRange {
/** Inclusive. */
start?: number | null ,
/** Inclusive. */
end?: number | null ,
}

/** Describes a value within an enum. */
export interface EnumValueDescriptorProto {
name?: string | null ,
number?: number | null ,
options?: EnumValueOptions | null ,
}

/** Describes a service. */
export interface ServiceDescriptorProto {
name?: string | null ,
method: MethodDescriptorProto[],
options?: ServiceOptions | null ,
}

/** Describes a method of a service. */
export interface MethodDescriptorProto {
name?: string | null ,
/**
 * Input and output type names.  These are resolved in the same way as
 * FieldDescriptorProto.type_name, but must refer to a message type.
 */
input_type?: string | null ,
output_type?: string | null ,
options?: MethodOptions | null ,
/** Identifies if client streams multiple client messages */
client_streaming?: boolean | null ,
/** Identifies if server streams multiple server messages */
server_streaming?: boolean | null ,
}

export interface FileOptions {
/**
 * Sets the Java package where classes generated from this .proto will be
 * placed.  By default, the proto package is used, but this is often
 * inappropriate because proto packages do not normally start with backwards
 * domain names.
 */
java_package?: string | null ,
/**
 * Controls the name of the wrapper Java class generated for the .proto file.
 * That class will always contain the .proto file's getDescriptor() method as
 * well as any top-level extensions defined in the .proto file.
 * If java_multiple_files is disabled, then all the other classes from the
 * .proto file will be nested inside the single wrapper outer class.
 */
java_outer_classname?: string | null ,
/**
 * If enabled, then the Java code generator will generate a separate .java
 * file for each top-level message, enum, and service defined in the .proto
 * file.  Thus, these types will *not* be nested inside the wrapper class
 * named by java_outer_classname.  However, the wrapper class will still be
 * generated to contain the file's getDescriptor() method as well as any
 * top-level extensions defined in the file.
 */
java_multiple_files?: boolean | null ,
/**
 * This option does nothing.
 * 
 * @deprecated
 */
java_generate_equals_and_hash?: boolean | null ,
/**
 * A proto2 file can set this to true to opt in to UTF-8 checking for Java,
 * which will throw an exception if invalid UTF-8 is parsed from the wire or
 * assigned to a string field.
 * 
 * TODO: clarify exactly what kinds of field types this option
 * applies to, and update these docs accordingly.
 * 
 * Proto3 files already perform these checks. Setting the option explicitly to
 * false has no effect: it cannot be used to opt proto3 files out of UTF-8
 * checks.
 */
java_string_check_utf8?: boolean | null ,
optimize_for?: FileOptions_OptimizeMode | null ,
/**
 * Sets the Go package where structs generated from this .proto will be
 * placed. If omitted, the Go package will be derived from the following:
 *   - The basename of the package import path, if provided.
 *   - Otherwise, the package statement in the .proto file, if present.
 *   - Otherwise, the basename of the .proto file, without extension.
 */
go_package?: string | null ,
/**
 * Should generic services be generated in each language?  "Generic" services
 * are not specific to any particular RPC system.  They are generated by the
 * main code generators in each language (without additional plugins).
 * Generic services were the only kind of service generation supported by
 * early versions of google.protobuf.
 * 
 * Generic services are now considered deprecated in favor of using plugins
 * that generate code specific to your particular RPC system.  Therefore,
 * these default to false.  Old code which depends on generic services should
 * explicitly set them to true.
 */
cc_generic_services?: boolean | null ,
java_generic_services?: boolean | null ,
py_generic_services?: boolean | null ,
/**
 * Is this file deprecated?
 * Depending on the target platform, this can emit Deprecated annotations
 * for everything in the file, or it will be completely ignored; in the very
 * least, this is a formalization for deprecating files.
 */
deprecated?: boolean | null ,
/**
 * Enables the use of arenas for the proto messages in this file. This applies
 * only to generated classes for C++.
 */
cc_enable_arenas?: boolean | null ,
/**
 * Sets the objective c class prefix which is prepended to all objective c
 * generated classes from this .proto. There is no default.
 */
objc_class_prefix?: string | null ,
/** Namespace for generated classes; defaults to the package. */
csharp_namespace?: string | null ,
/**
 * By default Swift generators will take the proto package and CamelCase it
 * replacing '.' with underscore and use that to prefix the types/symbols
 * defined. When this options is provided, they will use this value instead
 * to prefix the types/symbols defined.
 */
swift_prefix?: string | null ,
/**
 * Sets the php class prefix which is prepended to all php generated classes
 * from this .proto. Default is empty.
 */
php_class_prefix?: string | null ,
/**
 * Use this option to change the namespace of php generated classes. Default
 * is empty. When this option is empty, the package name will be used for
 * determining the namespace.
 */
php_namespace?: string | null ,
/**
 * Use this option to change the namespace of php generated metadata classes.
 * Default is empty. When this option is empty, the proto file name will be
 * used for determining the namespace.
 */
php_metadata_namespace?: string | null ,
/**
 * Use this option to change the package of ruby generated classes. Default
 * is empty. When this option is not set, the package name will be used for
 * determining the ruby package.
 */
ruby_package?: string | null ,
/** Any features defined in the specific edition. */
features?: FeatureSet | null ,
/**
 * The parser stores options it doesn't recognize here.
 * See the documentation for the "Options" section above.
 */
uninterpreted_option: UninterpretedOption[],
}

/** Generated classes can be optimized for speed or code size. */
export const FileOptions_OptimizeMode = {
/** SPEED - Generate complete code for parsing, serialization, */
SPEED : "SPEED",
/** CODE_SIZE - etc. */
CODE_SIZE : "CODE_SIZE",
/** LITE_RUNTIME - Generate code using MessageLite and the lite runtime. */
LITE_RUNTIME : "LITE_RUNTIME",
UNRECOGNIZED : "UNRECOGNIZED",
} as const

export type FileOptions_OptimizeMode = typeof FileOptions_OptimizeMode[keyof typeof FileOptions_OptimizeMode]

export namespace FileOptions_OptimizeMode {
export type SPEED = typeof FileOptions_OptimizeMode.SPEED;
export type CODE_SIZE = typeof FileOptions_OptimizeMode.CODE_SIZE;
export type LITE_RUNTIME = typeof FileOptions_OptimizeMode.LITE_RUNTIME;
export type UNRECOGNIZED = typeof FileOptions_OptimizeMode.UNRECOGNIZED;
}

export function fileOptions_OptimizeModeFromJSON(object: any): FileOptions_OptimizeMode {
switch (object) {
case 1:
      case "SPEED":
        return FileOptions_OptimizeMode.SPEED;
case 2:
      case "CODE_SIZE":
        return FileOptions_OptimizeMode.CODE_SIZE;
case 3:
      case "LITE_RUNTIME":
        return FileOptions_OptimizeMode.LITE_RUNTIME;
case 0:
        case "UNRECOGNIZED":
        default:
          return FileOptions_OptimizeMode.UNRECOGNIZED;
}
}

export function fileOptions_OptimizeModeToJSON(object: FileOptions_OptimizeMode): string {
switch (object) {
case FileOptions_OptimizeMode.SPEED: return "SPEED";
case FileOptions_OptimizeMode.CODE_SIZE: return "CODE_SIZE";
case FileOptions_OptimizeMode.LITE_RUNTIME: return "LITE_RUNTIME";
case FileOptions_OptimizeMode.UNRECOGNIZED:
default:
          return "UNRECOGNIZED";
}
}

export function fileOptions_OptimizeModeToNumber(object: FileOptions_OptimizeMode): number {
switch (object) {
case FileOptions_OptimizeMode.SPEED: return 1;
case FileOptions_OptimizeMode.CODE_SIZE: return 2;
case FileOptions_OptimizeMode.LITE_RUNTIME: return 3;
case FileOptions_OptimizeMode.UNRECOGNIZED:
        default:
          return 0;
}
}

export interface MessageOptions {
/**
 * Set true to use the old proto1 MessageSet wire format for extensions.
 * This is provided for backwards-compatibility with the MessageSet wire
 * format.  You should not use this for any other reason:  It's less
 * efficient, has fewer features, and is more complicated.
 * 
 * The message must be defined exactly as follows:
 *   message Foo {
 *     option message_set_wire_format = true;
 *     extensions 4 to max;
 *   }
 * Note that the message cannot have any defined fields; MessageSets only
 * have extensions.
 * 
 * All extensions of your type must be singular messages; e.g. they cannot
 * be int32s, enums, or repeated messages.
 * 
 * Because this is an option, the above two restrictions are not enforced by
 * the protocol compiler.
 */
message_set_wire_format?: boolean | null ,
/**
 * Disables the generation of the standard "descriptor()" accessor, which can
 * conflict with a field of the same name.  This is meant to make migration
 * from proto1 easier; new code should avoid fields named "descriptor".
 */
no_standard_descriptor_accessor?: boolean | null ,
/**
 * Is this message deprecated?
 * Depending on the target platform, this can emit Deprecated annotations
 * for the message, or it will be completely ignored; in the very least,
 * this is a formalization for deprecating messages.
 */
deprecated?: boolean | null ,
/**
 * Whether the message is an automatically generated map entry type for the
 * maps field.
 * 
 * For maps fields:
 *     map<KeyType, ValueType> map_field = 1;
 * The parsed descriptor looks like:
 *     message MapFieldEntry {
 *         option map_entry = true;
 *         optional KeyType key = 1;
 *         optional ValueType value = 2;
 *     }
 *     repeated MapFieldEntry map_field = 1;
 * 
 * Implementations may choose not to generate the map_entry=true message, but
 * use a native map in the target language to hold the keys and values.
 * The reflection APIs in such implementations still need to work as
 * if the field is a repeated message field.
 * 
 * NOTE: Do not set the option in .proto files. Always use the maps syntax
 * instead. The option should only be implicitly set by the proto compiler
 * parser.
 */
map_entry?: boolean | null ,
/**
 * Enable the legacy handling of JSON field name conflicts.  This lowercases
 * and strips underscored from the fields before comparison in proto3 only.
 * The new behavior takes `json_name` into account and applies to proto2 as
 * well.
 * 
 * This should only be used as a temporary measure against broken builds due
 * to the change in behavior for JSON field name conflicts.
 * 
 * TODO This is legacy behavior we plan to remove once downstream
 * teams have had time to migrate.
 * 
 * @deprecated
 */
deprecated_legacy_json_field_conflicts?: boolean | null ,
/** Any features defined in the specific edition. */
features?: FeatureSet | null ,
/** The parser stores options it doesn't recognize here. See above. */
uninterpreted_option: UninterpretedOption[],
}

export interface FieldOptions {
/**
 * The ctype option instructs the C++ code generator to use a different
 * representation of the field than it normally would.  See the specific
 * options below.  This option is only implemented to support use of
 * [ctype=CORD] and [ctype=STRING] (the default) on non-repeated fields of
 * type "bytes" in the open source release -- sorry, we'll try to include
 * other types in a future version!
 */
ctype?: FieldOptions_CType | null ,
/**
 * The packed option can be enabled for repeated primitive fields to enable
 * a more efficient representation on the wire. Rather than repeatedly
 * writing the tag and type for each element, the entire array is encoded as
 * a single length-delimited blob. In proto3, only explicit setting it to
 * false will avoid using packed encoding.  This option is prohibited in
 * Editions, but the `repeated_field_encoding` feature can be used to control
 * the behavior.
 */
packed?: boolean | null ,
/**
 * The jstype option determines the JavaScript type used for values of the
 * field.  The option is permitted only for 64 bit integral and fixed types
 * (int64, uint64, sint64, fixed64, sfixed64).  A field with jstype JS_STRING
 * is represented as JavaScript string, which avoids loss of precision that
 * can happen when a large value is converted to a floating point JavaScript.
 * Specifying JS_NUMBER for the jstype causes the generated JavaScript code to
 * use the JavaScript "number" type.  The behavior of the default option
 * JS_NORMAL is implementation dependent.
 * 
 * This option is an enum to permit additional types to be added, e.g.
 * goog.math.Integer.
 */
jstype?: FieldOptions_JSType | null ,
/**
 * Should this field be parsed lazily?  Lazy applies only to message-type
 * fields.  It means that when the outer message is initially parsed, the
 * inner message's contents will not be parsed but instead stored in encoded
 * form.  The inner message will actually be parsed when it is first accessed.
 * 
 * This is only a hint.  Implementations are free to choose whether to use
 * eager or lazy parsing regardless of the value of this option.  However,
 * setting this option true suggests that the protocol author believes that
 * using lazy parsing on this field is worth the additional bookkeeping
 * overhead typically needed to implement it.
 * 
 * This option does not affect the public interface of any generated code;
 * all method signatures remain the same.  Furthermore, thread-safety of the
 * interface is not affected by this option; const methods remain safe to
 * call from multiple threads concurrently, while non-const methods continue
 * to require exclusive access.
 * 
 * Note that lazy message fields are still eagerly verified to check
 * ill-formed wireformat or missing required fields. Calling IsInitialized()
 * on the outer message would fail if the inner message has missing required
 * fields. Failed verification would result in parsing failure (except when
 * uninitialized messages are acceptable).
 */
lazy?: boolean | null ,
/**
 * unverified_lazy does no correctness checks on the byte stream. This should
 * only be used where lazy with verification is prohibitive for performance
 * reasons.
 */
unverified_lazy?: boolean | null ,
/**
 * Is this field deprecated?
 * Depending on the target platform, this can emit Deprecated annotations
 * for accessors, or it will be completely ignored; in the very least, this
 * is a formalization for deprecating fields.
 */
deprecated?: boolean | null ,
/** For Google-internal migration only. Do not use. */
weak?: boolean | null ,
/**
 * Indicate that the field value should not be printed out when using debug
 * formats, e.g. when the field contains sensitive credentials.
 */
debug_redact?: boolean | null ,
retention?: FieldOptions_OptionRetention | null ,
targets: FieldOptions_OptionTargetType[],
edition_defaults: FieldOptions_EditionDefault[],
/** Any features defined in the specific edition. */
features?: FeatureSet | null ,
feature_support?: FieldOptions_FeatureSupport | null ,
/** The parser stores options it doesn't recognize here. See above. */
uninterpreted_option: UninterpretedOption[],
}

export const FieldOptions_CType = {
/** STRING - Default mode. */
STRING : "STRING",
/**
 * CORD - The option [ctype=CORD] may be applied to a non-repeated field of type
 * "bytes". It indicates that in C++, the data should be stored in a Cord
 * instead of a string.  For very large strings, this may reduce memory
 * fragmentation. It may also allow better performance when parsing from a
 * Cord, or when parsing with aliasing enabled, as the parsed Cord may then
 * alias the original buffer.
 */
CORD : "CORD",
STRING_PIECE : "STRING_PIECE",
} as const

export type FieldOptions_CType = typeof FieldOptions_CType[keyof typeof FieldOptions_CType]

export namespace FieldOptions_CType {
export type STRING = typeof FieldOptions_CType.STRING;
export type CORD = typeof FieldOptions_CType.CORD;
export type STRING_PIECE = typeof FieldOptions_CType.STRING_PIECE;
}

export function fieldOptions_CTypeFromJSON(object: any): FieldOptions_CType {
switch (object) {
case 0:
      case "STRING":
        return FieldOptions_CType.STRING;
case 1:
      case "CORD":
        return FieldOptions_CType.CORD;
case 2:
      case "STRING_PIECE":
        return FieldOptions_CType.STRING_PIECE;
default:
          return FieldOptions_CType.STRING;
}
}

export function fieldOptions_CTypeToJSON(object: FieldOptions_CType): string {
switch (object) {
case FieldOptions_CType.STRING: return "STRING";
case FieldOptions_CType.CORD: return "CORD";
case FieldOptions_CType.STRING_PIECE: return "STRING_PIECE";
default:
        return "STRING";
}
}

export function fieldOptions_CTypeToNumber(object: FieldOptions_CType): number {
switch (object) {
case FieldOptions_CType.STRING: return 0;
case FieldOptions_CType.CORD: return 1;
case FieldOptions_CType.STRING_PIECE: return 2;
default:
          return 0;
}
}

export const FieldOptions_JSType = {
/** JS_NORMAL - Use the default type. */
JS_NORMAL : "JS_NORMAL",
/** JS_STRING - Use JavaScript strings. */
JS_STRING : "JS_STRING",
/** JS_NUMBER - Use JavaScript numbers. */
JS_NUMBER : "JS_NUMBER",
} as const

export type FieldOptions_JSType = typeof FieldOptions_JSType[keyof typeof FieldOptions_JSType]

export namespace FieldOptions_JSType {
export type JS_NORMAL = typeof FieldOptions_JSType.JS_NORMAL;
export type JS_STRING = typeof FieldOptions_JSType.JS_STRING;
export type JS_NUMBER = typeof FieldOptions_JSType.JS_NUMBER;
}

export function fieldOptions_JSTypeFromJSON(object: any): FieldOptions_JSType {
switch (object) {
case 0:
      case "JS_NORMAL":
        return FieldOptions_JSType.JS_NORMAL;
case 1:
      case "JS_STRING":
        return FieldOptions_JSType.JS_STRING;
case 2:
      case "JS_NUMBER":
        return FieldOptions_JSType.JS_NUMBER;
default:
          return FieldOptions_JSType.JS_NORMAL;
}
}

export function fieldOptions_JSTypeToJSON(object: FieldOptions_JSType): string {
switch (object) {
case FieldOptions_JSType.JS_NORMAL: return "JS_NORMAL";
case FieldOptions_JSType.JS_STRING: return "JS_STRING";
case FieldOptions_JSType.JS_NUMBER: return "JS_NUMBER";
default:
        return "JS_NORMAL";
}
}

export function fieldOptions_JSTypeToNumber(object: FieldOptions_JSType): number {
switch (object) {
case FieldOptions_JSType.JS_NORMAL: return 0;
case FieldOptions_JSType.JS_STRING: return 1;
case FieldOptions_JSType.JS_NUMBER: return 2;
default:
          return 0;
}
}

/**
 * If set to RETENTION_SOURCE, the option will be omitted from the binary.
 * Note: as of January 2023, support for this is in progress and does not yet
 * have an effect (b/264593489).
 */
export const FieldOptions_OptionRetention = {
RETENTION_UNKNOWN : "RETENTION_UNKNOWN",
RETENTION_RUNTIME : "RETENTION_RUNTIME",
RETENTION_SOURCE : "RETENTION_SOURCE",
} as const

export type FieldOptions_OptionRetention = typeof FieldOptions_OptionRetention[keyof typeof FieldOptions_OptionRetention]

export namespace FieldOptions_OptionRetention {
export type RETENTION_UNKNOWN = typeof FieldOptions_OptionRetention.RETENTION_UNKNOWN;
export type RETENTION_RUNTIME = typeof FieldOptions_OptionRetention.RETENTION_RUNTIME;
export type RETENTION_SOURCE = typeof FieldOptions_OptionRetention.RETENTION_SOURCE;
}

export function fieldOptions_OptionRetentionFromJSON(object: any): FieldOptions_OptionRetention {
switch (object) {
case 0:
      case "RETENTION_UNKNOWN":
        return FieldOptions_OptionRetention.RETENTION_UNKNOWN;
case 1:
      case "RETENTION_RUNTIME":
        return FieldOptions_OptionRetention.RETENTION_RUNTIME;
case 2:
      case "RETENTION_SOURCE":
        return FieldOptions_OptionRetention.RETENTION_SOURCE;
default:
          return FieldOptions_OptionRetention.RETENTION_UNKNOWN;
}
}

export function fieldOptions_OptionRetentionToJSON(object: FieldOptions_OptionRetention): string {
switch (object) {
case FieldOptions_OptionRetention.RETENTION_UNKNOWN: return "RETENTION_UNKNOWN";
case FieldOptions_OptionRetention.RETENTION_RUNTIME: return "RETENTION_RUNTIME";
case FieldOptions_OptionRetention.RETENTION_SOURCE: return "RETENTION_SOURCE";
default:
        return "RETENTION_UNKNOWN";
}
}

export function fieldOptions_OptionRetentionToNumber(object: FieldOptions_OptionRetention): number {
switch (object) {
case FieldOptions_OptionRetention.RETENTION_UNKNOWN: return 0;
case FieldOptions_OptionRetention.RETENTION_RUNTIME: return 1;
case FieldOptions_OptionRetention.RETENTION_SOURCE: return 2;
default:
          return 0;
}
}

/**
 * This indicates the types of entities that the field may apply to when used
 * as an option. If it is unset, then the field may be freely used as an
 * option on any kind of entity. Note: as of January 2023, support for this is
 * in progress and does not yet have an effect (b/264593489).
 */
export const FieldOptions_OptionTargetType = {
TARGET_TYPE_UNKNOWN : "TARGET_TYPE_UNKNOWN",
TARGET_TYPE_FILE : "TARGET_TYPE_FILE",
TARGET_TYPE_EXTENSION_RANGE : "TARGET_TYPE_EXTENSION_RANGE",
TARGET_TYPE_MESSAGE : "TARGET_TYPE_MESSAGE",
TARGET_TYPE_FIELD : "TARGET_TYPE_FIELD",
TARGET_TYPE_ONEOF : "TARGET_TYPE_ONEOF",
TARGET_TYPE_ENUM : "TARGET_TYPE_ENUM",
TARGET_TYPE_ENUM_ENTRY : "TARGET_TYPE_ENUM_ENTRY",
TARGET_TYPE_SERVICE : "TARGET_TYPE_SERVICE",
TARGET_TYPE_METHOD : "TARGET_TYPE_METHOD",
} as const

export type FieldOptions_OptionTargetType = typeof FieldOptions_OptionTargetType[keyof typeof FieldOptions_OptionTargetType]

export namespace FieldOptions_OptionTargetType {
export type TARGET_TYPE_UNKNOWN = typeof FieldOptions_OptionTargetType.TARGET_TYPE_UNKNOWN;
export type TARGET_TYPE_FILE = typeof FieldOptions_OptionTargetType.TARGET_TYPE_FILE;
export type TARGET_TYPE_EXTENSION_RANGE = typeof FieldOptions_OptionTargetType.TARGET_TYPE_EXTENSION_RANGE;
export type TARGET_TYPE_MESSAGE = typeof FieldOptions_OptionTargetType.TARGET_TYPE_MESSAGE;
export type TARGET_TYPE_FIELD = typeof FieldOptions_OptionTargetType.TARGET_TYPE_FIELD;
export type TARGET_TYPE_ONEOF = typeof FieldOptions_OptionTargetType.TARGET_TYPE_ONEOF;
export type TARGET_TYPE_ENUM = typeof FieldOptions_OptionTargetType.TARGET_TYPE_ENUM;
export type TARGET_TYPE_ENUM_ENTRY = typeof FieldOptions_OptionTargetType.TARGET_TYPE_ENUM_ENTRY;
export type TARGET_TYPE_SERVICE = typeof FieldOptions_OptionTargetType.TARGET_TYPE_SERVICE;
export type TARGET_TYPE_METHOD = typeof FieldOptions_OptionTargetType.TARGET_TYPE_METHOD;
}

export function fieldOptions_OptionTargetTypeFromJSON(object: any): FieldOptions_OptionTargetType {
switch (object) {
case 0:
      case "TARGET_TYPE_UNKNOWN":
        return FieldOptions_OptionTargetType.TARGET_TYPE_UNKNOWN;
case 1:
      case "TARGET_TYPE_FILE":
        return FieldOptions_OptionTargetType.TARGET_TYPE_FILE;
case 2:
      case "TARGET_TYPE_EXTENSION_RANGE":
        return FieldOptions_OptionTargetType.TARGET_TYPE_EXTENSION_RANGE;
case 3:
      case "TARGET_TYPE_MESSAGE":
        return FieldOptions_OptionTargetType.TARGET_TYPE_MESSAGE;
case 4:
      case "TARGET_TYPE_FIELD":
        return FieldOptions_OptionTargetType.TARGET_TYPE_FIELD;
case 5:
      case "TARGET_TYPE_ONEOF":
        return FieldOptions_OptionTargetType.TARGET_TYPE_ONEOF;
case 6:
      case "TARGET_TYPE_ENUM":
        return FieldOptions_OptionTargetType.TARGET_TYPE_ENUM;
case 7:
      case "TARGET_TYPE_ENUM_ENTRY":
        return FieldOptions_OptionTargetType.TARGET_TYPE_ENUM_ENTRY;
case 8:
      case "TARGET_TYPE_SERVICE":
        return FieldOptions_OptionTargetType.TARGET_TYPE_SERVICE;
case 9:
      case "TARGET_TYPE_METHOD":
        return FieldOptions_OptionTargetType.TARGET_TYPE_METHOD;
default:
          return FieldOptions_OptionTargetType.TARGET_TYPE_UNKNOWN;
}
}

export function fieldOptions_OptionTargetTypeToJSON(object: FieldOptions_OptionTargetType): string {
switch (object) {
case FieldOptions_OptionTargetType.TARGET_TYPE_UNKNOWN: return "TARGET_TYPE_UNKNOWN";
case FieldOptions_OptionTargetType.TARGET_TYPE_FILE: return "TARGET_TYPE_FILE";
case FieldOptions_OptionTargetType.TARGET_TYPE_EXTENSION_RANGE: return "TARGET_TYPE_EXTENSION_RANGE";
case FieldOptions_OptionTargetType.TARGET_TYPE_MESSAGE: return "TARGET_TYPE_MESSAGE";
case FieldOptions_OptionTargetType.TARGET_TYPE_FIELD: return "TARGET_TYPE_FIELD";
case FieldOptions_OptionTargetType.TARGET_TYPE_ONEOF: return "TARGET_TYPE_ONEOF";
case FieldOptions_OptionTargetType.TARGET_TYPE_ENUM: return "TARGET_TYPE_ENUM";
case FieldOptions_OptionTargetType.TARGET_TYPE_ENUM_ENTRY: return "TARGET_TYPE_ENUM_ENTRY";
case FieldOptions_OptionTargetType.TARGET_TYPE_SERVICE: return "TARGET_TYPE_SERVICE";
case FieldOptions_OptionTargetType.TARGET_TYPE_METHOD: return "TARGET_TYPE_METHOD";
default:
        return "TARGET_TYPE_UNKNOWN";
}
}

export function fieldOptions_OptionTargetTypeToNumber(object: FieldOptions_OptionTargetType): number {
switch (object) {
case FieldOptions_OptionTargetType.TARGET_TYPE_UNKNOWN: return 0;
case FieldOptions_OptionTargetType.TARGET_TYPE_FILE: return 1;
case FieldOptions_OptionTargetType.TARGET_TYPE_EXTENSION_RANGE: return 2;
case FieldOptions_OptionTargetType.TARGET_TYPE_MESSAGE: return 3;
case FieldOptions_OptionTargetType.TARGET_TYPE_FIELD: return 4;
case FieldOptions_OptionTargetType.TARGET_TYPE_ONEOF: return 5;
case FieldOptions_OptionTargetType.TARGET_TYPE_ENUM: return 6;
case FieldOptions_OptionTargetType.TARGET_TYPE_ENUM_ENTRY: return 7;
case FieldOptions_OptionTargetType.TARGET_TYPE_SERVICE: return 8;
case FieldOptions_OptionTargetType.TARGET_TYPE_METHOD: return 9;
default:
          return 0;
}
}

export interface FieldOptions_EditionDefault {
edition?: Edition | null ,
/** Textproto value. */
value?: string | null ,
}

/** Information about the support window of a feature. */
export interface FieldOptions_FeatureSupport {
/**
 * The edition that this feature was first available in.  In editions
 * earlier than this one, the default assigned to EDITION_LEGACY will be
 * used, and proto files will not be able to override it.
 */
edition_introduced?: Edition | null ,
/**
 * The edition this feature becomes deprecated in.  Using this after this
 * edition may trigger warnings.
 */
edition_deprecated?: Edition | null ,
/**
 * The deprecation warning text if this feature is used after the edition it
 * was marked deprecated in.
 */
deprecation_warning?: string | null ,
/**
 * The edition this feature is no longer available in.  In editions after
 * this one, the last default assigned will be used, and proto files will
 * not be able to override it.
 */
edition_removed?: Edition | null ,
}

export interface OneofOptions {
/** Any features defined in the specific edition. */
features?: FeatureSet | null ,
/** The parser stores options it doesn't recognize here. See above. */
uninterpreted_option: UninterpretedOption[],
}

export interface EnumOptions {
/**
 * Set this option to true to allow mapping different tag names to the same
 * value.
 */
allow_alias?: boolean | null ,
/**
 * Is this enum deprecated?
 * Depending on the target platform, this can emit Deprecated annotations
 * for the enum, or it will be completely ignored; in the very least, this
 * is a formalization for deprecating enums.
 */
deprecated?: boolean | null ,
/**
 * Enable the legacy handling of JSON field name conflicts.  This lowercases
 * and strips underscored from the fields before comparison in proto3 only.
 * The new behavior takes `json_name` into account and applies to proto2 as
 * well.
 * TODO Remove this legacy behavior once downstream teams have
 * had time to migrate.
 * 
 * @deprecated
 */
deprecated_legacy_json_field_conflicts?: boolean | null ,
/** Any features defined in the specific edition. */
features?: FeatureSet | null ,
/** The parser stores options it doesn't recognize here. See above. */
uninterpreted_option: UninterpretedOption[],
}

export interface EnumValueOptions {
/**
 * Is this enum value deprecated?
 * Depending on the target platform, this can emit Deprecated annotations
 * for the enum value, or it will be completely ignored; in the very least,
 * this is a formalization for deprecating enum values.
 */
deprecated?: boolean | null ,
/** Any features defined in the specific edition. */
features?: FeatureSet | null ,
/**
 * Indicate that fields annotated with this enum value should not be printed
 * out when using debug formats, e.g. when the field contains sensitive
 * credentials.
 */
debug_redact?: boolean | null ,
/** Information about the support window of a feature value. */
feature_support?: FieldOptions_FeatureSupport | null ,
/** The parser stores options it doesn't recognize here. See above. */
uninterpreted_option: UninterpretedOption[],
}

export interface ServiceOptions {
/** Any features defined in the specific edition. */
features?: FeatureSet | null ,
/**
 * Is this service deprecated?
 * Depending on the target platform, this can emit Deprecated annotations
 * for the service, or it will be completely ignored; in the very least,
 * this is a formalization for deprecating services.
 */
deprecated?: boolean | null ,
/** The parser stores options it doesn't recognize here. See above. */
uninterpreted_option: UninterpretedOption[],
}

export interface MethodOptions {
/**
 * Is this method deprecated?
 * Depending on the target platform, this can emit Deprecated annotations
 * for the method, or it will be completely ignored; in the very least,
 * this is a formalization for deprecating methods.
 */
deprecated?: boolean | null ,
idempotency_level?: MethodOptions_IdempotencyLevel | null ,
/** Any features defined in the specific edition. */
features?: FeatureSet | null ,
/** The parser stores options it doesn't recognize here. See above. */
uninterpreted_option: UninterpretedOption[],
}

/**
 * Is this method side-effect-free (or safe in HTTP parlance), or idempotent,
 * or neither? HTTP based RPC implementation may choose GET verb for safe
 * methods, and PUT verb for idempotent methods instead of the default POST.
 */
export const MethodOptions_IdempotencyLevel = {
IDEMPOTENCY_UNKNOWN : "IDEMPOTENCY_UNKNOWN",
/** NO_SIDE_EFFECTS - implies idempotent */
NO_SIDE_EFFECTS : "NO_SIDE_EFFECTS",
/** IDEMPOTENT - idempotent, but may have side effects */
IDEMPOTENT : "IDEMPOTENT",
} as const

export type MethodOptions_IdempotencyLevel = typeof MethodOptions_IdempotencyLevel[keyof typeof MethodOptions_IdempotencyLevel]

export namespace MethodOptions_IdempotencyLevel {
export type IDEMPOTENCY_UNKNOWN = typeof MethodOptions_IdempotencyLevel.IDEMPOTENCY_UNKNOWN;
export type NO_SIDE_EFFECTS = typeof MethodOptions_IdempotencyLevel.NO_SIDE_EFFECTS;
export type IDEMPOTENT = typeof MethodOptions_IdempotencyLevel.IDEMPOTENT;
}

export function methodOptions_IdempotencyLevelFromJSON(object: any): MethodOptions_IdempotencyLevel {
switch (object) {
case 0:
      case "IDEMPOTENCY_UNKNOWN":
        return MethodOptions_IdempotencyLevel.IDEMPOTENCY_UNKNOWN;
case 1:
      case "NO_SIDE_EFFECTS":
        return MethodOptions_IdempotencyLevel.NO_SIDE_EFFECTS;
case 2:
      case "IDEMPOTENT":
        return MethodOptions_IdempotencyLevel.IDEMPOTENT;
default:
          return MethodOptions_IdempotencyLevel.IDEMPOTENCY_UNKNOWN;
}
}

export function methodOptions_IdempotencyLevelToJSON(object: MethodOptions_IdempotencyLevel): string {
switch (object) {
case MethodOptions_IdempotencyLevel.IDEMPOTENCY_UNKNOWN: return "IDEMPOTENCY_UNKNOWN";
case MethodOptions_IdempotencyLevel.NO_SIDE_EFFECTS: return "NO_SIDE_EFFECTS";
case MethodOptions_IdempotencyLevel.IDEMPOTENT: return "IDEMPOTENT";
default:
        return "IDEMPOTENCY_UNKNOWN";
}
}

export function methodOptions_IdempotencyLevelToNumber(object: MethodOptions_IdempotencyLevel): number {
switch (object) {
case MethodOptions_IdempotencyLevel.IDEMPOTENCY_UNKNOWN: return 0;
case MethodOptions_IdempotencyLevel.NO_SIDE_EFFECTS: return 1;
case MethodOptions_IdempotencyLevel.IDEMPOTENT: return 2;
default:
          return 0;
}
}

/**
 * A message representing a option the parser does not recognize. This only
 * appears in options protos created by the compiler::Parser class.
 * DescriptorPool resolves these when building Descriptor objects. Therefore,
 * options protos in descriptor objects (e.g. returned by Descriptor::options(),
 * or produced by Descriptor::CopyTo()) will never have UninterpretedOptions
 * in them.
 */
export interface UninterpretedOption {
name: UninterpretedOption_NamePart[],
/**
 * The value of the uninterpreted option, in whatever type the tokenizer
 * identified it as during parsing. Exactly one of these should be set.
 */
identifier_value?: string | null ,
positive_int_value?: bigint | null ,
negative_int_value?: bigint | null ,
double_value?: number | null ,
string_value?: Buffer | null ,
aggregate_value?: string | null ,
}

/**
 * The name of the uninterpreted option.  Each string represents a segment in
 * a dot-separated name.  is_extension is true iff a segment represents an
 * extension (denoted with parentheses in options specs in .proto files).
 * E.g.,{ ["foo", false], ["bar.baz", true], ["moo", false] } represents
 * "foo.(bar.baz).moo".
 */
export interface UninterpretedOption_NamePart {
name_part: string,
is_extension: boolean,
}

/**
 * TODO Enums in C++ gencode (and potentially other languages) are
 * not well scoped.  This means that each of the feature enums below can clash
 * with each other.  The short names we've chosen maximize call-site
 * readability, but leave us very open to this scenario.  A future feature will
 * be designed and implemented to handle this, hopefully before we ever hit a
 * conflict here.
 */
export interface FeatureSet {
field_presence?: FeatureSet_FieldPresence | null ,
enum_type?: FeatureSet_EnumType | null ,
repeated_field_encoding?: FeatureSet_RepeatedFieldEncoding | null ,
utf8_validation?: FeatureSet_Utf8Validation | null ,
message_encoding?: FeatureSet_MessageEncoding | null ,
json_format?: FeatureSet_JsonFormat | null ,
}

export const FeatureSet_FieldPresence = {
UNKNOWN : "FIELD_PRESENCE_UNKNOWN",
EXPLICIT : "EXPLICIT",
IMPLICIT : "IMPLICIT",
LEGACY_REQUIRED : "LEGACY_REQUIRED",
} as const

export type FeatureSet_FieldPresence = typeof FeatureSet_FieldPresence[keyof typeof FeatureSet_FieldPresence]

export namespace FeatureSet_FieldPresence {
export type UNKNOWN = typeof FeatureSet_FieldPresence.UNKNOWN;
export type EXPLICIT = typeof FeatureSet_FieldPresence.EXPLICIT;
export type IMPLICIT = typeof FeatureSet_FieldPresence.IMPLICIT;
export type LEGACY_REQUIRED = typeof FeatureSet_FieldPresence.LEGACY_REQUIRED;
}

export function featureSet_FieldPresenceFromJSON(object: any): FeatureSet_FieldPresence {
switch (object) {
case 0:
      case "FIELD_PRESENCE_UNKNOWN":
        return FeatureSet_FieldPresence.UNKNOWN;
case 1:
      case "EXPLICIT":
        return FeatureSet_FieldPresence.EXPLICIT;
case 2:
      case "IMPLICIT":
        return FeatureSet_FieldPresence.IMPLICIT;
case 3:
      case "LEGACY_REQUIRED":
        return FeatureSet_FieldPresence.LEGACY_REQUIRED;
default:
          return FeatureSet_FieldPresence.UNKNOWN;
}
}

export function featureSet_FieldPresenceToJSON(object: FeatureSet_FieldPresence): string {
switch (object) {
case FeatureSet_FieldPresence.UNKNOWN: return "FIELD_PRESENCE_UNKNOWN";
case FeatureSet_FieldPresence.EXPLICIT: return "EXPLICIT";
case FeatureSet_FieldPresence.IMPLICIT: return "IMPLICIT";
case FeatureSet_FieldPresence.LEGACY_REQUIRED: return "LEGACY_REQUIRED";
default:
        return "UNKNOWN";
}
}

export function featureSet_FieldPresenceToNumber(object: FeatureSet_FieldPresence): number {
switch (object) {
case FeatureSet_FieldPresence.UNKNOWN: return 0;
case FeatureSet_FieldPresence.EXPLICIT: return 1;
case FeatureSet_FieldPresence.IMPLICIT: return 2;
case FeatureSet_FieldPresence.LEGACY_REQUIRED: return 3;
default:
          return 0;
}
}

export const FeatureSet_EnumType = {
UNKNOWN : "ENUM_TYPE_UNKNOWN",
OPEN : "OPEN",
CLOSED : "CLOSED",
} as const

export type FeatureSet_EnumType = typeof FeatureSet_EnumType[keyof typeof FeatureSet_EnumType]

export namespace FeatureSet_EnumType {
export type UNKNOWN = typeof FeatureSet_EnumType.UNKNOWN;
export type OPEN = typeof FeatureSet_EnumType.OPEN;
export type CLOSED = typeof FeatureSet_EnumType.CLOSED;
}

export function featureSet_EnumTypeFromJSON(object: any): FeatureSet_EnumType {
switch (object) {
case 0:
      case "ENUM_TYPE_UNKNOWN":
        return FeatureSet_EnumType.UNKNOWN;
case 1:
      case "OPEN":
        return FeatureSet_EnumType.OPEN;
case 2:
      case "CLOSED":
        return FeatureSet_EnumType.CLOSED;
default:
          return FeatureSet_EnumType.UNKNOWN;
}
}

export function featureSet_EnumTypeToJSON(object: FeatureSet_EnumType): string {
switch (object) {
case FeatureSet_EnumType.UNKNOWN: return "ENUM_TYPE_UNKNOWN";
case FeatureSet_EnumType.OPEN: return "OPEN";
case FeatureSet_EnumType.CLOSED: return "CLOSED";
default:
        return "UNKNOWN";
}
}

export function featureSet_EnumTypeToNumber(object: FeatureSet_EnumType): number {
switch (object) {
case FeatureSet_EnumType.UNKNOWN: return 0;
case FeatureSet_EnumType.OPEN: return 1;
case FeatureSet_EnumType.CLOSED: return 2;
default:
          return 0;
}
}

export const FeatureSet_RepeatedFieldEncoding = {
UNKNOWN : "REPEATED_FIELD_ENCODING_UNKNOWN",
PACKED : "PACKED",
EXPANDED : "EXPANDED",
} as const

export type FeatureSet_RepeatedFieldEncoding = typeof FeatureSet_RepeatedFieldEncoding[keyof typeof FeatureSet_RepeatedFieldEncoding]

export namespace FeatureSet_RepeatedFieldEncoding {
export type UNKNOWN = typeof FeatureSet_RepeatedFieldEncoding.UNKNOWN;
export type PACKED = typeof FeatureSet_RepeatedFieldEncoding.PACKED;
export type EXPANDED = typeof FeatureSet_RepeatedFieldEncoding.EXPANDED;
}

export function featureSet_RepeatedFieldEncodingFromJSON(object: any): FeatureSet_RepeatedFieldEncoding {
switch (object) {
case 0:
      case "REPEATED_FIELD_ENCODING_UNKNOWN":
        return FeatureSet_RepeatedFieldEncoding.UNKNOWN;
case 1:
      case "PACKED":
        return FeatureSet_RepeatedFieldEncoding.PACKED;
case 2:
      case "EXPANDED":
        return FeatureSet_RepeatedFieldEncoding.EXPANDED;
default:
          return FeatureSet_RepeatedFieldEncoding.UNKNOWN;
}
}

export function featureSet_RepeatedFieldEncodingToJSON(object: FeatureSet_RepeatedFieldEncoding): string {
switch (object) {
case FeatureSet_RepeatedFieldEncoding.UNKNOWN: return "REPEATED_FIELD_ENCODING_UNKNOWN";
case FeatureSet_RepeatedFieldEncoding.PACKED: return "PACKED";
case FeatureSet_RepeatedFieldEncoding.EXPANDED: return "EXPANDED";
default:
        return "UNKNOWN";
}
}

export function featureSet_RepeatedFieldEncodingToNumber(object: FeatureSet_RepeatedFieldEncoding): number {
switch (object) {
case FeatureSet_RepeatedFieldEncoding.UNKNOWN: return 0;
case FeatureSet_RepeatedFieldEncoding.PACKED: return 1;
case FeatureSet_RepeatedFieldEncoding.EXPANDED: return 2;
default:
          return 0;
}
}

export const FeatureSet_Utf8Validation = {
UNKNOWN : "UTF8_VALIDATION_UNKNOWN",
VERIFY : "VERIFY",
NONE : "NONE",
} as const

export type FeatureSet_Utf8Validation = typeof FeatureSet_Utf8Validation[keyof typeof FeatureSet_Utf8Validation]

export namespace FeatureSet_Utf8Validation {
export type UNKNOWN = typeof FeatureSet_Utf8Validation.UNKNOWN;
export type VERIFY = typeof FeatureSet_Utf8Validation.VERIFY;
export type NONE = typeof FeatureSet_Utf8Validation.NONE;
}

export function featureSet_Utf8ValidationFromJSON(object: any): FeatureSet_Utf8Validation {
switch (object) {
case 0:
      case "UTF8_VALIDATION_UNKNOWN":
        return FeatureSet_Utf8Validation.UNKNOWN;
case 2:
      case "VERIFY":
        return FeatureSet_Utf8Validation.VERIFY;
case 3:
      case "NONE":
        return FeatureSet_Utf8Validation.NONE;
default:
          return FeatureSet_Utf8Validation.UNKNOWN;
}
}

export function featureSet_Utf8ValidationToJSON(object: FeatureSet_Utf8Validation): string {
switch (object) {
case FeatureSet_Utf8Validation.UNKNOWN: return "UTF8_VALIDATION_UNKNOWN";
case FeatureSet_Utf8Validation.VERIFY: return "VERIFY";
case FeatureSet_Utf8Validation.NONE: return "NONE";
default:
        return "UNKNOWN";
}
}

export function featureSet_Utf8ValidationToNumber(object: FeatureSet_Utf8Validation): number {
switch (object) {
case FeatureSet_Utf8Validation.UNKNOWN: return 0;
case FeatureSet_Utf8Validation.VERIFY: return 2;
case FeatureSet_Utf8Validation.NONE: return 3;
default:
          return 0;
}
}

export const FeatureSet_MessageEncoding = {
UNKNOWN : "MESSAGE_ENCODING_UNKNOWN",
LENGTH_PREFIXED : "LENGTH_PREFIXED",
DELIMITED : "DELIMITED",
} as const

export type FeatureSet_MessageEncoding = typeof FeatureSet_MessageEncoding[keyof typeof FeatureSet_MessageEncoding]

export namespace FeatureSet_MessageEncoding {
export type UNKNOWN = typeof FeatureSet_MessageEncoding.UNKNOWN;
export type LENGTH_PREFIXED = typeof FeatureSet_MessageEncoding.LENGTH_PREFIXED;
export type DELIMITED = typeof FeatureSet_MessageEncoding.DELIMITED;
}

export function featureSet_MessageEncodingFromJSON(object: any): FeatureSet_MessageEncoding {
switch (object) {
case 0:
      case "MESSAGE_ENCODING_UNKNOWN":
        return FeatureSet_MessageEncoding.UNKNOWN;
case 1:
      case "LENGTH_PREFIXED":
        return FeatureSet_MessageEncoding.LENGTH_PREFIXED;
case 2:
      case "DELIMITED":
        return FeatureSet_MessageEncoding.DELIMITED;
default:
          return FeatureSet_MessageEncoding.UNKNOWN;
}
}

export function featureSet_MessageEncodingToJSON(object: FeatureSet_MessageEncoding): string {
switch (object) {
case FeatureSet_MessageEncoding.UNKNOWN: return "MESSAGE_ENCODING_UNKNOWN";
case FeatureSet_MessageEncoding.LENGTH_PREFIXED: return "LENGTH_PREFIXED";
case FeatureSet_MessageEncoding.DELIMITED: return "DELIMITED";
default:
        return "UNKNOWN";
}
}

export function featureSet_MessageEncodingToNumber(object: FeatureSet_MessageEncoding): number {
switch (object) {
case FeatureSet_MessageEncoding.UNKNOWN: return 0;
case FeatureSet_MessageEncoding.LENGTH_PREFIXED: return 1;
case FeatureSet_MessageEncoding.DELIMITED: return 2;
default:
          return 0;
}
}

export const FeatureSet_JsonFormat = {
UNKNOWN : "JSON_FORMAT_UNKNOWN",
ALLOW : "ALLOW",
LEGACY_BEST_EFFORT : "LEGACY_BEST_EFFORT",
} as const

export type FeatureSet_JsonFormat = typeof FeatureSet_JsonFormat[keyof typeof FeatureSet_JsonFormat]

export namespace FeatureSet_JsonFormat {
export type UNKNOWN = typeof FeatureSet_JsonFormat.UNKNOWN;
export type ALLOW = typeof FeatureSet_JsonFormat.ALLOW;
export type LEGACY_BEST_EFFORT = typeof FeatureSet_JsonFormat.LEGACY_BEST_EFFORT;
}

export function featureSet_JsonFormatFromJSON(object: any): FeatureSet_JsonFormat {
switch (object) {
case 0:
      case "JSON_FORMAT_UNKNOWN":
        return FeatureSet_JsonFormat.UNKNOWN;
case 1:
      case "ALLOW":
        return FeatureSet_JsonFormat.ALLOW;
case 2:
      case "LEGACY_BEST_EFFORT":
        return FeatureSet_JsonFormat.LEGACY_BEST_EFFORT;
default:
          return FeatureSet_JsonFormat.UNKNOWN;
}
}

export function featureSet_JsonFormatToJSON(object: FeatureSet_JsonFormat): string {
switch (object) {
case FeatureSet_JsonFormat.UNKNOWN: return "JSON_FORMAT_UNKNOWN";
case FeatureSet_JsonFormat.ALLOW: return "ALLOW";
case FeatureSet_JsonFormat.LEGACY_BEST_EFFORT: return "LEGACY_BEST_EFFORT";
default:
        return "UNKNOWN";
}
}

export function featureSet_JsonFormatToNumber(object: FeatureSet_JsonFormat): number {
switch (object) {
case FeatureSet_JsonFormat.UNKNOWN: return 0;
case FeatureSet_JsonFormat.ALLOW: return 1;
case FeatureSet_JsonFormat.LEGACY_BEST_EFFORT: return 2;
default:
          return 0;
}
}

/**
 * A compiled specification for the defaults of a set of features.  These
 * messages are generated from FeatureSet extensions and can be used to seed
 * feature resolution. The resolution with this object becomes a simple search
 * for the closest matching edition, followed by proto merges.
 */
export interface FeatureSetDefaults {
defaults: FeatureSetDefaults_FeatureSetEditionDefault[],
/**
 * The minimum supported edition (inclusive) when this was constructed.
 * Editions before this will not have defaults.
 */
minimum_edition?: Edition | null ,
/**
 * The maximum known edition (inclusive) when this was constructed. Editions
 * after this will not have reliable defaults.
 */
maximum_edition?: Edition | null ,
}

/**
 * A map from every known edition with a unique set of defaults to its
 * defaults. Not all editions may be contained here.  For a given edition,
 * the defaults at the closest matching edition ordered at or before it should
 * be used.  This field must be in strict ascending order by edition.
 */
export interface FeatureSetDefaults_FeatureSetEditionDefault {
edition?: Edition | null ,
/** Defaults of features that can be overridden in this edition. */
overridable_features?: FeatureSet | null ,
/** Defaults of features that can't be overridden in this edition. */
fixed_features?: FeatureSet | null ,
}

/**
 * Encapsulates information about the original source file from which a
 * FileDescriptorProto was generated.
 */
export interface SourceCodeInfo {
/**
 * A Location identifies a piece of source code in a .proto file which
 * corresponds to a particular definition.  This information is intended
 * to be useful to IDEs, code indexers, documentation generators, and similar
 * tools.
 * 
 * For example, say we have a file like:
 *   message Foo {
 *     optional string foo = 1;
 *   }
 * Let's look at just the field definition:
 *   optional string foo = 1;
 *   ^       ^^     ^^  ^  ^^^
 *   a       bc     de  f  ghi
 * We have the following locations:
 *   span   path               represents
 *   [a,i)  [ 4, 0, 2, 0 ]     The whole field definition.
 *   [a,b)  [ 4, 0, 2, 0, 4 ]  The label (optional).
 *   [c,d)  [ 4, 0, 2, 0, 5 ]  The type (string).
 *   [e,f)  [ 4, 0, 2, 0, 1 ]  The name (foo).
 *   [g,h)  [ 4, 0, 2, 0, 3 ]  The number (1).
 * 
 * Notes:
 * - A location may refer to a repeated field itself (i.e. not to any
 *   particular index within it).  This is used whenever a set of elements are
 *   logically enclosed in a single code segment.  For example, an entire
 *   extend block (possibly containing multiple extension definitions) will
 *   have an outer location whose path refers to the "extensions" repeated
 *   field without an index.
 * - Multiple locations may have the same path.  This happens when a single
 *   logical declaration is spread out across multiple places.  The most
 *   obvious example is the "extend" block again -- there may be multiple
 *   extend blocks in the same scope, each of which will have the same path.
 * - A location's span is not always a subset of its parent's span.  For
 *   example, the "extendee" of an extension declaration appears at the
 *   beginning of the "extend" block and is shared by all extensions within
 *   the block.
 * - Just because a location's span is a subset of some other location's span
 *   does not mean that it is a descendant.  For example, a "group" defines
 *   both a type and a field in a single declaration.  Thus, the locations
 *   corresponding to the type and field and their components will overlap.
 * - Code which tries to interpret locations should probably be designed to
 *   ignore those that it doesn't understand, as more types of locations could
 *   be recorded in the future.
 */
location: SourceCodeInfo_Location[],
}

export interface SourceCodeInfo_Location {
/**
 * Identifies which part of the FileDescriptorProto was defined at this
 * location.
 * 
 * Each element is a field number or an index.  They form a path from
 * the root FileDescriptorProto to the place where the definition appears.
 * For example, this path:
 *   [ 4, 3, 2, 7, 1 ]
 * refers to:
 *   file.message_type(3)  // 4, 3
 *       .field(7)         // 2, 7
 *       .name()           // 1
 * This is because FileDescriptorProto.message_type has field number 4:
 *   repeated DescriptorProto message_type = 4;
 * and DescriptorProto.field has field number 2:
 *   repeated FieldDescriptorProto field = 2;
 * and FieldDescriptorProto.name has field number 1:
 *   optional string name = 1;
 * 
 * Thus, the above path gives the location of a field name.  If we removed
 * the last element:
 *   [ 4, 3, 2, 7 ]
 * this path refers to the whole field declaration (from the beginning
 * of the label to the terminating semicolon).
 */
path: number[],
/**
 * Always has exactly three or four elements: start line, start column,
 * end line (optional, otherwise assumed same as start line), end column.
 * These are packed into a single field for efficiency.  Note that line
 * and column numbers are zero-based -- typically you will want to add
 * 1 to each before displaying to a user.
 */
span: number[],
/**
 * If this SourceCodeInfo represents a complete declaration, these are any
 * comments appearing before and after the declaration which appear to be
 * attached to the declaration.
 * 
 * A series of line comments appearing on consecutive lines, with no other
 * tokens appearing on those lines, will be treated as a single comment.
 * 
 * leading_detached_comments will keep paragraphs of comments that appear
 * before (but not connected to) the current element. Each paragraph,
 * separated by empty lines, will be one comment element in the repeated
 * field.
 * 
 * Only the comment content is provided; comment markers (e.g. //) are
 * stripped out.  For block comments, leading whitespace and an asterisk
 * will be stripped from the beginning of each line other than the first.
 * Newlines are included in the output.
 * 
 * Examples:
 * 
 *   optional int32 foo = 1;  // Comment attached to foo.
 *   // Comment attached to bar.
 *   optional int32 bar = 2;
 * 
 *   optional string baz = 3;
 *   // Comment attached to baz.
 *   // Another line attached to baz.
 * 
 *   // Comment attached to moo.
 *   //
 *   // Another line attached to moo.
 *   optional double moo = 4;
 * 
 *   // Detached comment for corge. This is not leading or trailing comments
 *   // to moo or corge because there are blank lines separating it from
 *   // both.
 * 
 *   // Detached comment for corge paragraph 2.
 * 
 *   optional string corge = 5;
 *   /* Block comment attached
 *    * to corge.  Leading asterisks
 *    * will be removed. * /
 *   /* Block comment attached to
 *    * grault. * /
 *   optional int32 grault = 6;
 * 
 *   // ignored detached comments.
 */
leading_comments?: string | null ,
trailing_comments?: string | null ,
leading_detached_comments: string[],
}

/**
 * Describes the relationship between generated code and its original source
 * file. A GeneratedCodeInfo message is associated with only one generated
 * source file, but may contain references to different source .proto files.
 */
export interface GeneratedCodeInfo {
/**
 * An Annotation connects some span of text in generated code to an element
 * of its generating .proto file.
 */
annotation: GeneratedCodeInfo_Annotation[],
}

export interface GeneratedCodeInfo_Annotation {
/**
 * Identifies the element in the original source .proto file. This field
 * is formatted the same as SourceCodeInfo.Location.path.
 */
path: number[],
/** Identifies the filesystem path to the original source .proto. */
source_file?: string | null ,
/**
 * Identifies the starting offset in bytes in the generated code
 * that relates to the identified object.
 */
begin?: number | null ,
/**
 * Identifies the ending offset in bytes in the generated code that
 * relates to the identified object. The end offset should be one past
 * the last relevant byte (so the length of the text = end - begin).
 */
end?: number | null ,
semantic?: GeneratedCodeInfo_Annotation_Semantic | null ,
}

/**
 * Represents the identified object's effect on the element in the original
 * .proto file.
 */
export const GeneratedCodeInfo_Annotation_Semantic = {
/** NONE - There is no effect or the effect is indescribable. */
NONE : "NONE",
/** SET - The element is set or otherwise mutated. */
SET : "SET",
/** ALIAS - An alias to the element is returned. */
ALIAS : "ALIAS",
} as const

export type GeneratedCodeInfo_Annotation_Semantic = typeof GeneratedCodeInfo_Annotation_Semantic[keyof typeof GeneratedCodeInfo_Annotation_Semantic]

export namespace GeneratedCodeInfo_Annotation_Semantic {
export type NONE = typeof GeneratedCodeInfo_Annotation_Semantic.NONE;
export type SET = typeof GeneratedCodeInfo_Annotation_Semantic.SET;
export type ALIAS = typeof GeneratedCodeInfo_Annotation_Semantic.ALIAS;
}

export function generatedCodeInfo_Annotation_SemanticFromJSON(object: any): GeneratedCodeInfo_Annotation_Semantic {
switch (object) {
case 0:
      case "NONE":
        return GeneratedCodeInfo_Annotation_Semantic.NONE;
case 1:
      case "SET":
        return GeneratedCodeInfo_Annotation_Semantic.SET;
case 2:
      case "ALIAS":
        return GeneratedCodeInfo_Annotation_Semantic.ALIAS;
default:
          return GeneratedCodeInfo_Annotation_Semantic.NONE;
}
}

export function generatedCodeInfo_Annotation_SemanticToJSON(object: GeneratedCodeInfo_Annotation_Semantic): string {
switch (object) {
case GeneratedCodeInfo_Annotation_Semantic.NONE: return "NONE";
case GeneratedCodeInfo_Annotation_Semantic.SET: return "SET";
case GeneratedCodeInfo_Annotation_Semantic.ALIAS: return "ALIAS";
default:
        return "NONE";
}
}

export function generatedCodeInfo_Annotation_SemanticToNumber(object: GeneratedCodeInfo_Annotation_Semantic): number {
switch (object) {
case GeneratedCodeInfo_Annotation_Semantic.NONE: return 0;
case GeneratedCodeInfo_Annotation_Semantic.SET: return 1;
case GeneratedCodeInfo_Annotation_Semantic.ALIAS: return 2;
default:
          return 0;
}
}

function createBaseFileDescriptorSet(): FileDescriptorSet {
      return { file: [] };
    }

export const FileDescriptorSet = {
              encode(
      message: FileDescriptorSet,
      writer: _m0.Writer = _m0.Writer.create(),
    ): _m0.Writer {
for (const v of message.file) {
            FileDescriptorProto.encode(v!, writer.uint32(10).fork()).ldelim();
          }
return writer;
},

decode(
      input: _m0.Reader | Uint8Array,
      length?: number,
    ): FileDescriptorSet {
      const reader = input instanceof _m0.Reader ? input : _m0.Reader.create(input);
      let end = length === undefined ? reader.len : reader.pos + length;
const message = createBaseFileDescriptorSet();
while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
case 1:
if (tag !== 10) {
        break;
      }
    
            
            message.file.push(FileDescriptorProto.decode(reader, reader.uint32()));
continue;
}
if ((tag & 7) === 4 || tag === 0) {
        break;
      }
reader.skipType(tag & 7);
}
return message;
},

// encodeTransform encodes a source of message objects.
    // Transform<FileDescriptorSet, Uint8Array>
    async *encodeTransform(
      source: AsyncIterable<FileDescriptorSet | FileDescriptorSet[]> | Iterable<FileDescriptorSet | FileDescriptorSet[]>
    ): AsyncIterable<Uint8Array> {
      for await (const pkt of source) {
        if (globalThis.Array.isArray(pkt)) {
          for (const p of (pkt as any)) {
            yield* [FileDescriptorSet.encode(p).finish()]
          }
        } else {
          yield* [FileDescriptorSet.encode(pkt as any).finish()]
        }
      }
    },

// decodeTransform decodes a source of encoded messages.
    // Transform<Uint8Array, FileDescriptorSet>
    async *decodeTransform(
      source: AsyncIterable<Uint8Array | Uint8Array[]> | Iterable<Uint8Array | Uint8Array[]>
    ): AsyncIterable<FileDescriptorSet> {
      for await (const pkt of source) {
        if (globalThis.Array.isArray(pkt)) {
          for (const p of (pkt as any)) {
            yield* [FileDescriptorSet.decode(p)]
          }
        } else {
          yield* [FileDescriptorSet.decode(pkt as any)]
        }
      }
    },

fromJSON(object: any): FileDescriptorSet {
      return {
file: globalThis.Array.isArray(object?.file) ? object.file.map((e: any) => FileDescriptorProto.fromJSON(e)): [],
};
},

toJSON(message: FileDescriptorSet): unknown {
      const obj: any = {};
if (message.file?.length) {
          obj.file = message.file.map(e => FileDescriptorProto.toJSON(e));
        }
return obj;
},

create<I extends Exact<DeepPartial<FileDescriptorSet>, I>>(base?: I): FileDescriptorSet {
        return FileDescriptorSet.fromPartial(base ?? ({} as any));
      },
fromPartial<I extends Exact<DeepPartial<FileDescriptorSet>, I>>(object: I): FileDescriptorSet {
const message = createBaseFileDescriptorSet();
message.file = object.file?.map((e) => FileDescriptorProto.fromPartial(e)) || [];
return message;
}
            };

function createBaseFileDescriptorProto(): FileDescriptorProto {
      return { name: "",package: "",dependency: [],public_dependency: [],weak_dependency: [],message_type: [],enum_type: [],service: [],extension: [],options: null,source_code_info: null,syntax: "",edition: Edition.UNKNOWN };
    }

export const FileDescriptorProto = {
              encode(
      message: FileDescriptorProto,
      writer: _m0.Writer = _m0.Writer.create(),
    ): _m0.Writer {
if (message.name !== undefined  && message.name !== null && message.name !== "") {
          writer.uint32(10).string(message.name);
        }
if (message.package !== undefined  && message.package !== null && message.package !== "") {
          writer.uint32(18).string(message.package);
        }
for (const v of message.dependency) {
            writer.uint32(26).string(v!);
          }
writer.uint32(82).fork();
          for (const v of message.public_dependency) {
            writer.int32(v);
          }
          writer.ldelim();
writer.uint32(90).fork();
          for (const v of message.weak_dependency) {
            writer.int32(v);
          }
          writer.ldelim();
for (const v of message.message_type) {
            DescriptorProto.encode(v!, writer.uint32(34).fork()).ldelim();
          }
for (const v of message.enum_type) {
            EnumDescriptorProto.encode(v!, writer.uint32(42).fork()).ldelim();
          }
for (const v of message.service) {
            ServiceDescriptorProto.encode(v!, writer.uint32(50).fork()).ldelim();
          }
for (const v of message.extension) {
            FieldDescriptorProto.encode(v!, writer.uint32(58).fork()).ldelim();
          }
if (message.options !== undefined  && message.options !== null) {
          FileOptions.encode(message.options, writer.uint32(66).fork()).ldelim();
        }
if (message.source_code_info !== undefined  && message.source_code_info !== null) {
          SourceCodeInfo.encode(message.source_code_info, writer.uint32(74).fork()).ldelim();
        }
if (message.syntax !== undefined  && message.syntax !== null && message.syntax !== "") {
          writer.uint32(98).string(message.syntax);
        }
if (message.edition !== undefined  && message.edition !== null && message.edition !== Edition.UNKNOWN) {
          writer.uint32(112).int32(editionToNumber(message.edition));
        }
return writer;
},

decode(
      input: _m0.Reader | Uint8Array,
      length?: number,
    ): FileDescriptorProto {
      const reader = input instanceof _m0.Reader ? input : _m0.Reader.create(input);
      let end = length === undefined ? reader.len : reader.pos + length;
const message = createBaseFileDescriptorProto();
while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
case 1:
if (tag !== 10) {
        break;
      }
    
        message.name = reader.string();
continue;
case 2:
if (tag !== 18) {
        break;
      }
    
        message.package = reader.string();
continue;
case 3:
if (tag !== 26) {
        break;
      }
    
            
            message.dependency.push(reader.string());
continue;
case 10:
if (tag === 80) {
              
              message.public_dependency.push(reader.int32());

              continue;
            }

            if (tag === 82) {
              
              const end2 = reader.uint32() + reader.pos;
              while (reader.pos < end2) {
                message.public_dependency.push(reader.int32());
              }

              continue;
            }

            break;
case 11:
if (tag === 88) {
              
              message.weak_dependency.push(reader.int32());

              continue;
            }

            if (tag === 90) {
              
              const end2 = reader.uint32() + reader.pos;
              while (reader.pos < end2) {
                message.weak_dependency.push(reader.int32());
              }

              continue;
            }

            break;
case 4:
if (tag !== 34) {
        break;
      }
    
            
            message.message_type.push(DescriptorProto.decode(reader, reader.uint32()));
continue;
case 5:
if (tag !== 42) {
        break;
      }
    
            
            message.enum_type.push(EnumDescriptorProto.decode(reader, reader.uint32()));
continue;
case 6:
if (tag !== 50) {
        break;
      }
    
            
            message.service.push(ServiceDescriptorProto.decode(reader, reader.uint32()));
continue;
case 7:
if (tag !== 58) {
        break;
      }
    
            
            message.extension.push(FieldDescriptorProto.decode(reader, reader.uint32()));
continue;
case 8:
if (tag !== 66) {
        break;
      }
    
        message.options = FileOptions.decode(reader, reader.uint32());
continue;
case 9:
if (tag !== 74) {
        break;
      }
    
        message.source_code_info = SourceCodeInfo.decode(reader, reader.uint32());
continue;
case 12:
if (tag !== 98) {
        break;
      }
    
        message.syntax = reader.string();
continue;
case 14:
if (tag !== 112) {
        break;
      }
    
        message.edition = editionFromJSON(reader.int32());
continue;
}
if ((tag & 7) === 4 || tag === 0) {
        break;
      }
reader.skipType(tag & 7);
}
return message;
},

// encodeTransform encodes a source of message objects.
    // Transform<FileDescriptorProto, Uint8Array>
    async *encodeTransform(
      source: AsyncIterable<FileDescriptorProto | FileDescriptorProto[]> | Iterable<FileDescriptorProto | FileDescriptorProto[]>
    ): AsyncIterable<Uint8Array> {
      for await (const pkt of source) {
        if (globalThis.Array.isArray(pkt)) {
          for (const p of (pkt as any)) {
            yield* [FileDescriptorProto.encode(p).finish()]
          }
        } else {
          yield* [FileDescriptorProto.encode(pkt as any).finish()]
        }
      }
    },

// decodeTransform decodes a source of encoded messages.
    // Transform<Uint8Array, FileDescriptorProto>
    async *decodeTransform(
      source: AsyncIterable<Uint8Array | Uint8Array[]> | Iterable<Uint8Array | Uint8Array[]>
    ): AsyncIterable<FileDescriptorProto> {
      for await (const pkt of source) {
        if (globalThis.Array.isArray(pkt)) {
          for (const p of (pkt as any)) {
            yield* [FileDescriptorProto.decode(p)]
          }
        } else {
          yield* [FileDescriptorProto.decode(pkt as any)]
        }
      }
    },

fromJSON(object: any): FileDescriptorProto {
      return {
name: isSet(object.name)
          ? globalThis.String(object.name)
          : "",
package: isSet(object.package)
          ? globalThis.String(object.package)
          : "",
dependency: globalThis.Array.isArray(object?.dependency) ? object.dependency.map((e: any) => globalThis.String(e)): [],
public_dependency: globalThis.Array.isArray(object?.public_dependency) ? object.public_dependency.map((e: any) => globalThis.Number(e)): [],
weak_dependency: globalThis.Array.isArray(object?.weak_dependency) ? object.weak_dependency.map((e: any) => globalThis.Number(e)): [],
message_type: globalThis.Array.isArray(object?.message_type) ? object.message_type.map((e: any) => DescriptorProto.fromJSON(e)): [],
enum_type: globalThis.Array.isArray(object?.enum_type) ? object.enum_type.map((e: any) => EnumDescriptorProto.fromJSON(e)): [],
service: globalThis.Array.isArray(object?.service) ? object.service.map((e: any) => ServiceDescriptorProto.fromJSON(e)): [],
extension: globalThis.Array.isArray(object?.extension) ? object.extension.map((e: any) => FieldDescriptorProto.fromJSON(e)): [],
options: isSet(object.options)
          ? FileOptions.fromJSON(object.options)
          : null ,
source_code_info: isSet(object.source_code_info)
          ? SourceCodeInfo.fromJSON(object.source_code_info)
          : null ,
syntax: isSet(object.syntax)
          ? globalThis.String(object.syntax)
          : "",
edition: isSet(object.edition)
          ? editionFromJSON(object.edition)
          : Edition.UNKNOWN,
};
},

toJSON(message: FileDescriptorProto): unknown {
      const obj: any = {};
if (message.name !== undefined  && message.name !== null && message.name !== "") {
          obj.name = message.name;
        }
if (message.package !== undefined  && message.package !== null && message.package !== "") {
          obj.package = message.package;
        }
if (message.dependency?.length) {
          obj.dependency = message.dependency;
        }
if (message.public_dependency?.length) {
          obj.public_dependency = message.public_dependency.map(e => Math.round(e));
        }
if (message.weak_dependency?.length) {
          obj.weak_dependency = message.weak_dependency.map(e => Math.round(e));
        }
if (message.message_type?.length) {
          obj.message_type = message.message_type.map(e => DescriptorProto.toJSON(e));
        }
if (message.enum_type?.length) {
          obj.enum_type = message.enum_type.map(e => EnumDescriptorProto.toJSON(e));
        }
if (message.service?.length) {
          obj.service = message.service.map(e => ServiceDescriptorProto.toJSON(e));
        }
if (message.extension?.length) {
          obj.extension = message.extension.map(e => FieldDescriptorProto.toJSON(e));
        }
if (message.options !== undefined  && message.options !== null) {
          obj.options = FileOptions.toJSON(message.options);
        }
if (message.source_code_info !== undefined  && message.source_code_info !== null) {
          obj.source_code_info = SourceCodeInfo.toJSON(message.source_code_info);
        }
if (message.syntax !== undefined  && message.syntax !== null && message.syntax !== "") {
          obj.syntax = message.syntax;
        }
if (message.edition !== undefined  && message.edition !== null && message.edition !== Edition.UNKNOWN) {
          obj.edition = editionToJSON(message.edition);
        }
return obj;
},

create<I extends Exact<DeepPartial<FileDescriptorProto>, I>>(base?: I): FileDescriptorProto {
        return FileDescriptorProto.fromPartial(base ?? ({} as any));
      },
fromPartial<I extends Exact<DeepPartial<FileDescriptorProto>, I>>(object: I): FileDescriptorProto {
const message = createBaseFileDescriptorProto();
message.name = object.name ?? "";
message.package = object.package ?? "";
message.dependency = object.dependency?.map((e) => e) || [];
message.public_dependency = object.public_dependency?.map((e) => e) || [];
message.weak_dependency = object.weak_dependency?.map((e) => e) || [];
message.message_type = object.message_type?.map((e) => DescriptorProto.fromPartial(e)) || [];
message.enum_type = object.enum_type?.map((e) => EnumDescriptorProto.fromPartial(e)) || [];
message.service = object.service?.map((e) => ServiceDescriptorProto.fromPartial(e)) || [];
message.extension = object.extension?.map((e) => FieldDescriptorProto.fromPartial(e)) || [];
message.options = (object.options !== undefined && object.options !== null)
          ? FileOptions.fromPartial(object.options)
          : null ;
message.source_code_info = (object.source_code_info !== undefined && object.source_code_info !== null)
          ? SourceCodeInfo.fromPartial(object.source_code_info)
          : null ;
message.syntax = object.syntax ?? "";
message.edition = object.edition ?? Edition.UNKNOWN;
return message;
}
            };

function createBaseDescriptorProto(): DescriptorProto {
      return { name: "",field: [],extension: [],nested_type: [],enum_type: [],extension_range: [],oneof_decl: [],options: null,reserved_range: [],reserved_name: [] };
    }

export const DescriptorProto = {
              encode(
      message: DescriptorProto,
      writer: _m0.Writer = _m0.Writer.create(),
    ): _m0.Writer {
if (message.name !== undefined  && message.name !== null && message.name !== "") {
          writer.uint32(10).string(message.name);
        }
for (const v of message.field) {
            FieldDescriptorProto.encode(v!, writer.uint32(18).fork()).ldelim();
          }
for (const v of message.extension) {
            FieldDescriptorProto.encode(v!, writer.uint32(50).fork()).ldelim();
          }
for (const v of message.nested_type) {
            DescriptorProto.encode(v!, writer.uint32(26).fork()).ldelim();
          }
for (const v of message.enum_type) {
            EnumDescriptorProto.encode(v!, writer.uint32(34).fork()).ldelim();
          }
for (const v of message.extension_range) {
            DescriptorProto_ExtensionRange.encode(v!, writer.uint32(42).fork()).ldelim();
          }
for (const v of message.oneof_decl) {
            OneofDescriptorProto.encode(v!, writer.uint32(66).fork()).ldelim();
          }
if (message.options !== undefined  && message.options !== null) {
          MessageOptions.encode(message.options, writer.uint32(58).fork()).ldelim();
        }
for (const v of message.reserved_range) {
            DescriptorProto_ReservedRange.encode(v!, writer.uint32(74).fork()).ldelim();
          }
for (const v of message.reserved_name) {
            writer.uint32(82).string(v!);
          }
return writer;
},

decode(
      input: _m0.Reader | Uint8Array,
      length?: number,
    ): DescriptorProto {
      const reader = input instanceof _m0.Reader ? input : _m0.Reader.create(input);
      let end = length === undefined ? reader.len : reader.pos + length;
const message = createBaseDescriptorProto();
while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
case 1:
if (tag !== 10) {
        break;
      }
    
        message.name = reader.string();
continue;
case 2:
if (tag !== 18) {
        break;
      }
    
            
            message.field.push(FieldDescriptorProto.decode(reader, reader.uint32()));
continue;
case 6:
if (tag !== 50) {
        break;
      }
    
            
            message.extension.push(FieldDescriptorProto.decode(reader, reader.uint32()));
continue;
case 3:
if (tag !== 26) {
        break;
      }
    
            
            message.nested_type.push(DescriptorProto.decode(reader, reader.uint32()));
continue;
case 4:
if (tag !== 34) {
        break;
      }
    
            
            message.enum_type.push(EnumDescriptorProto.decode(reader, reader.uint32()));
continue;
case 5:
if (tag !== 42) {
        break;
      }
    
            
            message.extension_range.push(DescriptorProto_ExtensionRange.decode(reader, reader.uint32()));
continue;
case 8:
if (tag !== 66) {
        break;
      }
    
            
            message.oneof_decl.push(OneofDescriptorProto.decode(reader, reader.uint32()));
continue;
case 7:
if (tag !== 58) {
        break;
      }
    
        message.options = MessageOptions.decode(reader, reader.uint32());
continue;
case 9:
if (tag !== 74) {
        break;
      }
    
            
            message.reserved_range.push(DescriptorProto_ReservedRange.decode(reader, reader.uint32()));
continue;
case 10:
if (tag !== 82) {
        break;
      }
    
            
            message.reserved_name.push(reader.string());
continue;
}
if ((tag & 7) === 4 || tag === 0) {
        break;
      }
reader.skipType(tag & 7);
}
return message;
},

// encodeTransform encodes a source of message objects.
    // Transform<DescriptorProto, Uint8Array>
    async *encodeTransform(
      source: AsyncIterable<DescriptorProto | DescriptorProto[]> | Iterable<DescriptorProto | DescriptorProto[]>
    ): AsyncIterable<Uint8Array> {
      for await (const pkt of source) {
        if (globalThis.Array.isArray(pkt)) {
          for (const p of (pkt as any)) {
            yield* [DescriptorProto.encode(p).finish()]
          }
        } else {
          yield* [DescriptorProto.encode(pkt as any).finish()]
        }
      }
    },

// decodeTransform decodes a source of encoded messages.
    // Transform<Uint8Array, DescriptorProto>
    async *decodeTransform(
      source: AsyncIterable<Uint8Array | Uint8Array[]> | Iterable<Uint8Array | Uint8Array[]>
    ): AsyncIterable<DescriptorProto> {
      for await (const pkt of source) {
        if (globalThis.Array.isArray(pkt)) {
          for (const p of (pkt as any)) {
            yield* [DescriptorProto.decode(p)]
          }
        } else {
          yield* [DescriptorProto.decode(pkt as any)]
        }
      }
    },

fromJSON(object: any): DescriptorProto {
      return {
name: isSet(object.name)
          ? globalThis.String(object.name)
          : "",
field: globalThis.Array.isArray(object?.field) ? object.field.map((e: any) => FieldDescriptorProto.fromJSON(e)): [],
extension: globalThis.Array.isArray(object?.extension) ? object.extension.map((e: any) => FieldDescriptorProto.fromJSON(e)): [],
nested_type: globalThis.Array.isArray(object?.nested_type) ? object.nested_type.map((e: any) => DescriptorProto.fromJSON(e)): [],
enum_type: globalThis.Array.isArray(object?.enum_type) ? object.enum_type.map((e: any) => EnumDescriptorProto.fromJSON(e)): [],
extension_range: globalThis.Array.isArray(object?.extension_range) ? object.extension_range.map((e: any) => DescriptorProto_ExtensionRange.fromJSON(e)): [],
oneof_decl: globalThis.Array.isArray(object?.oneof_decl) ? object.oneof_decl.map((e: any) => OneofDescriptorProto.fromJSON(e)): [],
options: isSet(object.options)
          ? MessageOptions.fromJSON(object.options)
          : null ,
reserved_range: globalThis.Array.isArray(object?.reserved_range) ? object.reserved_range.map((e: any) => DescriptorProto_ReservedRange.fromJSON(e)): [],
reserved_name: globalThis.Array.isArray(object?.reserved_name) ? object.reserved_name.map((e: any) => globalThis.String(e)): [],
};
},

toJSON(message: DescriptorProto): unknown {
      const obj: any = {};
if (message.name !== undefined  && message.name !== null && message.name !== "") {
          obj.name = message.name;
        }
if (message.field?.length) {
          obj.field = message.field.map(e => FieldDescriptorProto.toJSON(e));
        }
if (message.extension?.length) {
          obj.extension = message.extension.map(e => FieldDescriptorProto.toJSON(e));
        }
if (message.nested_type?.length) {
          obj.nested_type = message.nested_type.map(e => DescriptorProto.toJSON(e));
        }
if (message.enum_type?.length) {
          obj.enum_type = message.enum_type.map(e => EnumDescriptorProto.toJSON(e));
        }
if (message.extension_range?.length) {
          obj.extension_range = message.extension_range.map(e => DescriptorProto_ExtensionRange.toJSON(e));
        }
if (message.oneof_decl?.length) {
          obj.oneof_decl = message.oneof_decl.map(e => OneofDescriptorProto.toJSON(e));
        }
if (message.options !== undefined  && message.options !== null) {
          obj.options = MessageOptions.toJSON(message.options);
        }
if (message.reserved_range?.length) {
          obj.reserved_range = message.reserved_range.map(e => DescriptorProto_ReservedRange.toJSON(e));
        }
if (message.reserved_name?.length) {
          obj.reserved_name = message.reserved_name;
        }
return obj;
},

create<I extends Exact<DeepPartial<DescriptorProto>, I>>(base?: I): DescriptorProto {
        return DescriptorProto.fromPartial(base ?? ({} as any));
      },
fromPartial<I extends Exact<DeepPartial<DescriptorProto>, I>>(object: I): DescriptorProto {
const message = createBaseDescriptorProto();
message.name = object.name ?? "";
message.field = object.field?.map((e) => FieldDescriptorProto.fromPartial(e)) || [];
message.extension = object.extension?.map((e) => FieldDescriptorProto.fromPartial(e)) || [];
message.nested_type = object.nested_type?.map((e) => DescriptorProto.fromPartial(e)) || [];
message.enum_type = object.enum_type?.map((e) => EnumDescriptorProto.fromPartial(e)) || [];
message.extension_range = object.extension_range?.map((e) => DescriptorProto_ExtensionRange.fromPartial(e)) || [];
message.oneof_decl = object.oneof_decl?.map((e) => OneofDescriptorProto.fromPartial(e)) || [];
message.options = (object.options !== undefined && object.options !== null)
          ? MessageOptions.fromPartial(object.options)
          : null ;
message.reserved_range = object.reserved_range?.map((e) => DescriptorProto_ReservedRange.fromPartial(e)) || [];
message.reserved_name = object.reserved_name?.map((e) => e) || [];
return message;
}
            };

function createBaseDescriptorProto_ExtensionRange(): DescriptorProto_ExtensionRange {
      return { start: 0,end: 0,options: null };
    }

export const DescriptorProto_ExtensionRange = {
              encode(
      message: DescriptorProto_ExtensionRange,
      writer: _m0.Writer = _m0.Writer.create(),
    ): _m0.Writer {
if (message.start !== undefined  && message.start !== null && message.start !== 0) {
          writer.uint32(8).int32(message.start);
        }
if (message.end !== undefined  && message.end !== null && message.end !== 0) {
          writer.uint32(16).int32(message.end);
        }
if (message.options !== undefined  && message.options !== null) {
          ExtensionRangeOptions.encode(message.options, writer.uint32(26).fork()).ldelim();
        }
return writer;
},

decode(
      input: _m0.Reader | Uint8Array,
      length?: number,
    ): DescriptorProto_ExtensionRange {
      const reader = input instanceof _m0.Reader ? input : _m0.Reader.create(input);
      let end = length === undefined ? reader.len : reader.pos + length;
const message = createBaseDescriptorProto_ExtensionRange();
while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
case 1:
if (tag !== 8) {
        break;
      }
    
        message.start = reader.int32();
continue;
case 2:
if (tag !== 16) {
        break;
      }
    
        message.end = reader.int32();
continue;
case 3:
if (tag !== 26) {
        break;
      }
    
        message.options = ExtensionRangeOptions.decode(reader, reader.uint32());
continue;
}
if ((tag & 7) === 4 || tag === 0) {
        break;
      }
reader.skipType(tag & 7);
}
return message;
},

// encodeTransform encodes a source of message objects.
    // Transform<DescriptorProto_ExtensionRange, Uint8Array>
    async *encodeTransform(
      source: AsyncIterable<DescriptorProto_ExtensionRange | DescriptorProto_ExtensionRange[]> | Iterable<DescriptorProto_ExtensionRange | DescriptorProto_ExtensionRange[]>
    ): AsyncIterable<Uint8Array> {
      for await (const pkt of source) {
        if (globalThis.Array.isArray(pkt)) {
          for (const p of (pkt as any)) {
            yield* [DescriptorProto_ExtensionRange.encode(p).finish()]
          }
        } else {
          yield* [DescriptorProto_ExtensionRange.encode(pkt as any).finish()]
        }
      }
    },

// decodeTransform decodes a source of encoded messages.
    // Transform<Uint8Array, DescriptorProto_ExtensionRange>
    async *decodeTransform(
      source: AsyncIterable<Uint8Array | Uint8Array[]> | Iterable<Uint8Array | Uint8Array[]>
    ): AsyncIterable<DescriptorProto_ExtensionRange> {
      for await (const pkt of source) {
        if (globalThis.Array.isArray(pkt)) {
          for (const p of (pkt as any)) {
            yield* [DescriptorProto_ExtensionRange.decode(p)]
          }
        } else {
          yield* [DescriptorProto_ExtensionRange.decode(pkt as any)]
        }
      }
    },

fromJSON(object: any): DescriptorProto_ExtensionRange {
      return {
start: isSet(object.start)
          ? globalThis.Number(object.start)
          : 0,
end: isSet(object.end)
          ? globalThis.Number(object.end)
          : 0,
options: isSet(object.options)
          ? ExtensionRangeOptions.fromJSON(object.options)
          : null ,
};
},

toJSON(message: DescriptorProto_ExtensionRange): unknown {
      const obj: any = {};
if (message.start !== undefined  && message.start !== null && message.start !== 0) {
          obj.start = Math.round(message.start);
        }
if (message.end !== undefined  && message.end !== null && message.end !== 0) {
          obj.end = Math.round(message.end);
        }
if (message.options !== undefined  && message.options !== null) {
          obj.options = ExtensionRangeOptions.toJSON(message.options);
        }
return obj;
},

create<I extends Exact<DeepPartial<DescriptorProto_ExtensionRange>, I>>(base?: I): DescriptorProto_ExtensionRange {
        return DescriptorProto_ExtensionRange.fromPartial(base ?? ({} as any));
      },
fromPartial<I extends Exact<DeepPartial<DescriptorProto_ExtensionRange>, I>>(object: I): DescriptorProto_ExtensionRange {
const message = createBaseDescriptorProto_ExtensionRange();
message.start = object.start ?? 0;
message.end = object.end ?? 0;
message.options = (object.options !== undefined && object.options !== null)
          ? ExtensionRangeOptions.fromPartial(object.options)
          : null ;
return message;
}
            };

function createBaseDescriptorProto_ReservedRange(): DescriptorProto_ReservedRange {
      return { start: 0,end: 0 };
    }

export const DescriptorProto_ReservedRange = {
              encode(
      message: DescriptorProto_ReservedRange,
      writer: _m0.Writer = _m0.Writer.create(),
    ): _m0.Writer {
if (message.start !== undefined  && message.start !== null && message.start !== 0) {
          writer.uint32(8).int32(message.start);
        }
if (message.end !== undefined  && message.end !== null && message.end !== 0) {
          writer.uint32(16).int32(message.end);
        }
return writer;
},

decode(
      input: _m0.Reader | Uint8Array,
      length?: number,
    ): DescriptorProto_ReservedRange {
      const reader = input instanceof _m0.Reader ? input : _m0.Reader.create(input);
      let end = length === undefined ? reader.len : reader.pos + length;
const message = createBaseDescriptorProto_ReservedRange();
while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
case 1:
if (tag !== 8) {
        break;
      }
    
        message.start = reader.int32();
continue;
case 2:
if (tag !== 16) {
        break;
      }
    
        message.end = reader.int32();
continue;
}
if ((tag & 7) === 4 || tag === 0) {
        break;
      }
reader.skipType(tag & 7);
}
return message;
},

// encodeTransform encodes a source of message objects.
    // Transform<DescriptorProto_ReservedRange, Uint8Array>
    async *encodeTransform(
      source: AsyncIterable<DescriptorProto_ReservedRange | DescriptorProto_ReservedRange[]> | Iterable<DescriptorProto_ReservedRange | DescriptorProto_ReservedRange[]>
    ): AsyncIterable<Uint8Array> {
      for await (const pkt of source) {
        if (globalThis.Array.isArray(pkt)) {
          for (const p of (pkt as any)) {
            yield* [DescriptorProto_ReservedRange.encode(p).finish()]
          }
        } else {
          yield* [DescriptorProto_ReservedRange.encode(pkt as any).finish()]
        }
      }
    },

// decodeTransform decodes a source of encoded messages.
    // Transform<Uint8Array, DescriptorProto_ReservedRange>
    async *decodeTransform(
      source: AsyncIterable<Uint8Array | Uint8Array[]> | Iterable<Uint8Array | Uint8Array[]>
    ): AsyncIterable<DescriptorProto_ReservedRange> {
      for await (const pkt of source) {
        if (globalThis.Array.isArray(pkt)) {
          for (const p of (pkt as any)) {
            yield* [DescriptorProto_ReservedRange.decode(p)]
          }
        } else {
          yield* [DescriptorProto_ReservedRange.decode(pkt as any)]
        }
      }
    },

fromJSON(object: any): DescriptorProto_ReservedRange {
      return {
start: isSet(object.start)
          ? globalThis.Number(object.start)
          : 0,
end: isSet(object.end)
          ? globalThis.Number(object.end)
          : 0,
};
},

toJSON(message: DescriptorProto_ReservedRange): unknown {
      const obj: any = {};
if (message.start !== undefined  && message.start !== null && message.start !== 0) {
          obj.start = Math.round(message.start);
        }
if (message.end !== undefined  && message.end !== null && message.end !== 0) {
          obj.end = Math.round(message.end);
        }
return obj;
},

create<I extends Exact<DeepPartial<DescriptorProto_ReservedRange>, I>>(base?: I): DescriptorProto_ReservedRange {
        return DescriptorProto_ReservedRange.fromPartial(base ?? ({} as any));
      },
fromPartial<I extends Exact<DeepPartial<DescriptorProto_ReservedRange>, I>>(object: I): DescriptorProto_ReservedRange {
const message = createBaseDescriptorProto_ReservedRange();
message.start = object.start ?? 0;
message.end = object.end ?? 0;
return message;
}
            };

function createBaseExtensionRangeOptions(): ExtensionRangeOptions {
      return { uninterpreted_option: [],declaration: [],features: null,verification: ExtensionRangeOptions_VerificationState.UNVERIFIED };
    }

export const ExtensionRangeOptions = {
              encode(
      message: ExtensionRangeOptions,
      writer: _m0.Writer = _m0.Writer.create(),
    ): _m0.Writer {
for (const v of message.uninterpreted_option) {
            UninterpretedOption.encode(v!, writer.uint32(7994).fork()).ldelim();
          }
for (const v of message.declaration) {
            ExtensionRangeOptions_Declaration.encode(v!, writer.uint32(18).fork()).ldelim();
          }
if (message.features !== undefined  && message.features !== null) {
          FeatureSet.encode(message.features, writer.uint32(402).fork()).ldelim();
        }
if (message.verification !== undefined  && message.verification !== null && message.verification !== ExtensionRangeOptions_VerificationState.DECLARATION) {
          writer.uint32(24).int32(extensionRangeOptions_VerificationStateToNumber(message.verification));
        }
return writer;
},

decode(
      input: _m0.Reader | Uint8Array,
      length?: number,
    ): ExtensionRangeOptions {
      const reader = input instanceof _m0.Reader ? input : _m0.Reader.create(input);
      let end = length === undefined ? reader.len : reader.pos + length;
const message = createBaseExtensionRangeOptions();
while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
case 999:
if (tag !== 7994) {
        break;
      }
    
            
            message.uninterpreted_option.push(UninterpretedOption.decode(reader, reader.uint32()));
continue;
case 2:
if (tag !== 18) {
        break;
      }
    
            
            message.declaration.push(ExtensionRangeOptions_Declaration.decode(reader, reader.uint32()));
continue;
case 50:
if (tag !== 402) {
        break;
      }
    
        message.features = FeatureSet.decode(reader, reader.uint32());
continue;
case 3:
if (tag !== 24) {
        break;
      }
    
        message.verification = extensionRangeOptions_VerificationStateFromJSON(reader.int32());
continue;
}
if ((tag & 7) === 4 || tag === 0) {
        break;
      }
reader.skipType(tag & 7);
}
return message;
},

// encodeTransform encodes a source of message objects.
    // Transform<ExtensionRangeOptions, Uint8Array>
    async *encodeTransform(
      source: AsyncIterable<ExtensionRangeOptions | ExtensionRangeOptions[]> | Iterable<ExtensionRangeOptions | ExtensionRangeOptions[]>
    ): AsyncIterable<Uint8Array> {
      for await (const pkt of source) {
        if (globalThis.Array.isArray(pkt)) {
          for (const p of (pkt as any)) {
            yield* [ExtensionRangeOptions.encode(p).finish()]
          }
        } else {
          yield* [ExtensionRangeOptions.encode(pkt as any).finish()]
        }
      }
    },

// decodeTransform decodes a source of encoded messages.
    // Transform<Uint8Array, ExtensionRangeOptions>
    async *decodeTransform(
      source: AsyncIterable<Uint8Array | Uint8Array[]> | Iterable<Uint8Array | Uint8Array[]>
    ): AsyncIterable<ExtensionRangeOptions> {
      for await (const pkt of source) {
        if (globalThis.Array.isArray(pkt)) {
          for (const p of (pkt as any)) {
            yield* [ExtensionRangeOptions.decode(p)]
          }
        } else {
          yield* [ExtensionRangeOptions.decode(pkt as any)]
        }
      }
    },

fromJSON(object: any): ExtensionRangeOptions {
      return {
uninterpreted_option: globalThis.Array.isArray(object?.uninterpreted_option) ? object.uninterpreted_option.map((e: any) => UninterpretedOption.fromJSON(e)): [],
declaration: globalThis.Array.isArray(object?.declaration) ? object.declaration.map((e: any) => ExtensionRangeOptions_Declaration.fromJSON(e)): [],
features: isSet(object.features)
          ? FeatureSet.fromJSON(object.features)
          : null ,
verification: isSet(object.verification)
          ? extensionRangeOptions_VerificationStateFromJSON(object.verification)
          : ExtensionRangeOptions_VerificationState.UNVERIFIED,
};
},

toJSON(message: ExtensionRangeOptions): unknown {
      const obj: any = {};
if (message.uninterpreted_option?.length) {
          obj.uninterpreted_option = message.uninterpreted_option.map(e => UninterpretedOption.toJSON(e));
        }
if (message.declaration?.length) {
          obj.declaration = message.declaration.map(e => ExtensionRangeOptions_Declaration.toJSON(e));
        }
if (message.features !== undefined  && message.features !== null) {
          obj.features = FeatureSet.toJSON(message.features);
        }
if (message.verification !== undefined  && message.verification !== null && message.verification !== ExtensionRangeOptions_VerificationState.DECLARATION) {
          obj.verification = extensionRangeOptions_VerificationStateToJSON(message.verification);
        }
return obj;
},

create<I extends Exact<DeepPartial<ExtensionRangeOptions>, I>>(base?: I): ExtensionRangeOptions {
        return ExtensionRangeOptions.fromPartial(base ?? ({} as any));
      },
fromPartial<I extends Exact<DeepPartial<ExtensionRangeOptions>, I>>(object: I): ExtensionRangeOptions {
const message = createBaseExtensionRangeOptions();
message.uninterpreted_option = object.uninterpreted_option?.map((e) => UninterpretedOption.fromPartial(e)) || [];
message.declaration = object.declaration?.map((e) => ExtensionRangeOptions_Declaration.fromPartial(e)) || [];
message.features = (object.features !== undefined && object.features !== null)
          ? FeatureSet.fromPartial(object.features)
          : null ;
message.verification = object.verification ?? ExtensionRangeOptions_VerificationState.UNVERIFIED;
return message;
}
            };

function createBaseExtensionRangeOptions_Declaration(): ExtensionRangeOptions_Declaration {
      return { number: 0,full_name: "",type: "",reserved: false,repeated: false };
    }

export const ExtensionRangeOptions_Declaration = {
              encode(
      message: ExtensionRangeOptions_Declaration,
      writer: _m0.Writer = _m0.Writer.create(),
    ): _m0.Writer {
if (message.number !== undefined  && message.number !== null && message.number !== 0) {
          writer.uint32(8).int32(message.number);
        }
if (message.full_name !== undefined  && message.full_name !== null && message.full_name !== "") {
          writer.uint32(18).string(message.full_name);
        }
if (message.type !== undefined  && message.type !== null && message.type !== "") {
          writer.uint32(26).string(message.type);
        }
if (message.reserved !== undefined  && message.reserved !== null && message.reserved !== false) {
          writer.uint32(40).bool(message.reserved);
        }
if (message.repeated !== undefined  && message.repeated !== null && message.repeated !== false) {
          writer.uint32(48).bool(message.repeated);
        }
return writer;
},

decode(
      input: _m0.Reader | Uint8Array,
      length?: number,
    ): ExtensionRangeOptions_Declaration {
      const reader = input instanceof _m0.Reader ? input : _m0.Reader.create(input);
      let end = length === undefined ? reader.len : reader.pos + length;
const message = createBaseExtensionRangeOptions_Declaration();
while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
case 1:
if (tag !== 8) {
        break;
      }
    
        message.number = reader.int32();
continue;
case 2:
if (tag !== 18) {
        break;
      }
    
        message.full_name = reader.string();
continue;
case 3:
if (tag !== 26) {
        break;
      }
    
        message.type = reader.string();
continue;
case 5:
if (tag !== 40) {
        break;
      }
    
        message.reserved = reader.bool();
continue;
case 6:
if (tag !== 48) {
        break;
      }
    
        message.repeated = reader.bool();
continue;
}
if ((tag & 7) === 4 || tag === 0) {
        break;
      }
reader.skipType(tag & 7);
}
return message;
},

// encodeTransform encodes a source of message objects.
    // Transform<ExtensionRangeOptions_Declaration, Uint8Array>
    async *encodeTransform(
      source: AsyncIterable<ExtensionRangeOptions_Declaration | ExtensionRangeOptions_Declaration[]> | Iterable<ExtensionRangeOptions_Declaration | ExtensionRangeOptions_Declaration[]>
    ): AsyncIterable<Uint8Array> {
      for await (const pkt of source) {
        if (globalThis.Array.isArray(pkt)) {
          for (const p of (pkt as any)) {
            yield* [ExtensionRangeOptions_Declaration.encode(p).finish()]
          }
        } else {
          yield* [ExtensionRangeOptions_Declaration.encode(pkt as any).finish()]
        }
      }
    },

// decodeTransform decodes a source of encoded messages.
    // Transform<Uint8Array, ExtensionRangeOptions_Declaration>
    async *decodeTransform(
      source: AsyncIterable<Uint8Array | Uint8Array[]> | Iterable<Uint8Array | Uint8Array[]>
    ): AsyncIterable<ExtensionRangeOptions_Declaration> {
      for await (const pkt of source) {
        if (globalThis.Array.isArray(pkt)) {
          for (const p of (pkt as any)) {
            yield* [ExtensionRangeOptions_Declaration.decode(p)]
          }
        } else {
          yield* [ExtensionRangeOptions_Declaration.decode(pkt as any)]
        }
      }
    },

fromJSON(object: any): ExtensionRangeOptions_Declaration {
      return {
number: isSet(object.number)
          ? globalThis.Number(object.number)
          : 0,
full_name: isSet(object.full_name)
          ? globalThis.String(object.full_name)
          : "",
type: isSet(object.type)
          ? globalThis.String(object.type)
          : "",
reserved: isSet(object.reserved)
          ? globalThis.Boolean(object.reserved)
          : false,
repeated: isSet(object.repeated)
          ? globalThis.Boolean(object.repeated)
          : false,
};
},

toJSON(message: ExtensionRangeOptions_Declaration): unknown {
      const obj: any = {};
if (message.number !== undefined  && message.number !== null && message.number !== 0) {
          obj.number = Math.round(message.number);
        }
if (message.full_name !== undefined  && message.full_name !== null && message.full_name !== "") {
          obj.full_name = message.full_name;
        }
if (message.type !== undefined  && message.type !== null && message.type !== "") {
          obj.type = message.type;
        }
if (message.reserved !== undefined  && message.reserved !== null && message.reserved !== false) {
          obj.reserved = message.reserved;
        }
if (message.repeated !== undefined  && message.repeated !== null && message.repeated !== false) {
          obj.repeated = message.repeated;
        }
return obj;
},

create<I extends Exact<DeepPartial<ExtensionRangeOptions_Declaration>, I>>(base?: I): ExtensionRangeOptions_Declaration {
        return ExtensionRangeOptions_Declaration.fromPartial(base ?? ({} as any));
      },
fromPartial<I extends Exact<DeepPartial<ExtensionRangeOptions_Declaration>, I>>(object: I): ExtensionRangeOptions_Declaration {
const message = createBaseExtensionRangeOptions_Declaration();
message.number = object.number ?? 0;
message.full_name = object.full_name ?? "";
message.type = object.type ?? "";
message.reserved = object.reserved ?? false;
message.repeated = object.repeated ?? false;
return message;
}
            };

function createBaseFieldDescriptorProto(): FieldDescriptorProto {
      return { name: "",number: 0,label: FieldDescriptorProto_Label.OPTIONAL,type: FieldDescriptorProto_Type.DOUBLE,type_name: "",extendee: "",default_value: "",oneof_index: 0,json_name: "",options: null,proto3_optional: false };
    }

export const FieldDescriptorProto = {
              encode(
      message: FieldDescriptorProto,
      writer: _m0.Writer = _m0.Writer.create(),
    ): _m0.Writer {
if (message.name !== undefined  && message.name !== null && message.name !== "") {
          writer.uint32(10).string(message.name);
        }
if (message.number !== undefined  && message.number !== null && message.number !== 0) {
          writer.uint32(24).int32(message.number);
        }
if (message.label !== undefined  && message.label !== null && message.label !== FieldDescriptorProto_Label.OPTIONAL) {
          writer.uint32(32).int32(fieldDescriptorProto_LabelToNumber(message.label));
        }
if (message.type !== undefined  && message.type !== null && message.type !== FieldDescriptorProto_Type.DOUBLE) {
          writer.uint32(40).int32(fieldDescriptorProto_TypeToNumber(message.type));
        }
if (message.type_name !== undefined  && message.type_name !== null && message.type_name !== "") {
          writer.uint32(50).string(message.type_name);
        }
if (message.extendee !== undefined  && message.extendee !== null && message.extendee !== "") {
          writer.uint32(18).string(message.extendee);
        }
if (message.default_value !== undefined  && message.default_value !== null && message.default_value !== "") {
          writer.uint32(58).string(message.default_value);
        }
if (message.oneof_index !== undefined  && message.oneof_index !== null && message.oneof_index !== 0) {
          writer.uint32(72).int32(message.oneof_index);
        }
if (message.json_name !== undefined  && message.json_name !== null && message.json_name !== "") {
          writer.uint32(82).string(message.json_name);
        }
if (message.options !== undefined  && message.options !== null) {
          FieldOptions.encode(message.options, writer.uint32(66).fork()).ldelim();
        }
if (message.proto3_optional !== undefined  && message.proto3_optional !== null && message.proto3_optional !== false) {
          writer.uint32(136).bool(message.proto3_optional);
        }
return writer;
},

decode(
      input: _m0.Reader | Uint8Array,
      length?: number,
    ): FieldDescriptorProto {
      const reader = input instanceof _m0.Reader ? input : _m0.Reader.create(input);
      let end = length === undefined ? reader.len : reader.pos + length;
const message = createBaseFieldDescriptorProto();
while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
case 1:
if (tag !== 10) {
        break;
      }
    
        message.name = reader.string();
continue;
case 3:
if (tag !== 24) {
        break;
      }
    
        message.number = reader.int32();
continue;
case 4:
if (tag !== 32) {
        break;
      }
    
        message.label = fieldDescriptorProto_LabelFromJSON(reader.int32());
continue;
case 5:
if (tag !== 40) {
        break;
      }
    
        message.type = fieldDescriptorProto_TypeFromJSON(reader.int32());
continue;
case 6:
if (tag !== 50) {
        break;
      }
    
        message.type_name = reader.string();
continue;
case 2:
if (tag !== 18) {
        break;
      }
    
        message.extendee = reader.string();
continue;
case 7:
if (tag !== 58) {
        break;
      }
    
        message.default_value = reader.string();
continue;
case 9:
if (tag !== 72) {
        break;
      }
    
        message.oneof_index = reader.int32();
continue;
case 10:
if (tag !== 82) {
        break;
      }
    
        message.json_name = reader.string();
continue;
case 8:
if (tag !== 66) {
        break;
      }
    
        message.options = FieldOptions.decode(reader, reader.uint32());
continue;
case 17:
if (tag !== 136) {
        break;
      }
    
        message.proto3_optional = reader.bool();
continue;
}
if ((tag & 7) === 4 || tag === 0) {
        break;
      }
reader.skipType(tag & 7);
}
return message;
},

// encodeTransform encodes a source of message objects.
    // Transform<FieldDescriptorProto, Uint8Array>
    async *encodeTransform(
      source: AsyncIterable<FieldDescriptorProto | FieldDescriptorProto[]> | Iterable<FieldDescriptorProto | FieldDescriptorProto[]>
    ): AsyncIterable<Uint8Array> {
      for await (const pkt of source) {
        if (globalThis.Array.isArray(pkt)) {
          for (const p of (pkt as any)) {
            yield* [FieldDescriptorProto.encode(p).finish()]
          }
        } else {
          yield* [FieldDescriptorProto.encode(pkt as any).finish()]
        }
      }
    },

// decodeTransform decodes a source of encoded messages.
    // Transform<Uint8Array, FieldDescriptorProto>
    async *decodeTransform(
      source: AsyncIterable<Uint8Array | Uint8Array[]> | Iterable<Uint8Array | Uint8Array[]>
    ): AsyncIterable<FieldDescriptorProto> {
      for await (const pkt of source) {
        if (globalThis.Array.isArray(pkt)) {
          for (const p of (pkt as any)) {
            yield* [FieldDescriptorProto.decode(p)]
          }
        } else {
          yield* [FieldDescriptorProto.decode(pkt as any)]
        }
      }
    },

fromJSON(object: any): FieldDescriptorProto {
      return {
name: isSet(object.name)
          ? globalThis.String(object.name)
          : "",
number: isSet(object.number)
          ? globalThis.Number(object.number)
          : 0,
label: isSet(object.label)
          ? fieldDescriptorProto_LabelFromJSON(object.label)
          : FieldDescriptorProto_Label.OPTIONAL,
type: isSet(object.type)
          ? fieldDescriptorProto_TypeFromJSON(object.type)
          : FieldDescriptorProto_Type.DOUBLE,
type_name: isSet(object.type_name)
          ? globalThis.String(object.type_name)
          : "",
extendee: isSet(object.extendee)
          ? globalThis.String(object.extendee)
          : "",
default_value: isSet(object.default_value)
          ? globalThis.String(object.default_value)
          : "",
oneof_index: isSet(object.oneof_index)
          ? globalThis.Number(object.oneof_index)
          : 0,
json_name: isSet(object.json_name)
          ? globalThis.String(object.json_name)
          : "",
options: isSet(object.options)
          ? FieldOptions.fromJSON(object.options)
          : null ,
proto3_optional: isSet(object.proto3_optional)
          ? globalThis.Boolean(object.proto3_optional)
          : false,
};
},

toJSON(message: FieldDescriptorProto): unknown {
      const obj: any = {};
if (message.name !== undefined  && message.name !== null && message.name !== "") {
          obj.name = message.name;
        }
if (message.number !== undefined  && message.number !== null && message.number !== 0) {
          obj.number = Math.round(message.number);
        }
if (message.label !== undefined  && message.label !== null && message.label !== FieldDescriptorProto_Label.OPTIONAL) {
          obj.label = fieldDescriptorProto_LabelToJSON(message.label);
        }
if (message.type !== undefined  && message.type !== null && message.type !== FieldDescriptorProto_Type.DOUBLE) {
          obj.type = fieldDescriptorProto_TypeToJSON(message.type);
        }
if (message.type_name !== undefined  && message.type_name !== null && message.type_name !== "") {
          obj.type_name = message.type_name;
        }
if (message.extendee !== undefined  && message.extendee !== null && message.extendee !== "") {
          obj.extendee = message.extendee;
        }
if (message.default_value !== undefined  && message.default_value !== null && message.default_value !== "") {
          obj.default_value = message.default_value;
        }
if (message.oneof_index !== undefined  && message.oneof_index !== null && message.oneof_index !== 0) {
          obj.oneof_index = Math.round(message.oneof_index);
        }
if (message.json_name !== undefined  && message.json_name !== null && message.json_name !== "") {
          obj.json_name = message.json_name;
        }
if (message.options !== undefined  && message.options !== null) {
          obj.options = FieldOptions.toJSON(message.options);
        }
if (message.proto3_optional !== undefined  && message.proto3_optional !== null && message.proto3_optional !== false) {
          obj.proto3_optional = message.proto3_optional;
        }
return obj;
},

create<I extends Exact<DeepPartial<FieldDescriptorProto>, I>>(base?: I): FieldDescriptorProto {
        return FieldDescriptorProto.fromPartial(base ?? ({} as any));
      },
fromPartial<I extends Exact<DeepPartial<FieldDescriptorProto>, I>>(object: I): FieldDescriptorProto {
const message = createBaseFieldDescriptorProto();
message.name = object.name ?? "";
message.number = object.number ?? 0;
message.label = object.label ?? FieldDescriptorProto_Label.OPTIONAL;
message.type = object.type ?? FieldDescriptorProto_Type.DOUBLE;
message.type_name = object.type_name ?? "";
message.extendee = object.extendee ?? "";
message.default_value = object.default_value ?? "";
message.oneof_index = object.oneof_index ?? 0;
message.json_name = object.json_name ?? "";
message.options = (object.options !== undefined && object.options !== null)
          ? FieldOptions.fromPartial(object.options)
          : null ;
message.proto3_optional = object.proto3_optional ?? false;
return message;
}
            };

function createBaseOneofDescriptorProto(): OneofDescriptorProto {
      return { name: "",options: null };
    }

export const OneofDescriptorProto = {
              encode(
      message: OneofDescriptorProto,
      writer: _m0.Writer = _m0.Writer.create(),
    ): _m0.Writer {
if (message.name !== undefined  && message.name !== null && message.name !== "") {
          writer.uint32(10).string(message.name);
        }
if (message.options !== undefined  && message.options !== null) {
          OneofOptions.encode(message.options, writer.uint32(18).fork()).ldelim();
        }
return writer;
},

decode(
      input: _m0.Reader | Uint8Array,
      length?: number,
    ): OneofDescriptorProto {
      const reader = input instanceof _m0.Reader ? input : _m0.Reader.create(input);
      let end = length === undefined ? reader.len : reader.pos + length;
const message = createBaseOneofDescriptorProto();
while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
case 1:
if (tag !== 10) {
        break;
      }
    
        message.name = reader.string();
continue;
case 2:
if (tag !== 18) {
        break;
      }
    
        message.options = OneofOptions.decode(reader, reader.uint32());
continue;
}
if ((tag & 7) === 4 || tag === 0) {
        break;
      }
reader.skipType(tag & 7);
}
return message;
},

// encodeTransform encodes a source of message objects.
    // Transform<OneofDescriptorProto, Uint8Array>
    async *encodeTransform(
      source: AsyncIterable<OneofDescriptorProto | OneofDescriptorProto[]> | Iterable<OneofDescriptorProto | OneofDescriptorProto[]>
    ): AsyncIterable<Uint8Array> {
      for await (const pkt of source) {
        if (globalThis.Array.isArray(pkt)) {
          for (const p of (pkt as any)) {
            yield* [OneofDescriptorProto.encode(p).finish()]
          }
        } else {
          yield* [OneofDescriptorProto.encode(pkt as any).finish()]
        }
      }
    },

// decodeTransform decodes a source of encoded messages.
    // Transform<Uint8Array, OneofDescriptorProto>
    async *decodeTransform(
      source: AsyncIterable<Uint8Array | Uint8Array[]> | Iterable<Uint8Array | Uint8Array[]>
    ): AsyncIterable<OneofDescriptorProto> {
      for await (const pkt of source) {
        if (globalThis.Array.isArray(pkt)) {
          for (const p of (pkt as any)) {
            yield* [OneofDescriptorProto.decode(p)]
          }
        } else {
          yield* [OneofDescriptorProto.decode(pkt as any)]
        }
      }
    },

fromJSON(object: any): OneofDescriptorProto {
      return {
name: isSet(object.name)
          ? globalThis.String(object.name)
          : "",
options: isSet(object.options)
          ? OneofOptions.fromJSON(object.options)
          : null ,
};
},

toJSON(message: OneofDescriptorProto): unknown {
      const obj: any = {};
if (message.name !== undefined  && message.name !== null && message.name !== "") {
          obj.name = message.name;
        }
if (message.options !== undefined  && message.options !== null) {
          obj.options = OneofOptions.toJSON(message.options);
        }
return obj;
},

create<I extends Exact<DeepPartial<OneofDescriptorProto>, I>>(base?: I): OneofDescriptorProto {
        return OneofDescriptorProto.fromPartial(base ?? ({} as any));
      },
fromPartial<I extends Exact<DeepPartial<OneofDescriptorProto>, I>>(object: I): OneofDescriptorProto {
const message = createBaseOneofDescriptorProto();
message.name = object.name ?? "";
message.options = (object.options !== undefined && object.options !== null)
          ? OneofOptions.fromPartial(object.options)
          : null ;
return message;
}
            };

function createBaseEnumDescriptorProto(): EnumDescriptorProto {
      return { name: "",value: [],options: null,reserved_range: [],reserved_name: [] };
    }

export const EnumDescriptorProto = {
              encode(
      message: EnumDescriptorProto,
      writer: _m0.Writer = _m0.Writer.create(),
    ): _m0.Writer {
if (message.name !== undefined  && message.name !== null && message.name !== "") {
          writer.uint32(10).string(message.name);
        }
for (const v of message.value) {
            EnumValueDescriptorProto.encode(v!, writer.uint32(18).fork()).ldelim();
          }
if (message.options !== undefined  && message.options !== null) {
          EnumOptions.encode(message.options, writer.uint32(26).fork()).ldelim();
        }
for (const v of message.reserved_range) {
            EnumDescriptorProto_EnumReservedRange.encode(v!, writer.uint32(34).fork()).ldelim();
          }
for (const v of message.reserved_name) {
            writer.uint32(42).string(v!);
          }
return writer;
},

decode(
      input: _m0.Reader | Uint8Array,
      length?: number,
    ): EnumDescriptorProto {
      const reader = input instanceof _m0.Reader ? input : _m0.Reader.create(input);
      let end = length === undefined ? reader.len : reader.pos + length;
const message = createBaseEnumDescriptorProto();
while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
case 1:
if (tag !== 10) {
        break;
      }
    
        message.name = reader.string();
continue;
case 2:
if (tag !== 18) {
        break;
      }
    
            
            message.value.push(EnumValueDescriptorProto.decode(reader, reader.uint32()));
continue;
case 3:
if (tag !== 26) {
        break;
      }
    
        message.options = EnumOptions.decode(reader, reader.uint32());
continue;
case 4:
if (tag !== 34) {
        break;
      }
    
            
            message.reserved_range.push(EnumDescriptorProto_EnumReservedRange.decode(reader, reader.uint32()));
continue;
case 5:
if (tag !== 42) {
        break;
      }
    
            
            message.reserved_name.push(reader.string());
continue;
}
if ((tag & 7) === 4 || tag === 0) {
        break;
      }
reader.skipType(tag & 7);
}
return message;
},

// encodeTransform encodes a source of message objects.
    // Transform<EnumDescriptorProto, Uint8Array>
    async *encodeTransform(
      source: AsyncIterable<EnumDescriptorProto | EnumDescriptorProto[]> | Iterable<EnumDescriptorProto | EnumDescriptorProto[]>
    ): AsyncIterable<Uint8Array> {
      for await (const pkt of source) {
        if (globalThis.Array.isArray(pkt)) {
          for (const p of (pkt as any)) {
            yield* [EnumDescriptorProto.encode(p).finish()]
          }
        } else {
          yield* [EnumDescriptorProto.encode(pkt as any).finish()]
        }
      }
    },

// decodeTransform decodes a source of encoded messages.
    // Transform<Uint8Array, EnumDescriptorProto>
    async *decodeTransform(
      source: AsyncIterable<Uint8Array | Uint8Array[]> | Iterable<Uint8Array | Uint8Array[]>
    ): AsyncIterable<EnumDescriptorProto> {
      for await (const pkt of source) {
        if (globalThis.Array.isArray(pkt)) {
          for (const p of (pkt as any)) {
            yield* [EnumDescriptorProto.decode(p)]
          }
        } else {
          yield* [EnumDescriptorProto.decode(pkt as any)]
        }
      }
    },

fromJSON(object: any): EnumDescriptorProto {
      return {
name: isSet(object.name)
          ? globalThis.String(object.name)
          : "",
value: globalThis.Array.isArray(object?.value) ? object.value.map((e: any) => EnumValueDescriptorProto.fromJSON(e)): [],
options: isSet(object.options)
          ? EnumOptions.fromJSON(object.options)
          : null ,
reserved_range: globalThis.Array.isArray(object?.reserved_range) ? object.reserved_range.map((e: any) => EnumDescriptorProto_EnumReservedRange.fromJSON(e)): [],
reserved_name: globalThis.Array.isArray(object?.reserved_name) ? object.reserved_name.map((e: any) => globalThis.String(e)): [],
};
},

toJSON(message: EnumDescriptorProto): unknown {
      const obj: any = {};
if (message.name !== undefined  && message.name !== null && message.name !== "") {
          obj.name = message.name;
        }
if (message.value?.length) {
          obj.value = message.value.map(e => EnumValueDescriptorProto.toJSON(e));
        }
if (message.options !== undefined  && message.options !== null) {
          obj.options = EnumOptions.toJSON(message.options);
        }
if (message.reserved_range?.length) {
          obj.reserved_range = message.reserved_range.map(e => EnumDescriptorProto_EnumReservedRange.toJSON(e));
        }
if (message.reserved_name?.length) {
          obj.reserved_name = message.reserved_name;
        }
return obj;
},

create<I extends Exact<DeepPartial<EnumDescriptorProto>, I>>(base?: I): EnumDescriptorProto {
        return EnumDescriptorProto.fromPartial(base ?? ({} as any));
      },
fromPartial<I extends Exact<DeepPartial<EnumDescriptorProto>, I>>(object: I): EnumDescriptorProto {
const message = createBaseEnumDescriptorProto();
message.name = object.name ?? "";
message.value = object.value?.map((e) => EnumValueDescriptorProto.fromPartial(e)) || [];
message.options = (object.options !== undefined && object.options !== null)
          ? EnumOptions.fromPartial(object.options)
          : null ;
message.reserved_range = object.reserved_range?.map((e) => EnumDescriptorProto_EnumReservedRange.fromPartial(e)) || [];
message.reserved_name = object.reserved_name?.map((e) => e) || [];
return message;
}
            };

function createBaseEnumDescriptorProto_EnumReservedRange(): EnumDescriptorProto_EnumReservedRange {
      return { start: 0,end: 0 };
    }

export const EnumDescriptorProto_EnumReservedRange = {
              encode(
      message: EnumDescriptorProto_EnumReservedRange,
      writer: _m0.Writer = _m0.Writer.create(),
    ): _m0.Writer {
if (message.start !== undefined  && message.start !== null && message.start !== 0) {
          writer.uint32(8).int32(message.start);
        }
if (message.end !== undefined  && message.end !== null && message.end !== 0) {
          writer.uint32(16).int32(message.end);
        }
return writer;
},

decode(
      input: _m0.Reader | Uint8Array,
      length?: number,
    ): EnumDescriptorProto_EnumReservedRange {
      const reader = input instanceof _m0.Reader ? input : _m0.Reader.create(input);
      let end = length === undefined ? reader.len : reader.pos + length;
const message = createBaseEnumDescriptorProto_EnumReservedRange();
while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
case 1:
if (tag !== 8) {
        break;
      }
    
        message.start = reader.int32();
continue;
case 2:
if (tag !== 16) {
        break;
      }
    
        message.end = reader.int32();
continue;
}
if ((tag & 7) === 4 || tag === 0) {
        break;
      }
reader.skipType(tag & 7);
}
return message;
},

// encodeTransform encodes a source of message objects.
    // Transform<EnumDescriptorProto_EnumReservedRange, Uint8Array>
    async *encodeTransform(
      source: AsyncIterable<EnumDescriptorProto_EnumReservedRange | EnumDescriptorProto_EnumReservedRange[]> | Iterable<EnumDescriptorProto_EnumReservedRange | EnumDescriptorProto_EnumReservedRange[]>
    ): AsyncIterable<Uint8Array> {
      for await (const pkt of source) {
        if (globalThis.Array.isArray(pkt)) {
          for (const p of (pkt as any)) {
            yield* [EnumDescriptorProto_EnumReservedRange.encode(p).finish()]
          }
        } else {
          yield* [EnumDescriptorProto_EnumReservedRange.encode(pkt as any).finish()]
        }
      }
    },

// decodeTransform decodes a source of encoded messages.
    // Transform<Uint8Array, EnumDescriptorProto_EnumReservedRange>
    async *decodeTransform(
      source: AsyncIterable<Uint8Array | Uint8Array[]> | Iterable<Uint8Array | Uint8Array[]>
    ): AsyncIterable<EnumDescriptorProto_EnumReservedRange> {
      for await (const pkt of source) {
        if (globalThis.Array.isArray(pkt)) {
          for (const p of (pkt as any)) {
            yield* [EnumDescriptorProto_EnumReservedRange.decode(p)]
          }
        } else {
          yield* [EnumDescriptorProto_EnumReservedRange.decode(pkt as any)]
        }
      }
    },

fromJSON(object: any): EnumDescriptorProto_EnumReservedRange {
      return {
start: isSet(object.start)
          ? globalThis.Number(object.start)
          : 0,
end: isSet(object.end)
          ? globalThis.Number(object.end)
          : 0,
};
},

toJSON(message: EnumDescriptorProto_EnumReservedRange): unknown {
      const obj: any = {};
if (message.start !== undefined  && message.start !== null && message.start !== 0) {
          obj.start = Math.round(message.start);
        }
if (message.end !== undefined  && message.end !== null && message.end !== 0) {
          obj.end = Math.round(message.end);
        }
return obj;
},

create<I extends Exact<DeepPartial<EnumDescriptorProto_EnumReservedRange>, I>>(base?: I): EnumDescriptorProto_EnumReservedRange {
        return EnumDescriptorProto_EnumReservedRange.fromPartial(base ?? ({} as any));
      },
fromPartial<I extends Exact<DeepPartial<EnumDescriptorProto_EnumReservedRange>, I>>(object: I): EnumDescriptorProto_EnumReservedRange {
const message = createBaseEnumDescriptorProto_EnumReservedRange();
message.start = object.start ?? 0;
message.end = object.end ?? 0;
return message;
}
            };

function createBaseEnumValueDescriptorProto(): EnumValueDescriptorProto {
      return { name: "",number: 0,options: null };
    }

export const EnumValueDescriptorProto = {
              encode(
      message: EnumValueDescriptorProto,
      writer: _m0.Writer = _m0.Writer.create(),
    ): _m0.Writer {
if (message.name !== undefined  && message.name !== null && message.name !== "") {
          writer.uint32(10).string(message.name);
        }
if (message.number !== undefined  && message.number !== null && message.number !== 0) {
          writer.uint32(16).int32(message.number);
        }
if (message.options !== undefined  && message.options !== null) {
          EnumValueOptions.encode(message.options, writer.uint32(26).fork()).ldelim();
        }
return writer;
},

decode(
      input: _m0.Reader | Uint8Array,
      length?: number,
    ): EnumValueDescriptorProto {
      const reader = input instanceof _m0.Reader ? input : _m0.Reader.create(input);
      let end = length === undefined ? reader.len : reader.pos + length;
const message = createBaseEnumValueDescriptorProto();
while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
case 1:
if (tag !== 10) {
        break;
      }
    
        message.name = reader.string();
continue;
case 2:
if (tag !== 16) {
        break;
      }
    
        message.number = reader.int32();
continue;
case 3:
if (tag !== 26) {
        break;
      }
    
        message.options = EnumValueOptions.decode(reader, reader.uint32());
continue;
}
if ((tag & 7) === 4 || tag === 0) {
        break;
      }
reader.skipType(tag & 7);
}
return message;
},

// encodeTransform encodes a source of message objects.
    // Transform<EnumValueDescriptorProto, Uint8Array>
    async *encodeTransform(
      source: AsyncIterable<EnumValueDescriptorProto | EnumValueDescriptorProto[]> | Iterable<EnumValueDescriptorProto | EnumValueDescriptorProto[]>
    ): AsyncIterable<Uint8Array> {
      for await (const pkt of source) {
        if (globalThis.Array.isArray(pkt)) {
          for (const p of (pkt as any)) {
            yield* [EnumValueDescriptorProto.encode(p).finish()]
          }
        } else {
          yield* [EnumValueDescriptorProto.encode(pkt as any).finish()]
        }
      }
    },

// decodeTransform decodes a source of encoded messages.
    // Transform<Uint8Array, EnumValueDescriptorProto>
    async *decodeTransform(
      source: AsyncIterable<Uint8Array | Uint8Array[]> | Iterable<Uint8Array | Uint8Array[]>
    ): AsyncIterable<EnumValueDescriptorProto> {
      for await (const pkt of source) {
        if (globalThis.Array.isArray(pkt)) {
          for (const p of (pkt as any)) {
            yield* [EnumValueDescriptorProto.decode(p)]
          }
        } else {
          yield* [EnumValueDescriptorProto.decode(pkt as any)]
        }
      }
    },

fromJSON(object: any): EnumValueDescriptorProto {
      return {
name: isSet(object.name)
          ? globalThis.String(object.name)
          : "",
number: isSet(object.number)
          ? globalThis.Number(object.number)
          : 0,
options: isSet(object.options)
          ? EnumValueOptions.fromJSON(object.options)
          : null ,
};
},

toJSON(message: EnumValueDescriptorProto): unknown {
      const obj: any = {};
if (message.name !== undefined  && message.name !== null && message.name !== "") {
          obj.name = message.name;
        }
if (message.number !== undefined  && message.number !== null && message.number !== 0) {
          obj.number = Math.round(message.number);
        }
if (message.options !== undefined  && message.options !== null) {
          obj.options = EnumValueOptions.toJSON(message.options);
        }
return obj;
},

create<I extends Exact<DeepPartial<EnumValueDescriptorProto>, I>>(base?: I): EnumValueDescriptorProto {
        return EnumValueDescriptorProto.fromPartial(base ?? ({} as any));
      },
fromPartial<I extends Exact<DeepPartial<EnumValueDescriptorProto>, I>>(object: I): EnumValueDescriptorProto {
const message = createBaseEnumValueDescriptorProto();
message.name = object.name ?? "";
message.number = object.number ?? 0;
message.options = (object.options !== undefined && object.options !== null)
          ? EnumValueOptions.fromPartial(object.options)
          : null ;
return message;
}
            };

function createBaseServiceDescriptorProto(): ServiceDescriptorProto {
      return { name: "",method: [],options: null };
    }

export const ServiceDescriptorProto = {
              encode(
      message: ServiceDescriptorProto,
      writer: _m0.Writer = _m0.Writer.create(),
    ): _m0.Writer {
if (message.name !== undefined  && message.name !== null && message.name !== "") {
          writer.uint32(10).string(message.name);
        }
for (const v of message.method) {
            MethodDescriptorProto.encode(v!, writer.uint32(18).fork()).ldelim();
          }
if (message.options !== undefined  && message.options !== null) {
          ServiceOptions.encode(message.options, writer.uint32(26).fork()).ldelim();
        }
return writer;
},

decode(
      input: _m0.Reader | Uint8Array,
      length?: number,
    ): ServiceDescriptorProto {
      const reader = input instanceof _m0.Reader ? input : _m0.Reader.create(input);
      let end = length === undefined ? reader.len : reader.pos + length;
const message = createBaseServiceDescriptorProto();
while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
case 1:
if (tag !== 10) {
        break;
      }
    
        message.name = reader.string();
continue;
case 2:
if (tag !== 18) {
        break;
      }
    
            
            message.method.push(MethodDescriptorProto.decode(reader, reader.uint32()));
continue;
case 3:
if (tag !== 26) {
        break;
      }
    
        message.options = ServiceOptions.decode(reader, reader.uint32());
continue;
}
if ((tag & 7) === 4 || tag === 0) {
        break;
      }
reader.skipType(tag & 7);
}
return message;
},

// encodeTransform encodes a source of message objects.
    // Transform<ServiceDescriptorProto, Uint8Array>
    async *encodeTransform(
      source: AsyncIterable<ServiceDescriptorProto | ServiceDescriptorProto[]> | Iterable<ServiceDescriptorProto | ServiceDescriptorProto[]>
    ): AsyncIterable<Uint8Array> {
      for await (const pkt of source) {
        if (globalThis.Array.isArray(pkt)) {
          for (const p of (pkt as any)) {
            yield* [ServiceDescriptorProto.encode(p).finish()]
          }
        } else {
          yield* [ServiceDescriptorProto.encode(pkt as any).finish()]
        }
      }
    },

// decodeTransform decodes a source of encoded messages.
    // Transform<Uint8Array, ServiceDescriptorProto>
    async *decodeTransform(
      source: AsyncIterable<Uint8Array | Uint8Array[]> | Iterable<Uint8Array | Uint8Array[]>
    ): AsyncIterable<ServiceDescriptorProto> {
      for await (const pkt of source) {
        if (globalThis.Array.isArray(pkt)) {
          for (const p of (pkt as any)) {
            yield* [ServiceDescriptorProto.decode(p)]
          }
        } else {
          yield* [ServiceDescriptorProto.decode(pkt as any)]
        }
      }
    },

fromJSON(object: any): ServiceDescriptorProto {
      return {
name: isSet(object.name)
          ? globalThis.String(object.name)
          : "",
method: globalThis.Array.isArray(object?.method) ? object.method.map((e: any) => MethodDescriptorProto.fromJSON(e)): [],
options: isSet(object.options)
          ? ServiceOptions.fromJSON(object.options)
          : null ,
};
},

toJSON(message: ServiceDescriptorProto): unknown {
      const obj: any = {};
if (message.name !== undefined  && message.name !== null && message.name !== "") {
          obj.name = message.name;
        }
if (message.method?.length) {
          obj.method = message.method.map(e => MethodDescriptorProto.toJSON(e));
        }
if (message.options !== undefined  && message.options !== null) {
          obj.options = ServiceOptions.toJSON(message.options);
        }
return obj;
},

create<I extends Exact<DeepPartial<ServiceDescriptorProto>, I>>(base?: I): ServiceDescriptorProto {
        return ServiceDescriptorProto.fromPartial(base ?? ({} as any));
      },
fromPartial<I extends Exact<DeepPartial<ServiceDescriptorProto>, I>>(object: I): ServiceDescriptorProto {
const message = createBaseServiceDescriptorProto();
message.name = object.name ?? "";
message.method = object.method?.map((e) => MethodDescriptorProto.fromPartial(e)) || [];
message.options = (object.options !== undefined && object.options !== null)
          ? ServiceOptions.fromPartial(object.options)
          : null ;
return message;
}
            };

function createBaseMethodDescriptorProto(): MethodDescriptorProto {
      return { name: "",input_type: "",output_type: "",options: null,client_streaming: false,server_streaming: false };
    }

export const MethodDescriptorProto = {
              encode(
      message: MethodDescriptorProto,
      writer: _m0.Writer = _m0.Writer.create(),
    ): _m0.Writer {
if (message.name !== undefined  && message.name !== null && message.name !== "") {
          writer.uint32(10).string(message.name);
        }
if (message.input_type !== undefined  && message.input_type !== null && message.input_type !== "") {
          writer.uint32(18).string(message.input_type);
        }
if (message.output_type !== undefined  && message.output_type !== null && message.output_type !== "") {
          writer.uint32(26).string(message.output_type);
        }
if (message.options !== undefined  && message.options !== null) {
          MethodOptions.encode(message.options, writer.uint32(34).fork()).ldelim();
        }
if (message.client_streaming !== undefined  && message.client_streaming !== null && message.client_streaming !== false) {
          writer.uint32(40).bool(message.client_streaming);
        }
if (message.server_streaming !== undefined  && message.server_streaming !== null && message.server_streaming !== false) {
          writer.uint32(48).bool(message.server_streaming);
        }
return writer;
},

decode(
      input: _m0.Reader | Uint8Array,
      length?: number,
    ): MethodDescriptorProto {
      const reader = input instanceof _m0.Reader ? input : _m0.Reader.create(input);
      let end = length === undefined ? reader.len : reader.pos + length;
const message = createBaseMethodDescriptorProto();
while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
case 1:
if (tag !== 10) {
        break;
      }
    
        message.name = reader.string();
continue;
case 2:
if (tag !== 18) {
        break;
      }
    
        message.input_type = reader.string();
continue;
case 3:
if (tag !== 26) {
        break;
      }
    
        message.output_type = reader.string();
continue;
case 4:
if (tag !== 34) {
        break;
      }
    
        message.options = MethodOptions.decode(reader, reader.uint32());
continue;
case 5:
if (tag !== 40) {
        break;
      }
    
        message.client_streaming = reader.bool();
continue;
case 6:
if (tag !== 48) {
        break;
      }
    
        message.server_streaming = reader.bool();
continue;
}
if ((tag & 7) === 4 || tag === 0) {
        break;
      }
reader.skipType(tag & 7);
}
return message;
},

// encodeTransform encodes a source of message objects.
    // Transform<MethodDescriptorProto, Uint8Array>
    async *encodeTransform(
      source: AsyncIterable<MethodDescriptorProto | MethodDescriptorProto[]> | Iterable<MethodDescriptorProto | MethodDescriptorProto[]>
    ): AsyncIterable<Uint8Array> {
      for await (const pkt of source) {
        if (globalThis.Array.isArray(pkt)) {
          for (const p of (pkt as any)) {
            yield* [MethodDescriptorProto.encode(p).finish()]
          }
        } else {
          yield* [MethodDescriptorProto.encode(pkt as any).finish()]
        }
      }
    },

// decodeTransform decodes a source of encoded messages.
    // Transform<Uint8Array, MethodDescriptorProto>
    async *decodeTransform(
      source: AsyncIterable<Uint8Array | Uint8Array[]> | Iterable<Uint8Array | Uint8Array[]>
    ): AsyncIterable<MethodDescriptorProto> {
      for await (const pkt of source) {
        if (globalThis.Array.isArray(pkt)) {
          for (const p of (pkt as any)) {
            yield* [MethodDescriptorProto.decode(p)]
          }
        } else {
          yield* [MethodDescriptorProto.decode(pkt as any)]
        }
      }
    },

fromJSON(object: any): MethodDescriptorProto {
      return {
name: isSet(object.name)
          ? globalThis.String(object.name)
          : "",
input_type: isSet(object.input_type)
          ? globalThis.String(object.input_type)
          : "",
output_type: isSet(object.output_type)
          ? globalThis.String(object.output_type)
          : "",
options: isSet(object.options)
          ? MethodOptions.fromJSON(object.options)
          : null ,
client_streaming: isSet(object.client_streaming)
          ? globalThis.Boolean(object.client_streaming)
          : false,
server_streaming: isSet(object.server_streaming)
          ? globalThis.Boolean(object.server_streaming)
          : false,
};
},

toJSON(message: MethodDescriptorProto): unknown {
      const obj: any = {};
if (message.name !== undefined  && message.name !== null && message.name !== "") {
          obj.name = message.name;
        }
if (message.input_type !== undefined  && message.input_type !== null && message.input_type !== "") {
          obj.input_type = message.input_type;
        }
if (message.output_type !== undefined  && message.output_type !== null && message.output_type !== "") {
          obj.output_type = message.output_type;
        }
if (message.options !== undefined  && message.options !== null) {
          obj.options = MethodOptions.toJSON(message.options);
        }
if (message.client_streaming !== undefined  && message.client_streaming !== null && message.client_streaming !== false) {
          obj.client_streaming = message.client_streaming;
        }
if (message.server_streaming !== undefined  && message.server_streaming !== null && message.server_streaming !== false) {
          obj.server_streaming = message.server_streaming;
        }
return obj;
},

create<I extends Exact<DeepPartial<MethodDescriptorProto>, I>>(base?: I): MethodDescriptorProto {
        return MethodDescriptorProto.fromPartial(base ?? ({} as any));
      },
fromPartial<I extends Exact<DeepPartial<MethodDescriptorProto>, I>>(object: I): MethodDescriptorProto {
const message = createBaseMethodDescriptorProto();
message.name = object.name ?? "";
message.input_type = object.input_type ?? "";
message.output_type = object.output_type ?? "";
message.options = (object.options !== undefined && object.options !== null)
          ? MethodOptions.fromPartial(object.options)
          : null ;
message.client_streaming = object.client_streaming ?? false;
message.server_streaming = object.server_streaming ?? false;
return message;
}
            };

function createBaseFileOptions(): FileOptions {
      return { java_package: "",java_outer_classname: "",java_multiple_files: false,java_generate_equals_and_hash: false,java_string_check_utf8: false,optimize_for: FileOptions_OptimizeMode.SPEED,go_package: "",cc_generic_services: false,java_generic_services: false,py_generic_services: false,deprecated: false,cc_enable_arenas: true,objc_class_prefix: "",csharp_namespace: "",swift_prefix: "",php_class_prefix: "",php_namespace: "",php_metadata_namespace: "",ruby_package: "",features: null,uninterpreted_option: [] };
    }

export const FileOptions = {
              encode(
      message: FileOptions,
      writer: _m0.Writer = _m0.Writer.create(),
    ): _m0.Writer {
if (message.java_package !== undefined  && message.java_package !== null && message.java_package !== "") {
          writer.uint32(10).string(message.java_package);
        }
if (message.java_outer_classname !== undefined  && message.java_outer_classname !== null && message.java_outer_classname !== "") {
          writer.uint32(66).string(message.java_outer_classname);
        }
if (message.java_multiple_files !== undefined  && message.java_multiple_files !== null && message.java_multiple_files !== false) {
          writer.uint32(80).bool(message.java_multiple_files);
        }
if (message.java_generate_equals_and_hash !== undefined  && message.java_generate_equals_and_hash !== null && message.java_generate_equals_and_hash !== false) {
          writer.uint32(160).bool(message.java_generate_equals_and_hash);
        }
if (message.java_string_check_utf8 !== undefined  && message.java_string_check_utf8 !== null && message.java_string_check_utf8 !== false) {
          writer.uint32(216).bool(message.java_string_check_utf8);
        }
if (message.optimize_for !== undefined  && message.optimize_for !== null && message.optimize_for !== FileOptions_OptimizeMode.SPEED) {
          writer.uint32(72).int32(fileOptions_OptimizeModeToNumber(message.optimize_for));
        }
if (message.go_package !== undefined  && message.go_package !== null && message.go_package !== "") {
          writer.uint32(90).string(message.go_package);
        }
if (message.cc_generic_services !== undefined  && message.cc_generic_services !== null && message.cc_generic_services !== false) {
          writer.uint32(128).bool(message.cc_generic_services);
        }
if (message.java_generic_services !== undefined  && message.java_generic_services !== null && message.java_generic_services !== false) {
          writer.uint32(136).bool(message.java_generic_services);
        }
if (message.py_generic_services !== undefined  && message.py_generic_services !== null && message.py_generic_services !== false) {
          writer.uint32(144).bool(message.py_generic_services);
        }
if (message.deprecated !== undefined  && message.deprecated !== null && message.deprecated !== false) {
          writer.uint32(184).bool(message.deprecated);
        }
if (message.cc_enable_arenas !== undefined  && message.cc_enable_arenas !== null && message.cc_enable_arenas !== true) {
          writer.uint32(248).bool(message.cc_enable_arenas);
        }
if (message.objc_class_prefix !== undefined  && message.objc_class_prefix !== null && message.objc_class_prefix !== "") {
          writer.uint32(290).string(message.objc_class_prefix);
        }
if (message.csharp_namespace !== undefined  && message.csharp_namespace !== null && message.csharp_namespace !== "") {
          writer.uint32(298).string(message.csharp_namespace);
        }
if (message.swift_prefix !== undefined  && message.swift_prefix !== null && message.swift_prefix !== "") {
          writer.uint32(314).string(message.swift_prefix);
        }
if (message.php_class_prefix !== undefined  && message.php_class_prefix !== null && message.php_class_prefix !== "") {
          writer.uint32(322).string(message.php_class_prefix);
        }
if (message.php_namespace !== undefined  && message.php_namespace !== null && message.php_namespace !== "") {
          writer.uint32(330).string(message.php_namespace);
        }
if (message.php_metadata_namespace !== undefined  && message.php_metadata_namespace !== null && message.php_metadata_namespace !== "") {
          writer.uint32(354).string(message.php_metadata_namespace);
        }
if (message.ruby_package !== undefined  && message.ruby_package !== null && message.ruby_package !== "") {
          writer.uint32(362).string(message.ruby_package);
        }
if (message.features !== undefined  && message.features !== null) {
          FeatureSet.encode(message.features, writer.uint32(402).fork()).ldelim();
        }
for (const v of message.uninterpreted_option) {
            UninterpretedOption.encode(v!, writer.uint32(7994).fork()).ldelim();
          }
return writer;
},

decode(
      input: _m0.Reader | Uint8Array,
      length?: number,
    ): FileOptions {
      const reader = input instanceof _m0.Reader ? input : _m0.Reader.create(input);
      let end = length === undefined ? reader.len : reader.pos + length;
const message = createBaseFileOptions();
while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
case 1:
if (tag !== 10) {
        break;
      }
    
        message.java_package = reader.string();
continue;
case 8:
if (tag !== 66) {
        break;
      }
    
        message.java_outer_classname = reader.string();
continue;
case 10:
if (tag !== 80) {
        break;
      }
    
        message.java_multiple_files = reader.bool();
continue;
case 20:
if (tag !== 160) {
        break;
      }
    
        message.java_generate_equals_and_hash = reader.bool();
continue;
case 27:
if (tag !== 216) {
        break;
      }
    
        message.java_string_check_utf8 = reader.bool();
continue;
case 9:
if (tag !== 72) {
        break;
      }
    
        message.optimize_for = fileOptions_OptimizeModeFromJSON(reader.int32());
continue;
case 11:
if (tag !== 90) {
        break;
      }
    
        message.go_package = reader.string();
continue;
case 16:
if (tag !== 128) {
        break;
      }
    
        message.cc_generic_services = reader.bool();
continue;
case 17:
if (tag !== 136) {
        break;
      }
    
        message.java_generic_services = reader.bool();
continue;
case 18:
if (tag !== 144) {
        break;
      }
    
        message.py_generic_services = reader.bool();
continue;
case 23:
if (tag !== 184) {
        break;
      }
    
        message.deprecated = reader.bool();
continue;
case 31:
if (tag !== 248) {
        break;
      }
    
        message.cc_enable_arenas = reader.bool();
continue;
case 36:
if (tag !== 290) {
        break;
      }
    
        message.objc_class_prefix = reader.string();
continue;
case 37:
if (tag !== 298) {
        break;
      }
    
        message.csharp_namespace = reader.string();
continue;
case 39:
if (tag !== 314) {
        break;
      }
    
        message.swift_prefix = reader.string();
continue;
case 40:
if (tag !== 322) {
        break;
      }
    
        message.php_class_prefix = reader.string();
continue;
case 41:
if (tag !== 330) {
        break;
      }
    
        message.php_namespace = reader.string();
continue;
case 44:
if (tag !== 354) {
        break;
      }
    
        message.php_metadata_namespace = reader.string();
continue;
case 45:
if (tag !== 362) {
        break;
      }
    
        message.ruby_package = reader.string();
continue;
case 50:
if (tag !== 402) {
        break;
      }
    
        message.features = FeatureSet.decode(reader, reader.uint32());
continue;
case 999:
if (tag !== 7994) {
        break;
      }
    
            
            message.uninterpreted_option.push(UninterpretedOption.decode(reader, reader.uint32()));
continue;
}
if ((tag & 7) === 4 || tag === 0) {
        break;
      }
reader.skipType(tag & 7);
}
return message;
},

// encodeTransform encodes a source of message objects.
    // Transform<FileOptions, Uint8Array>
    async *encodeTransform(
      source: AsyncIterable<FileOptions | FileOptions[]> | Iterable<FileOptions | FileOptions[]>
    ): AsyncIterable<Uint8Array> {
      for await (const pkt of source) {
        if (globalThis.Array.isArray(pkt)) {
          for (const p of (pkt as any)) {
            yield* [FileOptions.encode(p).finish()]
          }
        } else {
          yield* [FileOptions.encode(pkt as any).finish()]
        }
      }
    },

// decodeTransform decodes a source of encoded messages.
    // Transform<Uint8Array, FileOptions>
    async *decodeTransform(
      source: AsyncIterable<Uint8Array | Uint8Array[]> | Iterable<Uint8Array | Uint8Array[]>
    ): AsyncIterable<FileOptions> {
      for await (const pkt of source) {
        if (globalThis.Array.isArray(pkt)) {
          for (const p of (pkt as any)) {
            yield* [FileOptions.decode(p)]
          }
        } else {
          yield* [FileOptions.decode(pkt as any)]
        }
      }
    },

fromJSON(object: any): FileOptions {
      return {
java_package: isSet(object.java_package)
          ? globalThis.String(object.java_package)
          : "",
java_outer_classname: isSet(object.java_outer_classname)
          ? globalThis.String(object.java_outer_classname)
          : "",
java_multiple_files: isSet(object.java_multiple_files)
          ? globalThis.Boolean(object.java_multiple_files)
          : false,
java_generate_equals_and_hash: isSet(object.java_generate_equals_and_hash)
          ? globalThis.Boolean(object.java_generate_equals_and_hash)
          : false,
java_string_check_utf8: isSet(object.java_string_check_utf8)
          ? globalThis.Boolean(object.java_string_check_utf8)
          : false,
optimize_for: isSet(object.optimize_for)
          ? fileOptions_OptimizeModeFromJSON(object.optimize_for)
          : FileOptions_OptimizeMode.SPEED,
go_package: isSet(object.go_package)
          ? globalThis.String(object.go_package)
          : "",
cc_generic_services: isSet(object.cc_generic_services)
          ? globalThis.Boolean(object.cc_generic_services)
          : false,
java_generic_services: isSet(object.java_generic_services)
          ? globalThis.Boolean(object.java_generic_services)
          : false,
py_generic_services: isSet(object.py_generic_services)
          ? globalThis.Boolean(object.py_generic_services)
          : false,
deprecated: isSet(object.deprecated)
          ? globalThis.Boolean(object.deprecated)
          : false,
cc_enable_arenas: isSet(object.cc_enable_arenas)
          ? globalThis.Boolean(object.cc_enable_arenas)
          : true,
objc_class_prefix: isSet(object.objc_class_prefix)
          ? globalThis.String(object.objc_class_prefix)
          : "",
csharp_namespace: isSet(object.csharp_namespace)
          ? globalThis.String(object.csharp_namespace)
          : "",
swift_prefix: isSet(object.swift_prefix)
          ? globalThis.String(object.swift_prefix)
          : "",
php_class_prefix: isSet(object.php_class_prefix)
          ? globalThis.String(object.php_class_prefix)
          : "",
php_namespace: isSet(object.php_namespace)
          ? globalThis.String(object.php_namespace)
          : "",
php_metadata_namespace: isSet(object.php_metadata_namespace)
          ? globalThis.String(object.php_metadata_namespace)
          : "",
ruby_package: isSet(object.ruby_package)
          ? globalThis.String(object.ruby_package)
          : "",
features: isSet(object.features)
          ? FeatureSet.fromJSON(object.features)
          : null ,
uninterpreted_option: globalThis.Array.isArray(object?.uninterpreted_option) ? object.uninterpreted_option.map((e: any) => UninterpretedOption.fromJSON(e)): [],
};
},

toJSON(message: FileOptions): unknown {
      const obj: any = {};
if (message.java_package !== undefined  && message.java_package !== null && message.java_package !== "") {
          obj.java_package = message.java_package;
        }
if (message.java_outer_classname !== undefined  && message.java_outer_classname !== null && message.java_outer_classname !== "") {
          obj.java_outer_classname = message.java_outer_classname;
        }
if (message.java_multiple_files !== undefined  && message.java_multiple_files !== null && message.java_multiple_files !== false) {
          obj.java_multiple_files = message.java_multiple_files;
        }
if (message.java_generate_equals_and_hash !== undefined  && message.java_generate_equals_and_hash !== null && message.java_generate_equals_and_hash !== false) {
          obj.java_generate_equals_and_hash = message.java_generate_equals_and_hash;
        }
if (message.java_string_check_utf8 !== undefined  && message.java_string_check_utf8 !== null && message.java_string_check_utf8 !== false) {
          obj.java_string_check_utf8 = message.java_string_check_utf8;
        }
if (message.optimize_for !== undefined  && message.optimize_for !== null && message.optimize_for !== FileOptions_OptimizeMode.SPEED) {
          obj.optimize_for = fileOptions_OptimizeModeToJSON(message.optimize_for);
        }
if (message.go_package !== undefined  && message.go_package !== null && message.go_package !== "") {
          obj.go_package = message.go_package;
        }
if (message.cc_generic_services !== undefined  && message.cc_generic_services !== null && message.cc_generic_services !== false) {
          obj.cc_generic_services = message.cc_generic_services;
        }
if (message.java_generic_services !== undefined  && message.java_generic_services !== null && message.java_generic_services !== false) {
          obj.java_generic_services = message.java_generic_services;
        }
if (message.py_generic_services !== undefined  && message.py_generic_services !== null && message.py_generic_services !== false) {
          obj.py_generic_services = message.py_generic_services;
        }
if (message.deprecated !== undefined  && message.deprecated !== null && message.deprecated !== false) {
          obj.deprecated = message.deprecated;
        }
if (message.cc_enable_arenas !== undefined  && message.cc_enable_arenas !== null && message.cc_enable_arenas !== true) {
          obj.cc_enable_arenas = message.cc_enable_arenas;
        }
if (message.objc_class_prefix !== undefined  && message.objc_class_prefix !== null && message.objc_class_prefix !== "") {
          obj.objc_class_prefix = message.objc_class_prefix;
        }
if (message.csharp_namespace !== undefined  && message.csharp_namespace !== null && message.csharp_namespace !== "") {
          obj.csharp_namespace = message.csharp_namespace;
        }
if (message.swift_prefix !== undefined  && message.swift_prefix !== null && message.swift_prefix !== "") {
          obj.swift_prefix = message.swift_prefix;
        }
if (message.php_class_prefix !== undefined  && message.php_class_prefix !== null && message.php_class_prefix !== "") {
          obj.php_class_prefix = message.php_class_prefix;
        }
if (message.php_namespace !== undefined  && message.php_namespace !== null && message.php_namespace !== "") {
          obj.php_namespace = message.php_namespace;
        }
if (message.php_metadata_namespace !== undefined  && message.php_metadata_namespace !== null && message.php_metadata_namespace !== "") {
          obj.php_metadata_namespace = message.php_metadata_namespace;
        }
if (message.ruby_package !== undefined  && message.ruby_package !== null && message.ruby_package !== "") {
          obj.ruby_package = message.ruby_package;
        }
if (message.features !== undefined  && message.features !== null) {
          obj.features = FeatureSet.toJSON(message.features);
        }
if (message.uninterpreted_option?.length) {
          obj.uninterpreted_option = message.uninterpreted_option.map(e => UninterpretedOption.toJSON(e));
        }
return obj;
},

create<I extends Exact<DeepPartial<FileOptions>, I>>(base?: I): FileOptions {
        return FileOptions.fromPartial(base ?? ({} as any));
      },
fromPartial<I extends Exact<DeepPartial<FileOptions>, I>>(object: I): FileOptions {
const message = createBaseFileOptions();
message.java_package = object.java_package ?? "";
message.java_outer_classname = object.java_outer_classname ?? "";
message.java_multiple_files = object.java_multiple_files ?? false;
message.java_generate_equals_and_hash = object.java_generate_equals_and_hash ?? false;
message.java_string_check_utf8 = object.java_string_check_utf8 ?? false;
message.optimize_for = object.optimize_for ?? FileOptions_OptimizeMode.SPEED;
message.go_package = object.go_package ?? "";
message.cc_generic_services = object.cc_generic_services ?? false;
message.java_generic_services = object.java_generic_services ?? false;
message.py_generic_services = object.py_generic_services ?? false;
message.deprecated = object.deprecated ?? false;
message.cc_enable_arenas = object.cc_enable_arenas ?? true;
message.objc_class_prefix = object.objc_class_prefix ?? "";
message.csharp_namespace = object.csharp_namespace ?? "";
message.swift_prefix = object.swift_prefix ?? "";
message.php_class_prefix = object.php_class_prefix ?? "";
message.php_namespace = object.php_namespace ?? "";
message.php_metadata_namespace = object.php_metadata_namespace ?? "";
message.ruby_package = object.ruby_package ?? "";
message.features = (object.features !== undefined && object.features !== null)
          ? FeatureSet.fromPartial(object.features)
          : null ;
message.uninterpreted_option = object.uninterpreted_option?.map((e) => UninterpretedOption.fromPartial(e)) || [];
return message;
}
            };

function createBaseMessageOptions(): MessageOptions {
      return { message_set_wire_format: false,no_standard_descriptor_accessor: false,deprecated: false,map_entry: false,deprecated_legacy_json_field_conflicts: false,features: null,uninterpreted_option: [] };
    }

export const MessageOptions = {
              encode(
      message: MessageOptions,
      writer: _m0.Writer = _m0.Writer.create(),
    ): _m0.Writer {
if (message.message_set_wire_format !== undefined  && message.message_set_wire_format !== null && message.message_set_wire_format !== false) {
          writer.uint32(8).bool(message.message_set_wire_format);
        }
if (message.no_standard_descriptor_accessor !== undefined  && message.no_standard_descriptor_accessor !== null && message.no_standard_descriptor_accessor !== false) {
          writer.uint32(16).bool(message.no_standard_descriptor_accessor);
        }
if (message.deprecated !== undefined  && message.deprecated !== null && message.deprecated !== false) {
          writer.uint32(24).bool(message.deprecated);
        }
if (message.map_entry !== undefined  && message.map_entry !== null && message.map_entry !== false) {
          writer.uint32(56).bool(message.map_entry);
        }
if (message.deprecated_legacy_json_field_conflicts !== undefined  && message.deprecated_legacy_json_field_conflicts !== null && message.deprecated_legacy_json_field_conflicts !== false) {
          writer.uint32(88).bool(message.deprecated_legacy_json_field_conflicts);
        }
if (message.features !== undefined  && message.features !== null) {
          FeatureSet.encode(message.features, writer.uint32(98).fork()).ldelim();
        }
for (const v of message.uninterpreted_option) {
            UninterpretedOption.encode(v!, writer.uint32(7994).fork()).ldelim();
          }
return writer;
},

decode(
      input: _m0.Reader | Uint8Array,
      length?: number,
    ): MessageOptions {
      const reader = input instanceof _m0.Reader ? input : _m0.Reader.create(input);
      let end = length === undefined ? reader.len : reader.pos + length;
const message = createBaseMessageOptions();
while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
case 1:
if (tag !== 8) {
        break;
      }
    
        message.message_set_wire_format = reader.bool();
continue;
case 2:
if (tag !== 16) {
        break;
      }
    
        message.no_standard_descriptor_accessor = reader.bool();
continue;
case 3:
if (tag !== 24) {
        break;
      }
    
        message.deprecated = reader.bool();
continue;
case 7:
if (tag !== 56) {
        break;
      }
    
        message.map_entry = reader.bool();
continue;
case 11:
if (tag !== 88) {
        break;
      }
    
        message.deprecated_legacy_json_field_conflicts = reader.bool();
continue;
case 12:
if (tag !== 98) {
        break;
      }
    
        message.features = FeatureSet.decode(reader, reader.uint32());
continue;
case 999:
if (tag !== 7994) {
        break;
      }
    
            
            message.uninterpreted_option.push(UninterpretedOption.decode(reader, reader.uint32()));
continue;
}
if ((tag & 7) === 4 || tag === 0) {
        break;
      }
reader.skipType(tag & 7);
}
return message;
},

// encodeTransform encodes a source of message objects.
    // Transform<MessageOptions, Uint8Array>
    async *encodeTransform(
      source: AsyncIterable<MessageOptions | MessageOptions[]> | Iterable<MessageOptions | MessageOptions[]>
    ): AsyncIterable<Uint8Array> {
      for await (const pkt of source) {
        if (globalThis.Array.isArray(pkt)) {
          for (const p of (pkt as any)) {
            yield* [MessageOptions.encode(p).finish()]
          }
        } else {
          yield* [MessageOptions.encode(pkt as any).finish()]
        }
      }
    },

// decodeTransform decodes a source of encoded messages.
    // Transform<Uint8Array, MessageOptions>
    async *decodeTransform(
      source: AsyncIterable<Uint8Array | Uint8Array[]> | Iterable<Uint8Array | Uint8Array[]>
    ): AsyncIterable<MessageOptions> {
      for await (const pkt of source) {
        if (globalThis.Array.isArray(pkt)) {
          for (const p of (pkt as any)) {
            yield* [MessageOptions.decode(p)]
          }
        } else {
          yield* [MessageOptions.decode(pkt as any)]
        }
      }
    },

fromJSON(object: any): MessageOptions {
      return {
message_set_wire_format: isSet(object.message_set_wire_format)
          ? globalThis.Boolean(object.message_set_wire_format)
          : false,
no_standard_descriptor_accessor: isSet(object.no_standard_descriptor_accessor)
          ? globalThis.Boolean(object.no_standard_descriptor_accessor)
          : false,
deprecated: isSet(object.deprecated)
          ? globalThis.Boolean(object.deprecated)
          : false,
map_entry: isSet(object.map_entry)
          ? globalThis.Boolean(object.map_entry)
          : false,
deprecated_legacy_json_field_conflicts: isSet(object.deprecated_legacy_json_field_conflicts)
          ? globalThis.Boolean(object.deprecated_legacy_json_field_conflicts)
          : false,
features: isSet(object.features)
          ? FeatureSet.fromJSON(object.features)
          : null ,
uninterpreted_option: globalThis.Array.isArray(object?.uninterpreted_option) ? object.uninterpreted_option.map((e: any) => UninterpretedOption.fromJSON(e)): [],
};
},

toJSON(message: MessageOptions): unknown {
      const obj: any = {};
if (message.message_set_wire_format !== undefined  && message.message_set_wire_format !== null && message.message_set_wire_format !== false) {
          obj.message_set_wire_format = message.message_set_wire_format;
        }
if (message.no_standard_descriptor_accessor !== undefined  && message.no_standard_descriptor_accessor !== null && message.no_standard_descriptor_accessor !== false) {
          obj.no_standard_descriptor_accessor = message.no_standard_descriptor_accessor;
        }
if (message.deprecated !== undefined  && message.deprecated !== null && message.deprecated !== false) {
          obj.deprecated = message.deprecated;
        }
if (message.map_entry !== undefined  && message.map_entry !== null && message.map_entry !== false) {
          obj.map_entry = message.map_entry;
        }
if (message.deprecated_legacy_json_field_conflicts !== undefined  && message.deprecated_legacy_json_field_conflicts !== null && message.deprecated_legacy_json_field_conflicts !== false) {
          obj.deprecated_legacy_json_field_conflicts = message.deprecated_legacy_json_field_conflicts;
        }
if (message.features !== undefined  && message.features !== null) {
          obj.features = FeatureSet.toJSON(message.features);
        }
if (message.uninterpreted_option?.length) {
          obj.uninterpreted_option = message.uninterpreted_option.map(e => UninterpretedOption.toJSON(e));
        }
return obj;
},

create<I extends Exact<DeepPartial<MessageOptions>, I>>(base?: I): MessageOptions {
        return MessageOptions.fromPartial(base ?? ({} as any));
      },
fromPartial<I extends Exact<DeepPartial<MessageOptions>, I>>(object: I): MessageOptions {
const message = createBaseMessageOptions();
message.message_set_wire_format = object.message_set_wire_format ?? false;
message.no_standard_descriptor_accessor = object.no_standard_descriptor_accessor ?? false;
message.deprecated = object.deprecated ?? false;
message.map_entry = object.map_entry ?? false;
message.deprecated_legacy_json_field_conflicts = object.deprecated_legacy_json_field_conflicts ?? false;
message.features = (object.features !== undefined && object.features !== null)
          ? FeatureSet.fromPartial(object.features)
          : null ;
message.uninterpreted_option = object.uninterpreted_option?.map((e) => UninterpretedOption.fromPartial(e)) || [];
return message;
}
            };

function createBaseFieldOptions(): FieldOptions {
      return { ctype: FieldOptions_CType.STRING,packed: false,jstype: FieldOptions_JSType.JS_NORMAL,lazy: false,unverified_lazy: false,deprecated: false,weak: false,debug_redact: false,retention: FieldOptions_OptionRetention.RETENTION_UNKNOWN,targets: [],edition_defaults: [],features: null,feature_support: null,uninterpreted_option: [] };
    }

export const FieldOptions = {
              encode(
      message: FieldOptions,
      writer: _m0.Writer = _m0.Writer.create(),
    ): _m0.Writer {
if (message.ctype !== undefined  && message.ctype !== null && message.ctype !== FieldOptions_CType.STRING) {
          writer.uint32(8).int32(fieldOptions_CTypeToNumber(message.ctype));
        }
if (message.packed !== undefined  && message.packed !== null && message.packed !== false) {
          writer.uint32(16).bool(message.packed);
        }
if (message.jstype !== undefined  && message.jstype !== null && message.jstype !== FieldOptions_JSType.JS_NORMAL) {
          writer.uint32(48).int32(fieldOptions_JSTypeToNumber(message.jstype));
        }
if (message.lazy !== undefined  && message.lazy !== null && message.lazy !== false) {
          writer.uint32(40).bool(message.lazy);
        }
if (message.unverified_lazy !== undefined  && message.unverified_lazy !== null && message.unverified_lazy !== false) {
          writer.uint32(120).bool(message.unverified_lazy);
        }
if (message.deprecated !== undefined  && message.deprecated !== null && message.deprecated !== false) {
          writer.uint32(24).bool(message.deprecated);
        }
if (message.weak !== undefined  && message.weak !== null && message.weak !== false) {
          writer.uint32(80).bool(message.weak);
        }
if (message.debug_redact !== undefined  && message.debug_redact !== null && message.debug_redact !== false) {
          writer.uint32(128).bool(message.debug_redact);
        }
if (message.retention !== undefined  && message.retention !== null && message.retention !== FieldOptions_OptionRetention.RETENTION_UNKNOWN) {
          writer.uint32(136).int32(fieldOptions_OptionRetentionToNumber(message.retention));
        }
writer.uint32(154).fork();
          for (const v of message.targets) {
            writer.int32(fieldOptions_OptionTargetTypeToNumber(v));
          }
          writer.ldelim();
for (const v of message.edition_defaults) {
            FieldOptions_EditionDefault.encode(v!, writer.uint32(162).fork()).ldelim();
          }
if (message.features !== undefined  && message.features !== null) {
          FeatureSet.encode(message.features, writer.uint32(170).fork()).ldelim();
        }
if (message.feature_support !== undefined  && message.feature_support !== null) {
          FieldOptions_FeatureSupport.encode(message.feature_support, writer.uint32(178).fork()).ldelim();
        }
for (const v of message.uninterpreted_option) {
            UninterpretedOption.encode(v!, writer.uint32(7994).fork()).ldelim();
          }
return writer;
},

decode(
      input: _m0.Reader | Uint8Array,
      length?: number,
    ): FieldOptions {
      const reader = input instanceof _m0.Reader ? input : _m0.Reader.create(input);
      let end = length === undefined ? reader.len : reader.pos + length;
const message = createBaseFieldOptions();
while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
case 1:
if (tag !== 8) {
        break;
      }
    
        message.ctype = fieldOptions_CTypeFromJSON(reader.int32());
continue;
case 2:
if (tag !== 16) {
        break;
      }
    
        message.packed = reader.bool();
continue;
case 6:
if (tag !== 48) {
        break;
      }
    
        message.jstype = fieldOptions_JSTypeFromJSON(reader.int32());
continue;
case 5:
if (tag !== 40) {
        break;
      }
    
        message.lazy = reader.bool();
continue;
case 15:
if (tag !== 120) {
        break;
      }
    
        message.unverified_lazy = reader.bool();
continue;
case 3:
if (tag !== 24) {
        break;
      }
    
        message.deprecated = reader.bool();
continue;
case 10:
if (tag !== 80) {
        break;
      }
    
        message.weak = reader.bool();
continue;
case 16:
if (tag !== 128) {
        break;
      }
    
        message.debug_redact = reader.bool();
continue;
case 17:
if (tag !== 136) {
        break;
      }
    
        message.retention = fieldOptions_OptionRetentionFromJSON(reader.int32());
continue;
case 19:
if (tag === 152) {
              
              message.targets.push(fieldOptions_OptionTargetTypeFromJSON(reader.int32()));

              continue;
            }

            if (tag === 154) {
              
              const end2 = reader.uint32() + reader.pos;
              while (reader.pos < end2) {
                message.targets.push(fieldOptions_OptionTargetTypeFromJSON(reader.int32()));
              }

              continue;
            }

            break;
case 20:
if (tag !== 162) {
        break;
      }
    
            
            message.edition_defaults.push(FieldOptions_EditionDefault.decode(reader, reader.uint32()));
continue;
case 21:
if (tag !== 170) {
        break;
      }
    
        message.features = FeatureSet.decode(reader, reader.uint32());
continue;
case 22:
if (tag !== 178) {
        break;
      }
    
        message.feature_support = FieldOptions_FeatureSupport.decode(reader, reader.uint32());
continue;
case 999:
if (tag !== 7994) {
        break;
      }
    
            
            message.uninterpreted_option.push(UninterpretedOption.decode(reader, reader.uint32()));
continue;
}
if ((tag & 7) === 4 || tag === 0) {
        break;
      }
reader.skipType(tag & 7);
}
return message;
},

// encodeTransform encodes a source of message objects.
    // Transform<FieldOptions, Uint8Array>
    async *encodeTransform(
      source: AsyncIterable<FieldOptions | FieldOptions[]> | Iterable<FieldOptions | FieldOptions[]>
    ): AsyncIterable<Uint8Array> {
      for await (const pkt of source) {
        if (globalThis.Array.isArray(pkt)) {
          for (const p of (pkt as any)) {
            yield* [FieldOptions.encode(p).finish()]
          }
        } else {
          yield* [FieldOptions.encode(pkt as any).finish()]
        }
      }
    },

// decodeTransform decodes a source of encoded messages.
    // Transform<Uint8Array, FieldOptions>
    async *decodeTransform(
      source: AsyncIterable<Uint8Array | Uint8Array[]> | Iterable<Uint8Array | Uint8Array[]>
    ): AsyncIterable<FieldOptions> {
      for await (const pkt of source) {
        if (globalThis.Array.isArray(pkt)) {
          for (const p of (pkt as any)) {
            yield* [FieldOptions.decode(p)]
          }
        } else {
          yield* [FieldOptions.decode(pkt as any)]
        }
      }
    },

fromJSON(object: any): FieldOptions {
      return {
ctype: isSet(object.ctype)
          ? fieldOptions_CTypeFromJSON(object.ctype)
          : FieldOptions_CType.STRING,
packed: isSet(object.packed)
          ? globalThis.Boolean(object.packed)
          : false,
jstype: isSet(object.jstype)
          ? fieldOptions_JSTypeFromJSON(object.jstype)
          : FieldOptions_JSType.JS_NORMAL,
lazy: isSet(object.lazy)
          ? globalThis.Boolean(object.lazy)
          : false,
unverified_lazy: isSet(object.unverified_lazy)
          ? globalThis.Boolean(object.unverified_lazy)
          : false,
deprecated: isSet(object.deprecated)
          ? globalThis.Boolean(object.deprecated)
          : false,
weak: isSet(object.weak)
          ? globalThis.Boolean(object.weak)
          : false,
debug_redact: isSet(object.debug_redact)
          ? globalThis.Boolean(object.debug_redact)
          : false,
retention: isSet(object.retention)
          ? fieldOptions_OptionRetentionFromJSON(object.retention)
          : FieldOptions_OptionRetention.RETENTION_UNKNOWN,
targets: globalThis.Array.isArray(object?.targets) ? object.targets.map((e: any) => fieldOptions_OptionTargetTypeFromJSON(e)): [],
edition_defaults: globalThis.Array.isArray(object?.edition_defaults) ? object.edition_defaults.map((e: any) => FieldOptions_EditionDefault.fromJSON(e)): [],
features: isSet(object.features)
          ? FeatureSet.fromJSON(object.features)
          : null ,
feature_support: isSet(object.feature_support)
          ? FieldOptions_FeatureSupport.fromJSON(object.feature_support)
          : null ,
uninterpreted_option: globalThis.Array.isArray(object?.uninterpreted_option) ? object.uninterpreted_option.map((e: any) => UninterpretedOption.fromJSON(e)): [],
};
},

toJSON(message: FieldOptions): unknown {
      const obj: any = {};
if (message.ctype !== undefined  && message.ctype !== null && message.ctype !== FieldOptions_CType.STRING) {
          obj.ctype = fieldOptions_CTypeToJSON(message.ctype);
        }
if (message.packed !== undefined  && message.packed !== null && message.packed !== false) {
          obj.packed = message.packed;
        }
if (message.jstype !== undefined  && message.jstype !== null && message.jstype !== FieldOptions_JSType.JS_NORMAL) {
          obj.jstype = fieldOptions_JSTypeToJSON(message.jstype);
        }
if (message.lazy !== undefined  && message.lazy !== null && message.lazy !== false) {
          obj.lazy = message.lazy;
        }
if (message.unverified_lazy !== undefined  && message.unverified_lazy !== null && message.unverified_lazy !== false) {
          obj.unverified_lazy = message.unverified_lazy;
        }
if (message.deprecated !== undefined  && message.deprecated !== null && message.deprecated !== false) {
          obj.deprecated = message.deprecated;
        }
if (message.weak !== undefined  && message.weak !== null && message.weak !== false) {
          obj.weak = message.weak;
        }
if (message.debug_redact !== undefined  && message.debug_redact !== null && message.debug_redact !== false) {
          obj.debug_redact = message.debug_redact;
        }
if (message.retention !== undefined  && message.retention !== null && message.retention !== FieldOptions_OptionRetention.RETENTION_UNKNOWN) {
          obj.retention = fieldOptions_OptionRetentionToJSON(message.retention);
        }
if (message.targets?.length) {
          obj.targets = message.targets.map(e => fieldOptions_OptionTargetTypeToJSON(e));
        }
if (message.edition_defaults?.length) {
          obj.edition_defaults = message.edition_defaults.map(e => FieldOptions_EditionDefault.toJSON(e));
        }
if (message.features !== undefined  && message.features !== null) {
          obj.features = FeatureSet.toJSON(message.features);
        }
if (message.feature_support !== undefined  && message.feature_support !== null) {
          obj.feature_support = FieldOptions_FeatureSupport.toJSON(message.feature_support);
        }
if (message.uninterpreted_option?.length) {
          obj.uninterpreted_option = message.uninterpreted_option.map(e => UninterpretedOption.toJSON(e));
        }
return obj;
},

create<I extends Exact<DeepPartial<FieldOptions>, I>>(base?: I): FieldOptions {
        return FieldOptions.fromPartial(base ?? ({} as any));
      },
fromPartial<I extends Exact<DeepPartial<FieldOptions>, I>>(object: I): FieldOptions {
const message = createBaseFieldOptions();
message.ctype = object.ctype ?? FieldOptions_CType.STRING;
message.packed = object.packed ?? false;
message.jstype = object.jstype ?? FieldOptions_JSType.JS_NORMAL;
message.lazy = object.lazy ?? false;
message.unverified_lazy = object.unverified_lazy ?? false;
message.deprecated = object.deprecated ?? false;
message.weak = object.weak ?? false;
message.debug_redact = object.debug_redact ?? false;
message.retention = object.retention ?? FieldOptions_OptionRetention.RETENTION_UNKNOWN;
message.targets = object.targets?.map((e) => e) || [];
message.edition_defaults = object.edition_defaults?.map((e) => FieldOptions_EditionDefault.fromPartial(e)) || [];
message.features = (object.features !== undefined && object.features !== null)
          ? FeatureSet.fromPartial(object.features)
          : null ;
message.feature_support = (object.feature_support !== undefined && object.feature_support !== null)
          ? FieldOptions_FeatureSupport.fromPartial(object.feature_support)
          : null ;
message.uninterpreted_option = object.uninterpreted_option?.map((e) => UninterpretedOption.fromPartial(e)) || [];
return message;
}
            };

function createBaseFieldOptions_EditionDefault(): FieldOptions_EditionDefault {
      return { edition: Edition.UNKNOWN,value: "" };
    }

export const FieldOptions_EditionDefault = {
              encode(
      message: FieldOptions_EditionDefault,
      writer: _m0.Writer = _m0.Writer.create(),
    ): _m0.Writer {
if (message.edition !== undefined  && message.edition !== null && message.edition !== Edition.UNKNOWN) {
          writer.uint32(24).int32(editionToNumber(message.edition));
        }
if (message.value !== undefined  && message.value !== null && message.value !== "") {
          writer.uint32(18).string(message.value);
        }
return writer;
},

decode(
      input: _m0.Reader | Uint8Array,
      length?: number,
    ): FieldOptions_EditionDefault {
      const reader = input instanceof _m0.Reader ? input : _m0.Reader.create(input);
      let end = length === undefined ? reader.len : reader.pos + length;
const message = createBaseFieldOptions_EditionDefault();
while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
case 3:
if (tag !== 24) {
        break;
      }
    
        message.edition = editionFromJSON(reader.int32());
continue;
case 2:
if (tag !== 18) {
        break;
      }
    
        message.value = reader.string();
continue;
}
if ((tag & 7) === 4 || tag === 0) {
        break;
      }
reader.skipType(tag & 7);
}
return message;
},

// encodeTransform encodes a source of message objects.
    // Transform<FieldOptions_EditionDefault, Uint8Array>
    async *encodeTransform(
      source: AsyncIterable<FieldOptions_EditionDefault | FieldOptions_EditionDefault[]> | Iterable<FieldOptions_EditionDefault | FieldOptions_EditionDefault[]>
    ): AsyncIterable<Uint8Array> {
      for await (const pkt of source) {
        if (globalThis.Array.isArray(pkt)) {
          for (const p of (pkt as any)) {
            yield* [FieldOptions_EditionDefault.encode(p).finish()]
          }
        } else {
          yield* [FieldOptions_EditionDefault.encode(pkt as any).finish()]
        }
      }
    },

// decodeTransform decodes a source of encoded messages.
    // Transform<Uint8Array, FieldOptions_EditionDefault>
    async *decodeTransform(
      source: AsyncIterable<Uint8Array | Uint8Array[]> | Iterable<Uint8Array | Uint8Array[]>
    ): AsyncIterable<FieldOptions_EditionDefault> {
      for await (const pkt of source) {
        if (globalThis.Array.isArray(pkt)) {
          for (const p of (pkt as any)) {
            yield* [FieldOptions_EditionDefault.decode(p)]
          }
        } else {
          yield* [FieldOptions_EditionDefault.decode(pkt as any)]
        }
      }
    },

fromJSON(object: any): FieldOptions_EditionDefault {
      return {
edition: isSet(object.edition)
          ? editionFromJSON(object.edition)
          : Edition.UNKNOWN,
value: isSet(object.value)
          ? globalThis.String(object.value)
          : "",
};
},

toJSON(message: FieldOptions_EditionDefault): unknown {
      const obj: any = {};
if (message.edition !== undefined  && message.edition !== null && message.edition !== Edition.UNKNOWN) {
          obj.edition = editionToJSON(message.edition);
        }
if (message.value !== undefined  && message.value !== null && message.value !== "") {
          obj.value = message.value;
        }
return obj;
},

create<I extends Exact<DeepPartial<FieldOptions_EditionDefault>, I>>(base?: I): FieldOptions_EditionDefault {
        return FieldOptions_EditionDefault.fromPartial(base ?? ({} as any));
      },
fromPartial<I extends Exact<DeepPartial<FieldOptions_EditionDefault>, I>>(object: I): FieldOptions_EditionDefault {
const message = createBaseFieldOptions_EditionDefault();
message.edition = object.edition ?? Edition.UNKNOWN;
message.value = object.value ?? "";
return message;
}
            };

function createBaseFieldOptions_FeatureSupport(): FieldOptions_FeatureSupport {
      return { edition_introduced: Edition.UNKNOWN,edition_deprecated: Edition.UNKNOWN,deprecation_warning: "",edition_removed: Edition.UNKNOWN };
    }

export const FieldOptions_FeatureSupport = {
              encode(
      message: FieldOptions_FeatureSupport,
      writer: _m0.Writer = _m0.Writer.create(),
    ): _m0.Writer {
if (message.edition_introduced !== undefined  && message.edition_introduced !== null && message.edition_introduced !== Edition.UNKNOWN) {
          writer.uint32(8).int32(editionToNumber(message.edition_introduced));
        }
if (message.edition_deprecated !== undefined  && message.edition_deprecated !== null && message.edition_deprecated !== Edition.UNKNOWN) {
          writer.uint32(16).int32(editionToNumber(message.edition_deprecated));
        }
if (message.deprecation_warning !== undefined  && message.deprecation_warning !== null && message.deprecation_warning !== "") {
          writer.uint32(26).string(message.deprecation_warning);
        }
if (message.edition_removed !== undefined  && message.edition_removed !== null && message.edition_removed !== Edition.UNKNOWN) {
          writer.uint32(32).int32(editionToNumber(message.edition_removed));
        }
return writer;
},

decode(
      input: _m0.Reader | Uint8Array,
      length?: number,
    ): FieldOptions_FeatureSupport {
      const reader = input instanceof _m0.Reader ? input : _m0.Reader.create(input);
      let end = length === undefined ? reader.len : reader.pos + length;
const message = createBaseFieldOptions_FeatureSupport();
while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
case 1:
if (tag !== 8) {
        break;
      }
    
        message.edition_introduced = editionFromJSON(reader.int32());
continue;
case 2:
if (tag !== 16) {
        break;
      }
    
        message.edition_deprecated = editionFromJSON(reader.int32());
continue;
case 3:
if (tag !== 26) {
        break;
      }
    
        message.deprecation_warning = reader.string();
continue;
case 4:
if (tag !== 32) {
        break;
      }
    
        message.edition_removed = editionFromJSON(reader.int32());
continue;
}
if ((tag & 7) === 4 || tag === 0) {
        break;
      }
reader.skipType(tag & 7);
}
return message;
},

// encodeTransform encodes a source of message objects.
    // Transform<FieldOptions_FeatureSupport, Uint8Array>
    async *encodeTransform(
      source: AsyncIterable<FieldOptions_FeatureSupport | FieldOptions_FeatureSupport[]> | Iterable<FieldOptions_FeatureSupport | FieldOptions_FeatureSupport[]>
    ): AsyncIterable<Uint8Array> {
      for await (const pkt of source) {
        if (globalThis.Array.isArray(pkt)) {
          for (const p of (pkt as any)) {
            yield* [FieldOptions_FeatureSupport.encode(p).finish()]
          }
        } else {
          yield* [FieldOptions_FeatureSupport.encode(pkt as any).finish()]
        }
      }
    },

// decodeTransform decodes a source of encoded messages.
    // Transform<Uint8Array, FieldOptions_FeatureSupport>
    async *decodeTransform(
      source: AsyncIterable<Uint8Array | Uint8Array[]> | Iterable<Uint8Array | Uint8Array[]>
    ): AsyncIterable<FieldOptions_FeatureSupport> {
      for await (const pkt of source) {
        if (globalThis.Array.isArray(pkt)) {
          for (const p of (pkt as any)) {
            yield* [FieldOptions_FeatureSupport.decode(p)]
          }
        } else {
          yield* [FieldOptions_FeatureSupport.decode(pkt as any)]
        }
      }
    },

fromJSON(object: any): FieldOptions_FeatureSupport {
      return {
edition_introduced: isSet(object.edition_introduced)
          ? editionFromJSON(object.edition_introduced)
          : Edition.UNKNOWN,
edition_deprecated: isSet(object.edition_deprecated)
          ? editionFromJSON(object.edition_deprecated)
          : Edition.UNKNOWN,
deprecation_warning: isSet(object.deprecation_warning)
          ? globalThis.String(object.deprecation_warning)
          : "",
edition_removed: isSet(object.edition_removed)
          ? editionFromJSON(object.edition_removed)
          : Edition.UNKNOWN,
};
},

toJSON(message: FieldOptions_FeatureSupport): unknown {
      const obj: any = {};
if (message.edition_introduced !== undefined  && message.edition_introduced !== null && message.edition_introduced !== Edition.UNKNOWN) {
          obj.edition_introduced = editionToJSON(message.edition_introduced);
        }
if (message.edition_deprecated !== undefined  && message.edition_deprecated !== null && message.edition_deprecated !== Edition.UNKNOWN) {
          obj.edition_deprecated = editionToJSON(message.edition_deprecated);
        }
if (message.deprecation_warning !== undefined  && message.deprecation_warning !== null && message.deprecation_warning !== "") {
          obj.deprecation_warning = message.deprecation_warning;
        }
if (message.edition_removed !== undefined  && message.edition_removed !== null && message.edition_removed !== Edition.UNKNOWN) {
          obj.edition_removed = editionToJSON(message.edition_removed);
        }
return obj;
},

create<I extends Exact<DeepPartial<FieldOptions_FeatureSupport>, I>>(base?: I): FieldOptions_FeatureSupport {
        return FieldOptions_FeatureSupport.fromPartial(base ?? ({} as any));
      },
fromPartial<I extends Exact<DeepPartial<FieldOptions_FeatureSupport>, I>>(object: I): FieldOptions_FeatureSupport {
const message = createBaseFieldOptions_FeatureSupport();
message.edition_introduced = object.edition_introduced ?? Edition.UNKNOWN;
message.edition_deprecated = object.edition_deprecated ?? Edition.UNKNOWN;
message.deprecation_warning = object.deprecation_warning ?? "";
message.edition_removed = object.edition_removed ?? Edition.UNKNOWN;
return message;
}
            };

function createBaseOneofOptions(): OneofOptions {
      return { features: null,uninterpreted_option: [] };
    }

export const OneofOptions = {
              encode(
      message: OneofOptions,
      writer: _m0.Writer = _m0.Writer.create(),
    ): _m0.Writer {
if (message.features !== undefined  && message.features !== null) {
          FeatureSet.encode(message.features, writer.uint32(10).fork()).ldelim();
        }
for (const v of message.uninterpreted_option) {
            UninterpretedOption.encode(v!, writer.uint32(7994).fork()).ldelim();
          }
return writer;
},

decode(
      input: _m0.Reader | Uint8Array,
      length?: number,
    ): OneofOptions {
      const reader = input instanceof _m0.Reader ? input : _m0.Reader.create(input);
      let end = length === undefined ? reader.len : reader.pos + length;
const message = createBaseOneofOptions();
while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
case 1:
if (tag !== 10) {
        break;
      }
    
        message.features = FeatureSet.decode(reader, reader.uint32());
continue;
case 999:
if (tag !== 7994) {
        break;
      }
    
            
            message.uninterpreted_option.push(UninterpretedOption.decode(reader, reader.uint32()));
continue;
}
if ((tag & 7) === 4 || tag === 0) {
        break;
      }
reader.skipType(tag & 7);
}
return message;
},

// encodeTransform encodes a source of message objects.
    // Transform<OneofOptions, Uint8Array>
    async *encodeTransform(
      source: AsyncIterable<OneofOptions | OneofOptions[]> | Iterable<OneofOptions | OneofOptions[]>
    ): AsyncIterable<Uint8Array> {
      for await (const pkt of source) {
        if (globalThis.Array.isArray(pkt)) {
          for (const p of (pkt as any)) {
            yield* [OneofOptions.encode(p).finish()]
          }
        } else {
          yield* [OneofOptions.encode(pkt as any).finish()]
        }
      }
    },

// decodeTransform decodes a source of encoded messages.
    // Transform<Uint8Array, OneofOptions>
    async *decodeTransform(
      source: AsyncIterable<Uint8Array | Uint8Array[]> | Iterable<Uint8Array | Uint8Array[]>
    ): AsyncIterable<OneofOptions> {
      for await (const pkt of source) {
        if (globalThis.Array.isArray(pkt)) {
          for (const p of (pkt as any)) {
            yield* [OneofOptions.decode(p)]
          }
        } else {
          yield* [OneofOptions.decode(pkt as any)]
        }
      }
    },

fromJSON(object: any): OneofOptions {
      return {
features: isSet(object.features)
          ? FeatureSet.fromJSON(object.features)
          : null ,
uninterpreted_option: globalThis.Array.isArray(object?.uninterpreted_option) ? object.uninterpreted_option.map((e: any) => UninterpretedOption.fromJSON(e)): [],
};
},

toJSON(message: OneofOptions): unknown {
      const obj: any = {};
if (message.features !== undefined  && message.features !== null) {
          obj.features = FeatureSet.toJSON(message.features);
        }
if (message.uninterpreted_option?.length) {
          obj.uninterpreted_option = message.uninterpreted_option.map(e => UninterpretedOption.toJSON(e));
        }
return obj;
},

create<I extends Exact<DeepPartial<OneofOptions>, I>>(base?: I): OneofOptions {
        return OneofOptions.fromPartial(base ?? ({} as any));
      },
fromPartial<I extends Exact<DeepPartial<OneofOptions>, I>>(object: I): OneofOptions {
const message = createBaseOneofOptions();
message.features = (object.features !== undefined && object.features !== null)
          ? FeatureSet.fromPartial(object.features)
          : null ;
message.uninterpreted_option = object.uninterpreted_option?.map((e) => UninterpretedOption.fromPartial(e)) || [];
return message;
}
            };

function createBaseEnumOptions(): EnumOptions {
      return { allow_alias: false,deprecated: false,deprecated_legacy_json_field_conflicts: false,features: null,uninterpreted_option: [] };
    }

export const EnumOptions = {
              encode(
      message: EnumOptions,
      writer: _m0.Writer = _m0.Writer.create(),
    ): _m0.Writer {
if (message.allow_alias !== undefined  && message.allow_alias !== null && message.allow_alias !== false) {
          writer.uint32(16).bool(message.allow_alias);
        }
if (message.deprecated !== undefined  && message.deprecated !== null && message.deprecated !== false) {
          writer.uint32(24).bool(message.deprecated);
        }
if (message.deprecated_legacy_json_field_conflicts !== undefined  && message.deprecated_legacy_json_field_conflicts !== null && message.deprecated_legacy_json_field_conflicts !== false) {
          writer.uint32(48).bool(message.deprecated_legacy_json_field_conflicts);
        }
if (message.features !== undefined  && message.features !== null) {
          FeatureSet.encode(message.features, writer.uint32(58).fork()).ldelim();
        }
for (const v of message.uninterpreted_option) {
            UninterpretedOption.encode(v!, writer.uint32(7994).fork()).ldelim();
          }
return writer;
},

decode(
      input: _m0.Reader | Uint8Array,
      length?: number,
    ): EnumOptions {
      const reader = input instanceof _m0.Reader ? input : _m0.Reader.create(input);
      let end = length === undefined ? reader.len : reader.pos + length;
const message = createBaseEnumOptions();
while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
case 2:
if (tag !== 16) {
        break;
      }
    
        message.allow_alias = reader.bool();
continue;
case 3:
if (tag !== 24) {
        break;
      }
    
        message.deprecated = reader.bool();
continue;
case 6:
if (tag !== 48) {
        break;
      }
    
        message.deprecated_legacy_json_field_conflicts = reader.bool();
continue;
case 7:
if (tag !== 58) {
        break;
      }
    
        message.features = FeatureSet.decode(reader, reader.uint32());
continue;
case 999:
if (tag !== 7994) {
        break;
      }
    
            
            message.uninterpreted_option.push(UninterpretedOption.decode(reader, reader.uint32()));
continue;
}
if ((tag & 7) === 4 || tag === 0) {
        break;
      }
reader.skipType(tag & 7);
}
return message;
},

// encodeTransform encodes a source of message objects.
    // Transform<EnumOptions, Uint8Array>
    async *encodeTransform(
      source: AsyncIterable<EnumOptions | EnumOptions[]> | Iterable<EnumOptions | EnumOptions[]>
    ): AsyncIterable<Uint8Array> {
      for await (const pkt of source) {
        if (globalThis.Array.isArray(pkt)) {
          for (const p of (pkt as any)) {
            yield* [EnumOptions.encode(p).finish()]
          }
        } else {
          yield* [EnumOptions.encode(pkt as any).finish()]
        }
      }
    },

// decodeTransform decodes a source of encoded messages.
    // Transform<Uint8Array, EnumOptions>
    async *decodeTransform(
      source: AsyncIterable<Uint8Array | Uint8Array[]> | Iterable<Uint8Array | Uint8Array[]>
    ): AsyncIterable<EnumOptions> {
      for await (const pkt of source) {
        if (globalThis.Array.isArray(pkt)) {
          for (const p of (pkt as any)) {
            yield* [EnumOptions.decode(p)]
          }
        } else {
          yield* [EnumOptions.decode(pkt as any)]
        }
      }
    },

fromJSON(object: any): EnumOptions {
      return {
allow_alias: isSet(object.allow_alias)
          ? globalThis.Boolean(object.allow_alias)
          : false,
deprecated: isSet(object.deprecated)
          ? globalThis.Boolean(object.deprecated)
          : false,
deprecated_legacy_json_field_conflicts: isSet(object.deprecated_legacy_json_field_conflicts)
          ? globalThis.Boolean(object.deprecated_legacy_json_field_conflicts)
          : false,
features: isSet(object.features)
          ? FeatureSet.fromJSON(object.features)
          : null ,
uninterpreted_option: globalThis.Array.isArray(object?.uninterpreted_option) ? object.uninterpreted_option.map((e: any) => UninterpretedOption.fromJSON(e)): [],
};
},

toJSON(message: EnumOptions): unknown {
      const obj: any = {};
if (message.allow_alias !== undefined  && message.allow_alias !== null && message.allow_alias !== false) {
          obj.allow_alias = message.allow_alias;
        }
if (message.deprecated !== undefined  && message.deprecated !== null && message.deprecated !== false) {
          obj.deprecated = message.deprecated;
        }
if (message.deprecated_legacy_json_field_conflicts !== undefined  && message.deprecated_legacy_json_field_conflicts !== null && message.deprecated_legacy_json_field_conflicts !== false) {
          obj.deprecated_legacy_json_field_conflicts = message.deprecated_legacy_json_field_conflicts;
        }
if (message.features !== undefined  && message.features !== null) {
          obj.features = FeatureSet.toJSON(message.features);
        }
if (message.uninterpreted_option?.length) {
          obj.uninterpreted_option = message.uninterpreted_option.map(e => UninterpretedOption.toJSON(e));
        }
return obj;
},

create<I extends Exact<DeepPartial<EnumOptions>, I>>(base?: I): EnumOptions {
        return EnumOptions.fromPartial(base ?? ({} as any));
      },
fromPartial<I extends Exact<DeepPartial<EnumOptions>, I>>(object: I): EnumOptions {
const message = createBaseEnumOptions();
message.allow_alias = object.allow_alias ?? false;
message.deprecated = object.deprecated ?? false;
message.deprecated_legacy_json_field_conflicts = object.deprecated_legacy_json_field_conflicts ?? false;
message.features = (object.features !== undefined && object.features !== null)
          ? FeatureSet.fromPartial(object.features)
          : null ;
message.uninterpreted_option = object.uninterpreted_option?.map((e) => UninterpretedOption.fromPartial(e)) || [];
return message;
}
            };

function createBaseEnumValueOptions(): EnumValueOptions {
      return { deprecated: false,features: null,debug_redact: false,feature_support: null,uninterpreted_option: [] };
    }

export const EnumValueOptions = {
              encode(
      message: EnumValueOptions,
      writer: _m0.Writer = _m0.Writer.create(),
    ): _m0.Writer {
if (message.deprecated !== undefined  && message.deprecated !== null && message.deprecated !== false) {
          writer.uint32(8).bool(message.deprecated);
        }
if (message.features !== undefined  && message.features !== null) {
          FeatureSet.encode(message.features, writer.uint32(18).fork()).ldelim();
        }
if (message.debug_redact !== undefined  && message.debug_redact !== null && message.debug_redact !== false) {
          writer.uint32(24).bool(message.debug_redact);
        }
if (message.feature_support !== undefined  && message.feature_support !== null) {
          FieldOptions_FeatureSupport.encode(message.feature_support, writer.uint32(34).fork()).ldelim();
        }
for (const v of message.uninterpreted_option) {
            UninterpretedOption.encode(v!, writer.uint32(7994).fork()).ldelim();
          }
return writer;
},

decode(
      input: _m0.Reader | Uint8Array,
      length?: number,
    ): EnumValueOptions {
      const reader = input instanceof _m0.Reader ? input : _m0.Reader.create(input);
      let end = length === undefined ? reader.len : reader.pos + length;
const message = createBaseEnumValueOptions();
while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
case 1:
if (tag !== 8) {
        break;
      }
    
        message.deprecated = reader.bool();
continue;
case 2:
if (tag !== 18) {
        break;
      }
    
        message.features = FeatureSet.decode(reader, reader.uint32());
continue;
case 3:
if (tag !== 24) {
        break;
      }
    
        message.debug_redact = reader.bool();
continue;
case 4:
if (tag !== 34) {
        break;
      }
    
        message.feature_support = FieldOptions_FeatureSupport.decode(reader, reader.uint32());
continue;
case 999:
if (tag !== 7994) {
        break;
      }
    
            
            message.uninterpreted_option.push(UninterpretedOption.decode(reader, reader.uint32()));
continue;
}
if ((tag & 7) === 4 || tag === 0) {
        break;
      }
reader.skipType(tag & 7);
}
return message;
},

// encodeTransform encodes a source of message objects.
    // Transform<EnumValueOptions, Uint8Array>
    async *encodeTransform(
      source: AsyncIterable<EnumValueOptions | EnumValueOptions[]> | Iterable<EnumValueOptions | EnumValueOptions[]>
    ): AsyncIterable<Uint8Array> {
      for await (const pkt of source) {
        if (globalThis.Array.isArray(pkt)) {
          for (const p of (pkt as any)) {
            yield* [EnumValueOptions.encode(p).finish()]
          }
        } else {
          yield* [EnumValueOptions.encode(pkt as any).finish()]
        }
      }
    },

// decodeTransform decodes a source of encoded messages.
    // Transform<Uint8Array, EnumValueOptions>
    async *decodeTransform(
      source: AsyncIterable<Uint8Array | Uint8Array[]> | Iterable<Uint8Array | Uint8Array[]>
    ): AsyncIterable<EnumValueOptions> {
      for await (const pkt of source) {
        if (globalThis.Array.isArray(pkt)) {
          for (const p of (pkt as any)) {
            yield* [EnumValueOptions.decode(p)]
          }
        } else {
          yield* [EnumValueOptions.decode(pkt as any)]
        }
      }
    },

fromJSON(object: any): EnumValueOptions {
      return {
deprecated: isSet(object.deprecated)
          ? globalThis.Boolean(object.deprecated)
          : false,
features: isSet(object.features)
          ? FeatureSet.fromJSON(object.features)
          : null ,
debug_redact: isSet(object.debug_redact)
          ? globalThis.Boolean(object.debug_redact)
          : false,
feature_support: isSet(object.feature_support)
          ? FieldOptions_FeatureSupport.fromJSON(object.feature_support)
          : null ,
uninterpreted_option: globalThis.Array.isArray(object?.uninterpreted_option) ? object.uninterpreted_option.map((e: any) => UninterpretedOption.fromJSON(e)): [],
};
},

toJSON(message: EnumValueOptions): unknown {
      const obj: any = {};
if (message.deprecated !== undefined  && message.deprecated !== null && message.deprecated !== false) {
          obj.deprecated = message.deprecated;
        }
if (message.features !== undefined  && message.features !== null) {
          obj.features = FeatureSet.toJSON(message.features);
        }
if (message.debug_redact !== undefined  && message.debug_redact !== null && message.debug_redact !== false) {
          obj.debug_redact = message.debug_redact;
        }
if (message.feature_support !== undefined  && message.feature_support !== null) {
          obj.feature_support = FieldOptions_FeatureSupport.toJSON(message.feature_support);
        }
if (message.uninterpreted_option?.length) {
          obj.uninterpreted_option = message.uninterpreted_option.map(e => UninterpretedOption.toJSON(e));
        }
return obj;
},

create<I extends Exact<DeepPartial<EnumValueOptions>, I>>(base?: I): EnumValueOptions {
        return EnumValueOptions.fromPartial(base ?? ({} as any));
      },
fromPartial<I extends Exact<DeepPartial<EnumValueOptions>, I>>(object: I): EnumValueOptions {
const message = createBaseEnumValueOptions();
message.deprecated = object.deprecated ?? false;
message.features = (object.features !== undefined && object.features !== null)
          ? FeatureSet.fromPartial(object.features)
          : null ;
message.debug_redact = object.debug_redact ?? false;
message.feature_support = (object.feature_support !== undefined && object.feature_support !== null)
          ? FieldOptions_FeatureSupport.fromPartial(object.feature_support)
          : null ;
message.uninterpreted_option = object.uninterpreted_option?.map((e) => UninterpretedOption.fromPartial(e)) || [];
return message;
}
            };

function createBaseServiceOptions(): ServiceOptions {
      return { features: null,deprecated: false,uninterpreted_option: [] };
    }

export const ServiceOptions = {
              encode(
      message: ServiceOptions,
      writer: _m0.Writer = _m0.Writer.create(),
    ): _m0.Writer {
if (message.features !== undefined  && message.features !== null) {
          FeatureSet.encode(message.features, writer.uint32(274).fork()).ldelim();
        }
if (message.deprecated !== undefined  && message.deprecated !== null && message.deprecated !== false) {
          writer.uint32(264).bool(message.deprecated);
        }
for (const v of message.uninterpreted_option) {
            UninterpretedOption.encode(v!, writer.uint32(7994).fork()).ldelim();
          }
return writer;
},

decode(
      input: _m0.Reader | Uint8Array,
      length?: number,
    ): ServiceOptions {
      const reader = input instanceof _m0.Reader ? input : _m0.Reader.create(input);
      let end = length === undefined ? reader.len : reader.pos + length;
const message = createBaseServiceOptions();
while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
case 34:
if (tag !== 274) {
        break;
      }
    
        message.features = FeatureSet.decode(reader, reader.uint32());
continue;
case 33:
if (tag !== 264) {
        break;
      }
    
        message.deprecated = reader.bool();
continue;
case 999:
if (tag !== 7994) {
        break;
      }
    
            
            message.uninterpreted_option.push(UninterpretedOption.decode(reader, reader.uint32()));
continue;
}
if ((tag & 7) === 4 || tag === 0) {
        break;
      }
reader.skipType(tag & 7);
}
return message;
},

// encodeTransform encodes a source of message objects.
    // Transform<ServiceOptions, Uint8Array>
    async *encodeTransform(
      source: AsyncIterable<ServiceOptions | ServiceOptions[]> | Iterable<ServiceOptions | ServiceOptions[]>
    ): AsyncIterable<Uint8Array> {
      for await (const pkt of source) {
        if (globalThis.Array.isArray(pkt)) {
          for (const p of (pkt as any)) {
            yield* [ServiceOptions.encode(p).finish()]
          }
        } else {
          yield* [ServiceOptions.encode(pkt as any).finish()]
        }
      }
    },

// decodeTransform decodes a source of encoded messages.
    // Transform<Uint8Array, ServiceOptions>
    async *decodeTransform(
      source: AsyncIterable<Uint8Array | Uint8Array[]> | Iterable<Uint8Array | Uint8Array[]>
    ): AsyncIterable<ServiceOptions> {
      for await (const pkt of source) {
        if (globalThis.Array.isArray(pkt)) {
          for (const p of (pkt as any)) {
            yield* [ServiceOptions.decode(p)]
          }
        } else {
          yield* [ServiceOptions.decode(pkt as any)]
        }
      }
    },

fromJSON(object: any): ServiceOptions {
      return {
features: isSet(object.features)
          ? FeatureSet.fromJSON(object.features)
          : null ,
deprecated: isSet(object.deprecated)
          ? globalThis.Boolean(object.deprecated)
          : false,
uninterpreted_option: globalThis.Array.isArray(object?.uninterpreted_option) ? object.uninterpreted_option.map((e: any) => UninterpretedOption.fromJSON(e)): [],
};
},

toJSON(message: ServiceOptions): unknown {
      const obj: any = {};
if (message.features !== undefined  && message.features !== null) {
          obj.features = FeatureSet.toJSON(message.features);
        }
if (message.deprecated !== undefined  && message.deprecated !== null && message.deprecated !== false) {
          obj.deprecated = message.deprecated;
        }
if (message.uninterpreted_option?.length) {
          obj.uninterpreted_option = message.uninterpreted_option.map(e => UninterpretedOption.toJSON(e));
        }
return obj;
},

create<I extends Exact<DeepPartial<ServiceOptions>, I>>(base?: I): ServiceOptions {
        return ServiceOptions.fromPartial(base ?? ({} as any));
      },
fromPartial<I extends Exact<DeepPartial<ServiceOptions>, I>>(object: I): ServiceOptions {
const message = createBaseServiceOptions();
message.features = (object.features !== undefined && object.features !== null)
          ? FeatureSet.fromPartial(object.features)
          : null ;
message.deprecated = object.deprecated ?? false;
message.uninterpreted_option = object.uninterpreted_option?.map((e) => UninterpretedOption.fromPartial(e)) || [];
return message;
}
            };

function createBaseMethodOptions(): MethodOptions {
      return { deprecated: false,idempotency_level: MethodOptions_IdempotencyLevel.IDEMPOTENCY_UNKNOWN,features: null,uninterpreted_option: [] };
    }

export const MethodOptions = {
              encode(
      message: MethodOptions,
      writer: _m0.Writer = _m0.Writer.create(),
    ): _m0.Writer {
if (message.deprecated !== undefined  && message.deprecated !== null && message.deprecated !== false) {
          writer.uint32(264).bool(message.deprecated);
        }
if (message.idempotency_level !== undefined  && message.idempotency_level !== null && message.idempotency_level !== MethodOptions_IdempotencyLevel.IDEMPOTENCY_UNKNOWN) {
          writer.uint32(272).int32(methodOptions_IdempotencyLevelToNumber(message.idempotency_level));
        }
if (message.features !== undefined  && message.features !== null) {
          FeatureSet.encode(message.features, writer.uint32(282).fork()).ldelim();
        }
for (const v of message.uninterpreted_option) {
            UninterpretedOption.encode(v!, writer.uint32(7994).fork()).ldelim();
          }
return writer;
},

decode(
      input: _m0.Reader | Uint8Array,
      length?: number,
    ): MethodOptions {
      const reader = input instanceof _m0.Reader ? input : _m0.Reader.create(input);
      let end = length === undefined ? reader.len : reader.pos + length;
const message = createBaseMethodOptions();
while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
case 33:
if (tag !== 264) {
        break;
      }
    
        message.deprecated = reader.bool();
continue;
case 34:
if (tag !== 272) {
        break;
      }
    
        message.idempotency_level = methodOptions_IdempotencyLevelFromJSON(reader.int32());
continue;
case 35:
if (tag !== 282) {
        break;
      }
    
        message.features = FeatureSet.decode(reader, reader.uint32());
continue;
case 999:
if (tag !== 7994) {
        break;
      }
    
            
            message.uninterpreted_option.push(UninterpretedOption.decode(reader, reader.uint32()));
continue;
}
if ((tag & 7) === 4 || tag === 0) {
        break;
      }
reader.skipType(tag & 7);
}
return message;
},

// encodeTransform encodes a source of message objects.
    // Transform<MethodOptions, Uint8Array>
    async *encodeTransform(
      source: AsyncIterable<MethodOptions | MethodOptions[]> | Iterable<MethodOptions | MethodOptions[]>
    ): AsyncIterable<Uint8Array> {
      for await (const pkt of source) {
        if (globalThis.Array.isArray(pkt)) {
          for (const p of (pkt as any)) {
            yield* [MethodOptions.encode(p).finish()]
          }
        } else {
          yield* [MethodOptions.encode(pkt as any).finish()]
        }
      }
    },

// decodeTransform decodes a source of encoded messages.
    // Transform<Uint8Array, MethodOptions>
    async *decodeTransform(
      source: AsyncIterable<Uint8Array | Uint8Array[]> | Iterable<Uint8Array | Uint8Array[]>
    ): AsyncIterable<MethodOptions> {
      for await (const pkt of source) {
        if (globalThis.Array.isArray(pkt)) {
          for (const p of (pkt as any)) {
            yield* [MethodOptions.decode(p)]
          }
        } else {
          yield* [MethodOptions.decode(pkt as any)]
        }
      }
    },

fromJSON(object: any): MethodOptions {
      return {
deprecated: isSet(object.deprecated)
          ? globalThis.Boolean(object.deprecated)
          : false,
idempotency_level: isSet(object.idempotency_level)
          ? methodOptions_IdempotencyLevelFromJSON(object.idempotency_level)
          : MethodOptions_IdempotencyLevel.IDEMPOTENCY_UNKNOWN,
features: isSet(object.features)
          ? FeatureSet.fromJSON(object.features)
          : null ,
uninterpreted_option: globalThis.Array.isArray(object?.uninterpreted_option) ? object.uninterpreted_option.map((e: any) => UninterpretedOption.fromJSON(e)): [],
};
},

toJSON(message: MethodOptions): unknown {
      const obj: any = {};
if (message.deprecated !== undefined  && message.deprecated !== null && message.deprecated !== false) {
          obj.deprecated = message.deprecated;
        }
if (message.idempotency_level !== undefined  && message.idempotency_level !== null && message.idempotency_level !== MethodOptions_IdempotencyLevel.IDEMPOTENCY_UNKNOWN) {
          obj.idempotency_level = methodOptions_IdempotencyLevelToJSON(message.idempotency_level);
        }
if (message.features !== undefined  && message.features !== null) {
          obj.features = FeatureSet.toJSON(message.features);
        }
if (message.uninterpreted_option?.length) {
          obj.uninterpreted_option = message.uninterpreted_option.map(e => UninterpretedOption.toJSON(e));
        }
return obj;
},

create<I extends Exact<DeepPartial<MethodOptions>, I>>(base?: I): MethodOptions {
        return MethodOptions.fromPartial(base ?? ({} as any));
      },
fromPartial<I extends Exact<DeepPartial<MethodOptions>, I>>(object: I): MethodOptions {
const message = createBaseMethodOptions();
message.deprecated = object.deprecated ?? false;
message.idempotency_level = object.idempotency_level ?? MethodOptions_IdempotencyLevel.IDEMPOTENCY_UNKNOWN;
message.features = (object.features !== undefined && object.features !== null)
          ? FeatureSet.fromPartial(object.features)
          : null ;
message.uninterpreted_option = object.uninterpreted_option?.map((e) => UninterpretedOption.fromPartial(e)) || [];
return message;
}
            };

function createBaseUninterpretedOption(): UninterpretedOption {
      return { name: [],identifier_value: "",positive_int_value: BigInt("0"),negative_int_value: BigInt("0"),double_value: 0,string_value: Buffer.alloc(0),aggregate_value: "" };
    }

export const UninterpretedOption = {
              encode(
      message: UninterpretedOption,
      writer: _m0.Writer = _m0.Writer.create(),
    ): _m0.Writer {
for (const v of message.name) {
            UninterpretedOption_NamePart.encode(v!, writer.uint32(18).fork()).ldelim();
          }
if (message.identifier_value !== undefined  && message.identifier_value !== null && message.identifier_value !== "") {
          writer.uint32(26).string(message.identifier_value);
        }
if (message.positive_int_value !== undefined  && message.positive_int_value !== null && message.positive_int_value !== BigInt("0")) {
          if (BigInt.asUintN(64, message.positive_int_value) !== message.positive_int_value) {
          throw new globalThis.Error('value provided for field message.positive_int_value of type uint64 too large');
        }
        writer.uint32(32).uint64(message.positive_int_value.toString());
        }
if (message.negative_int_value !== undefined  && message.negative_int_value !== null && message.negative_int_value !== BigInt("0")) {
          if (BigInt.asIntN(64, message.negative_int_value) !== message.negative_int_value) {
          throw new globalThis.Error('value provided for field message.negative_int_value of type int64 too large');
        }
        writer.uint32(40).int64(message.negative_int_value.toString());
        }
if (message.double_value !== undefined  && message.double_value !== null && message.double_value !== 0) {
          writer.uint32(49).double(message.double_value);
        }
if (message.string_value !== undefined  && message.string_value !== null && message.string_value.length !== 0) {
          writer.uint32(58).bytes(message.string_value);
        }
if (message.aggregate_value !== undefined  && message.aggregate_value !== null && message.aggregate_value !== "") {
          writer.uint32(66).string(message.aggregate_value);
        }
return writer;
},

decode(
      input: _m0.Reader | Uint8Array,
      length?: number,
    ): UninterpretedOption {
      const reader = input instanceof _m0.Reader ? input : _m0.Reader.create(input);
      let end = length === undefined ? reader.len : reader.pos + length;
const message = createBaseUninterpretedOption();
while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
case 2:
if (tag !== 18) {
        break;
      }
    
            
            message.name.push(UninterpretedOption_NamePart.decode(reader, reader.uint32()));
continue;
case 3:
if (tag !== 26) {
        break;
      }
    
        message.identifier_value = reader.string();
continue;
case 4:
if (tag !== 32) {
        break;
      }
    
        message.positive_int_value = longToBigint(reader.uint64() as Long);
continue;
case 5:
if (tag !== 40) {
        break;
      }
    
        message.negative_int_value = longToBigint(reader.int64() as Long);
continue;
case 6:
if (tag !== 49) {
        break;
      }
    
        message.double_value = reader.double();
continue;
case 7:
if (tag !== 58) {
        break;
      }
    
        message.string_value = reader.bytes() as Buffer;
continue;
case 8:
if (tag !== 66) {
        break;
      }
    
        message.aggregate_value = reader.string();
continue;
}
if ((tag & 7) === 4 || tag === 0) {
        break;
      }
reader.skipType(tag & 7);
}
return message;
},

// encodeTransform encodes a source of message objects.
    // Transform<UninterpretedOption, Uint8Array>
    async *encodeTransform(
      source: AsyncIterable<UninterpretedOption | UninterpretedOption[]> | Iterable<UninterpretedOption | UninterpretedOption[]>
    ): AsyncIterable<Uint8Array> {
      for await (const pkt of source) {
        if (globalThis.Array.isArray(pkt)) {
          for (const p of (pkt as any)) {
            yield* [UninterpretedOption.encode(p).finish()]
          }
        } else {
          yield* [UninterpretedOption.encode(pkt as any).finish()]
        }
      }
    },

// decodeTransform decodes a source of encoded messages.
    // Transform<Uint8Array, UninterpretedOption>
    async *decodeTransform(
      source: AsyncIterable<Uint8Array | Uint8Array[]> | Iterable<Uint8Array | Uint8Array[]>
    ): AsyncIterable<UninterpretedOption> {
      for await (const pkt of source) {
        if (globalThis.Array.isArray(pkt)) {
          for (const p of (pkt as any)) {
            yield* [UninterpretedOption.decode(p)]
          }
        } else {
          yield* [UninterpretedOption.decode(pkt as any)]
        }
      }
    },

fromJSON(object: any): UninterpretedOption {
      return {
name: globalThis.Array.isArray(object?.name) ? object.name.map((e: any) => UninterpretedOption_NamePart.fromJSON(e)): [],
identifier_value: isSet(object.identifier_value)
          ? globalThis.String(object.identifier_value)
          : "",
positive_int_value: isSet(object.positive_int_value)
          ? BigInt(object.positive_int_value)
          : BigInt("0"),
negative_int_value: isSet(object.negative_int_value)
          ? BigInt(object.negative_int_value)
          : BigInt("0"),
double_value: isSet(object.double_value)
          ? globalThis.Number(object.double_value)
          : 0,
string_value: isSet(object.string_value)
          ? Buffer.from(bytesFromBase64(object.string_value))
          : Buffer.alloc(0),
aggregate_value: isSet(object.aggregate_value)
          ? globalThis.String(object.aggregate_value)
          : "",
};
},

toJSON(message: UninterpretedOption): unknown {
      const obj: any = {};
if (message.name?.length) {
          obj.name = message.name.map(e => UninterpretedOption_NamePart.toJSON(e));
        }
if (message.identifier_value !== undefined  && message.identifier_value !== null && message.identifier_value !== "") {
          obj.identifier_value = message.identifier_value;
        }
if (message.positive_int_value !== undefined  && message.positive_int_value !== null && message.positive_int_value !== BigInt("0")) {
          obj.positive_int_value = message.positive_int_value.toString();
        }
if (message.negative_int_value !== undefined  && message.negative_int_value !== null && message.negative_int_value !== BigInt("0")) {
          obj.negative_int_value = message.negative_int_value.toString();
        }
if (message.double_value !== undefined  && message.double_value !== null && message.double_value !== 0) {
          obj.double_value = message.double_value;
        }
if (message.string_value !== undefined  && message.string_value !== null && message.string_value.length !== 0) {
          obj.string_value = base64FromBytes(message.string_value);
        }
if (message.aggregate_value !== undefined  && message.aggregate_value !== null && message.aggregate_value !== "") {
          obj.aggregate_value = message.aggregate_value;
        }
return obj;
},

create<I extends Exact<DeepPartial<UninterpretedOption>, I>>(base?: I): UninterpretedOption {
        return UninterpretedOption.fromPartial(base ?? ({} as any));
      },
fromPartial<I extends Exact<DeepPartial<UninterpretedOption>, I>>(object: I): UninterpretedOption {
const message = createBaseUninterpretedOption();
message.name = object.name?.map((e) => UninterpretedOption_NamePart.fromPartial(e)) || [];
message.identifier_value = object.identifier_value ?? "";
message.positive_int_value = object.positive_int_value ?? BigInt("0");
message.negative_int_value = object.negative_int_value ?? BigInt("0");
message.double_value = object.double_value ?? 0;
message.string_value = object.string_value ?? Buffer.alloc(0);
message.aggregate_value = object.aggregate_value ?? "";
return message;
}
            };

function createBaseUninterpretedOption_NamePart(): UninterpretedOption_NamePart {
      return { name_part: "",is_extension: false };
    }

export const UninterpretedOption_NamePart = {
              encode(
      message: UninterpretedOption_NamePart,
      writer: _m0.Writer = _m0.Writer.create(),
    ): _m0.Writer {
if ( message.name_part !== "") {
          writer.uint32(10).string(message.name_part);
        }
if ( message.is_extension !== false) {
          writer.uint32(16).bool(message.is_extension);
        }
return writer;
},

decode(
      input: _m0.Reader | Uint8Array,
      length?: number,
    ): UninterpretedOption_NamePart {
      const reader = input instanceof _m0.Reader ? input : _m0.Reader.create(input);
      let end = length === undefined ? reader.len : reader.pos + length;
const message = createBaseUninterpretedOption_NamePart();
while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
case 1:
if (tag !== 10) {
        break;
      }
    
        message.name_part = reader.string();
continue;
case 2:
if (tag !== 16) {
        break;
      }
    
        message.is_extension = reader.bool();
continue;
}
if ((tag & 7) === 4 || tag === 0) {
        break;
      }
reader.skipType(tag & 7);
}
return message;
},

// encodeTransform encodes a source of message objects.
    // Transform<UninterpretedOption_NamePart, Uint8Array>
    async *encodeTransform(
      source: AsyncIterable<UninterpretedOption_NamePart | UninterpretedOption_NamePart[]> | Iterable<UninterpretedOption_NamePart | UninterpretedOption_NamePart[]>
    ): AsyncIterable<Uint8Array> {
      for await (const pkt of source) {
        if (globalThis.Array.isArray(pkt)) {
          for (const p of (pkt as any)) {
            yield* [UninterpretedOption_NamePart.encode(p).finish()]
          }
        } else {
          yield* [UninterpretedOption_NamePart.encode(pkt as any).finish()]
        }
      }
    },

// decodeTransform decodes a source of encoded messages.
    // Transform<Uint8Array, UninterpretedOption_NamePart>
    async *decodeTransform(
      source: AsyncIterable<Uint8Array | Uint8Array[]> | Iterable<Uint8Array | Uint8Array[]>
    ): AsyncIterable<UninterpretedOption_NamePart> {
      for await (const pkt of source) {
        if (globalThis.Array.isArray(pkt)) {
          for (const p of (pkt as any)) {
            yield* [UninterpretedOption_NamePart.decode(p)]
          }
        } else {
          yield* [UninterpretedOption_NamePart.decode(pkt as any)]
        }
      }
    },

fromJSON(object: any): UninterpretedOption_NamePart {
      return {
name_part: isSet(object.name_part)
          ? globalThis.String(object.name_part)
          : "",
is_extension: isSet(object.is_extension)
          ? globalThis.Boolean(object.is_extension)
          : false,
};
},

toJSON(message: UninterpretedOption_NamePart): unknown {
      const obj: any = {};
if ( message.name_part !== "") {
          obj.name_part = message.name_part;
        }
if ( message.is_extension !== false) {
          obj.is_extension = message.is_extension;
        }
return obj;
},

create<I extends Exact<DeepPartial<UninterpretedOption_NamePart>, I>>(base?: I): UninterpretedOption_NamePart {
        return UninterpretedOption_NamePart.fromPartial(base ?? ({} as any));
      },
fromPartial<I extends Exact<DeepPartial<UninterpretedOption_NamePart>, I>>(object: I): UninterpretedOption_NamePart {
const message = createBaseUninterpretedOption_NamePart();
message.name_part = object.name_part ?? "";
message.is_extension = object.is_extension ?? false;
return message;
}
            };

function createBaseFeatureSet(): FeatureSet {
      return { field_presence: FeatureSet_FieldPresence.UNKNOWN,enum_type: FeatureSet_EnumType.UNKNOWN,repeated_field_encoding: FeatureSet_RepeatedFieldEncoding.UNKNOWN,utf8_validation: FeatureSet_Utf8Validation.UNKNOWN,message_encoding: FeatureSet_MessageEncoding.UNKNOWN,json_format: FeatureSet_JsonFormat.UNKNOWN };
    }

export const FeatureSet = {
              encode(
      message: FeatureSet,
      writer: _m0.Writer = _m0.Writer.create(),
    ): _m0.Writer {
if (message.field_presence !== undefined  && message.field_presence !== null && message.field_presence !== FeatureSet_FieldPresence.UNKNOWN) {
          writer.uint32(8).int32(featureSet_FieldPresenceToNumber(message.field_presence));
        }
if (message.enum_type !== undefined  && message.enum_type !== null && message.enum_type !== FeatureSet_EnumType.UNKNOWN) {
          writer.uint32(16).int32(featureSet_EnumTypeToNumber(message.enum_type));
        }
if (message.repeated_field_encoding !== undefined  && message.repeated_field_encoding !== null && message.repeated_field_encoding !== FeatureSet_RepeatedFieldEncoding.UNKNOWN) {
          writer.uint32(24).int32(featureSet_RepeatedFieldEncodingToNumber(message.repeated_field_encoding));
        }
if (message.utf8_validation !== undefined  && message.utf8_validation !== null && message.utf8_validation !== FeatureSet_Utf8Validation.UNKNOWN) {
          writer.uint32(32).int32(featureSet_Utf8ValidationToNumber(message.utf8_validation));
        }
if (message.message_encoding !== undefined  && message.message_encoding !== null && message.message_encoding !== FeatureSet_MessageEncoding.UNKNOWN) {
          writer.uint32(40).int32(featureSet_MessageEncodingToNumber(message.message_encoding));
        }
if (message.json_format !== undefined  && message.json_format !== null && message.json_format !== FeatureSet_JsonFormat.UNKNOWN) {
          writer.uint32(48).int32(featureSet_JsonFormatToNumber(message.json_format));
        }
return writer;
},

decode(
      input: _m0.Reader | Uint8Array,
      length?: number,
    ): FeatureSet {
      const reader = input instanceof _m0.Reader ? input : _m0.Reader.create(input);
      let end = length === undefined ? reader.len : reader.pos + length;
const message = createBaseFeatureSet();
while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
case 1:
if (tag !== 8) {
        break;
      }
    
        message.field_presence = featureSet_FieldPresenceFromJSON(reader.int32());
continue;
case 2:
if (tag !== 16) {
        break;
      }
    
        message.enum_type = featureSet_EnumTypeFromJSON(reader.int32());
continue;
case 3:
if (tag !== 24) {
        break;
      }
    
        message.repeated_field_encoding = featureSet_RepeatedFieldEncodingFromJSON(reader.int32());
continue;
case 4:
if (tag !== 32) {
        break;
      }
    
        message.utf8_validation = featureSet_Utf8ValidationFromJSON(reader.int32());
continue;
case 5:
if (tag !== 40) {
        break;
      }
    
        message.message_encoding = featureSet_MessageEncodingFromJSON(reader.int32());
continue;
case 6:
if (tag !== 48) {
        break;
      }
    
        message.json_format = featureSet_JsonFormatFromJSON(reader.int32());
continue;
}
if ((tag & 7) === 4 || tag === 0) {
        break;
      }
reader.skipType(tag & 7);
}
return message;
},

// encodeTransform encodes a source of message objects.
    // Transform<FeatureSet, Uint8Array>
    async *encodeTransform(
      source: AsyncIterable<FeatureSet | FeatureSet[]> | Iterable<FeatureSet | FeatureSet[]>
    ): AsyncIterable<Uint8Array> {
      for await (const pkt of source) {
        if (globalThis.Array.isArray(pkt)) {
          for (const p of (pkt as any)) {
            yield* [FeatureSet.encode(p).finish()]
          }
        } else {
          yield* [FeatureSet.encode(pkt as any).finish()]
        }
      }
    },

// decodeTransform decodes a source of encoded messages.
    // Transform<Uint8Array, FeatureSet>
    async *decodeTransform(
      source: AsyncIterable<Uint8Array | Uint8Array[]> | Iterable<Uint8Array | Uint8Array[]>
    ): AsyncIterable<FeatureSet> {
      for await (const pkt of source) {
        if (globalThis.Array.isArray(pkt)) {
          for (const p of (pkt as any)) {
            yield* [FeatureSet.decode(p)]
          }
        } else {
          yield* [FeatureSet.decode(pkt as any)]
        }
      }
    },

fromJSON(object: any): FeatureSet {
      return {
field_presence: isSet(object.field_presence)
          ? featureSet_FieldPresenceFromJSON(object.field_presence)
          : FeatureSet_FieldPresence.UNKNOWN,
enum_type: isSet(object.enum_type)
          ? featureSet_EnumTypeFromJSON(object.enum_type)
          : FeatureSet_EnumType.UNKNOWN,
repeated_field_encoding: isSet(object.repeated_field_encoding)
          ? featureSet_RepeatedFieldEncodingFromJSON(object.repeated_field_encoding)
          : FeatureSet_RepeatedFieldEncoding.UNKNOWN,
utf8_validation: isSet(object.utf8_validation)
          ? featureSet_Utf8ValidationFromJSON(object.utf8_validation)
          : FeatureSet_Utf8Validation.UNKNOWN,
message_encoding: isSet(object.message_encoding)
          ? featureSet_MessageEncodingFromJSON(object.message_encoding)
          : FeatureSet_MessageEncoding.UNKNOWN,
json_format: isSet(object.json_format)
          ? featureSet_JsonFormatFromJSON(object.json_format)
          : FeatureSet_JsonFormat.UNKNOWN,
};
},

toJSON(message: FeatureSet): unknown {
      const obj: any = {};
if (message.field_presence !== undefined  && message.field_presence !== null && message.field_presence !== FeatureSet_FieldPresence.UNKNOWN) {
          obj.field_presence = featureSet_FieldPresenceToJSON(message.field_presence);
        }
if (message.enum_type !== undefined  && message.enum_type !== null && message.enum_type !== FeatureSet_EnumType.UNKNOWN) {
          obj.enum_type = featureSet_EnumTypeToJSON(message.enum_type);
        }
if (message.repeated_field_encoding !== undefined  && message.repeated_field_encoding !== null && message.repeated_field_encoding !== FeatureSet_RepeatedFieldEncoding.UNKNOWN) {
          obj.repeated_field_encoding = featureSet_RepeatedFieldEncodingToJSON(message.repeated_field_encoding);
        }
if (message.utf8_validation !== undefined  && message.utf8_validation !== null && message.utf8_validation !== FeatureSet_Utf8Validation.UNKNOWN) {
          obj.utf8_validation = featureSet_Utf8ValidationToJSON(message.utf8_validation);
        }
if (message.message_encoding !== undefined  && message.message_encoding !== null && message.message_encoding !== FeatureSet_MessageEncoding.UNKNOWN) {
          obj.message_encoding = featureSet_MessageEncodingToJSON(message.message_encoding);
        }
if (message.json_format !== undefined  && message.json_format !== null && message.json_format !== FeatureSet_JsonFormat.UNKNOWN) {
          obj.json_format = featureSet_JsonFormatToJSON(message.json_format);
        }
return obj;
},

create<I extends Exact<DeepPartial<FeatureSet>, I>>(base?: I): FeatureSet {
        return FeatureSet.fromPartial(base ?? ({} as any));
      },
fromPartial<I extends Exact<DeepPartial<FeatureSet>, I>>(object: I): FeatureSet {
const message = createBaseFeatureSet();
message.field_presence = object.field_presence ?? FeatureSet_FieldPresence.UNKNOWN;
message.enum_type = object.enum_type ?? FeatureSet_EnumType.UNKNOWN;
message.repeated_field_encoding = object.repeated_field_encoding ?? FeatureSet_RepeatedFieldEncoding.UNKNOWN;
message.utf8_validation = object.utf8_validation ?? FeatureSet_Utf8Validation.UNKNOWN;
message.message_encoding = object.message_encoding ?? FeatureSet_MessageEncoding.UNKNOWN;
message.json_format = object.json_format ?? FeatureSet_JsonFormat.UNKNOWN;
return message;
}
            };

function createBaseFeatureSetDefaults(): FeatureSetDefaults {
      return { defaults: [],minimum_edition: Edition.UNKNOWN,maximum_edition: Edition.UNKNOWN };
    }

export const FeatureSetDefaults = {
              encode(
      message: FeatureSetDefaults,
      writer: _m0.Writer = _m0.Writer.create(),
    ): _m0.Writer {
for (const v of message.defaults) {
            FeatureSetDefaults_FeatureSetEditionDefault.encode(v!, writer.uint32(10).fork()).ldelim();
          }
if (message.minimum_edition !== undefined  && message.minimum_edition !== null && message.minimum_edition !== Edition.UNKNOWN) {
          writer.uint32(32).int32(editionToNumber(message.minimum_edition));
        }
if (message.maximum_edition !== undefined  && message.maximum_edition !== null && message.maximum_edition !== Edition.UNKNOWN) {
          writer.uint32(40).int32(editionToNumber(message.maximum_edition));
        }
return writer;
},

decode(
      input: _m0.Reader | Uint8Array,
      length?: number,
    ): FeatureSetDefaults {
      const reader = input instanceof _m0.Reader ? input : _m0.Reader.create(input);
      let end = length === undefined ? reader.len : reader.pos + length;
const message = createBaseFeatureSetDefaults();
while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
case 1:
if (tag !== 10) {
        break;
      }
    
            
            message.defaults.push(FeatureSetDefaults_FeatureSetEditionDefault.decode(reader, reader.uint32()));
continue;
case 4:
if (tag !== 32) {
        break;
      }
    
        message.minimum_edition = editionFromJSON(reader.int32());
continue;
case 5:
if (tag !== 40) {
        break;
      }
    
        message.maximum_edition = editionFromJSON(reader.int32());
continue;
}
if ((tag & 7) === 4 || tag === 0) {
        break;
      }
reader.skipType(tag & 7);
}
return message;
},

// encodeTransform encodes a source of message objects.
    // Transform<FeatureSetDefaults, Uint8Array>
    async *encodeTransform(
      source: AsyncIterable<FeatureSetDefaults | FeatureSetDefaults[]> | Iterable<FeatureSetDefaults | FeatureSetDefaults[]>
    ): AsyncIterable<Uint8Array> {
      for await (const pkt of source) {
        if (globalThis.Array.isArray(pkt)) {
          for (const p of (pkt as any)) {
            yield* [FeatureSetDefaults.encode(p).finish()]
          }
        } else {
          yield* [FeatureSetDefaults.encode(pkt as any).finish()]
        }
      }
    },

// decodeTransform decodes a source of encoded messages.
    // Transform<Uint8Array, FeatureSetDefaults>
    async *decodeTransform(
      source: AsyncIterable<Uint8Array | Uint8Array[]> | Iterable<Uint8Array | Uint8Array[]>
    ): AsyncIterable<FeatureSetDefaults> {
      for await (const pkt of source) {
        if (globalThis.Array.isArray(pkt)) {
          for (const p of (pkt as any)) {
            yield* [FeatureSetDefaults.decode(p)]
          }
        } else {
          yield* [FeatureSetDefaults.decode(pkt as any)]
        }
      }
    },

fromJSON(object: any): FeatureSetDefaults {
      return {
defaults: globalThis.Array.isArray(object?.defaults) ? object.defaults.map((e: any) => FeatureSetDefaults_FeatureSetEditionDefault.fromJSON(e)): [],
minimum_edition: isSet(object.minimum_edition)
          ? editionFromJSON(object.minimum_edition)
          : Edition.UNKNOWN,
maximum_edition: isSet(object.maximum_edition)
          ? editionFromJSON(object.maximum_edition)
          : Edition.UNKNOWN,
};
},

toJSON(message: FeatureSetDefaults): unknown {
      const obj: any = {};
if (message.defaults?.length) {
          obj.defaults = message.defaults.map(e => FeatureSetDefaults_FeatureSetEditionDefault.toJSON(e));
        }
if (message.minimum_edition !== undefined  && message.minimum_edition !== null && message.minimum_edition !== Edition.UNKNOWN) {
          obj.minimum_edition = editionToJSON(message.minimum_edition);
        }
if (message.maximum_edition !== undefined  && message.maximum_edition !== null && message.maximum_edition !== Edition.UNKNOWN) {
          obj.maximum_edition = editionToJSON(message.maximum_edition);
        }
return obj;
},

create<I extends Exact<DeepPartial<FeatureSetDefaults>, I>>(base?: I): FeatureSetDefaults {
        return FeatureSetDefaults.fromPartial(base ?? ({} as any));
      },
fromPartial<I extends Exact<DeepPartial<FeatureSetDefaults>, I>>(object: I): FeatureSetDefaults {
const message = createBaseFeatureSetDefaults();
message.defaults = object.defaults?.map((e) => FeatureSetDefaults_FeatureSetEditionDefault.fromPartial(e)) || [];
message.minimum_edition = object.minimum_edition ?? Edition.UNKNOWN;
message.maximum_edition = object.maximum_edition ?? Edition.UNKNOWN;
return message;
}
            };

function createBaseFeatureSetDefaults_FeatureSetEditionDefault(): FeatureSetDefaults_FeatureSetEditionDefault {
      return { edition: Edition.UNKNOWN,overridable_features: null,fixed_features: null };
    }

export const FeatureSetDefaults_FeatureSetEditionDefault = {
              encode(
      message: FeatureSetDefaults_FeatureSetEditionDefault,
      writer: _m0.Writer = _m0.Writer.create(),
    ): _m0.Writer {
if (message.edition !== undefined  && message.edition !== null && message.edition !== Edition.UNKNOWN) {
          writer.uint32(24).int32(editionToNumber(message.edition));
        }
if (message.overridable_features !== undefined  && message.overridable_features !== null) {
          FeatureSet.encode(message.overridable_features, writer.uint32(34).fork()).ldelim();
        }
if (message.fixed_features !== undefined  && message.fixed_features !== null) {
          FeatureSet.encode(message.fixed_features, writer.uint32(42).fork()).ldelim();
        }
return writer;
},

decode(
      input: _m0.Reader | Uint8Array,
      length?: number,
    ): FeatureSetDefaults_FeatureSetEditionDefault {
      const reader = input instanceof _m0.Reader ? input : _m0.Reader.create(input);
      let end = length === undefined ? reader.len : reader.pos + length;
const message = createBaseFeatureSetDefaults_FeatureSetEditionDefault();
while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
case 3:
if (tag !== 24) {
        break;
      }
    
        message.edition = editionFromJSON(reader.int32());
continue;
case 4:
if (tag !== 34) {
        break;
      }
    
        message.overridable_features = FeatureSet.decode(reader, reader.uint32());
continue;
case 5:
if (tag !== 42) {
        break;
      }
    
        message.fixed_features = FeatureSet.decode(reader, reader.uint32());
continue;
}
if ((tag & 7) === 4 || tag === 0) {
        break;
      }
reader.skipType(tag & 7);
}
return message;
},

// encodeTransform encodes a source of message objects.
    // Transform<FeatureSetDefaults_FeatureSetEditionDefault, Uint8Array>
    async *encodeTransform(
      source: AsyncIterable<FeatureSetDefaults_FeatureSetEditionDefault | FeatureSetDefaults_FeatureSetEditionDefault[]> | Iterable<FeatureSetDefaults_FeatureSetEditionDefault | FeatureSetDefaults_FeatureSetEditionDefault[]>
    ): AsyncIterable<Uint8Array> {
      for await (const pkt of source) {
        if (globalThis.Array.isArray(pkt)) {
          for (const p of (pkt as any)) {
            yield* [FeatureSetDefaults_FeatureSetEditionDefault.encode(p).finish()]
          }
        } else {
          yield* [FeatureSetDefaults_FeatureSetEditionDefault.encode(pkt as any).finish()]
        }
      }
    },

// decodeTransform decodes a source of encoded messages.
    // Transform<Uint8Array, FeatureSetDefaults_FeatureSetEditionDefault>
    async *decodeTransform(
      source: AsyncIterable<Uint8Array | Uint8Array[]> | Iterable<Uint8Array | Uint8Array[]>
    ): AsyncIterable<FeatureSetDefaults_FeatureSetEditionDefault> {
      for await (const pkt of source) {
        if (globalThis.Array.isArray(pkt)) {
          for (const p of (pkt as any)) {
            yield* [FeatureSetDefaults_FeatureSetEditionDefault.decode(p)]
          }
        } else {
          yield* [FeatureSetDefaults_FeatureSetEditionDefault.decode(pkt as any)]
        }
      }
    },

fromJSON(object: any): FeatureSetDefaults_FeatureSetEditionDefault {
      return {
edition: isSet(object.edition)
          ? editionFromJSON(object.edition)
          : Edition.UNKNOWN,
overridable_features: isSet(object.overridable_features)
          ? FeatureSet.fromJSON(object.overridable_features)
          : null ,
fixed_features: isSet(object.fixed_features)
          ? FeatureSet.fromJSON(object.fixed_features)
          : null ,
};
},

toJSON(message: FeatureSetDefaults_FeatureSetEditionDefault): unknown {
      const obj: any = {};
if (message.edition !== undefined  && message.edition !== null && message.edition !== Edition.UNKNOWN) {
          obj.edition = editionToJSON(message.edition);
        }
if (message.overridable_features !== undefined  && message.overridable_features !== null) {
          obj.overridable_features = FeatureSet.toJSON(message.overridable_features);
        }
if (message.fixed_features !== undefined  && message.fixed_features !== null) {
          obj.fixed_features = FeatureSet.toJSON(message.fixed_features);
        }
return obj;
},

create<I extends Exact<DeepPartial<FeatureSetDefaults_FeatureSetEditionDefault>, I>>(base?: I): FeatureSetDefaults_FeatureSetEditionDefault {
        return FeatureSetDefaults_FeatureSetEditionDefault.fromPartial(base ?? ({} as any));
      },
fromPartial<I extends Exact<DeepPartial<FeatureSetDefaults_FeatureSetEditionDefault>, I>>(object: I): FeatureSetDefaults_FeatureSetEditionDefault {
const message = createBaseFeatureSetDefaults_FeatureSetEditionDefault();
message.edition = object.edition ?? Edition.UNKNOWN;
message.overridable_features = (object.overridable_features !== undefined && object.overridable_features !== null)
          ? FeatureSet.fromPartial(object.overridable_features)
          : null ;
message.fixed_features = (object.fixed_features !== undefined && object.fixed_features !== null)
          ? FeatureSet.fromPartial(object.fixed_features)
          : null ;
return message;
}
            };

function createBaseSourceCodeInfo(): SourceCodeInfo {
      return { location: [] };
    }

export const SourceCodeInfo = {
              encode(
      message: SourceCodeInfo,
      writer: _m0.Writer = _m0.Writer.create(),
    ): _m0.Writer {
for (const v of message.location) {
            SourceCodeInfo_Location.encode(v!, writer.uint32(10).fork()).ldelim();
          }
return writer;
},

decode(
      input: _m0.Reader | Uint8Array,
      length?: number,
    ): SourceCodeInfo {
      const reader = input instanceof _m0.Reader ? input : _m0.Reader.create(input);
      let end = length === undefined ? reader.len : reader.pos + length;
const message = createBaseSourceCodeInfo();
while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
case 1:
if (tag !== 10) {
        break;
      }
    
            
            message.location.push(SourceCodeInfo_Location.decode(reader, reader.uint32()));
continue;
}
if ((tag & 7) === 4 || tag === 0) {
        break;
      }
reader.skipType(tag & 7);
}
return message;
},

// encodeTransform encodes a source of message objects.
    // Transform<SourceCodeInfo, Uint8Array>
    async *encodeTransform(
      source: AsyncIterable<SourceCodeInfo | SourceCodeInfo[]> | Iterable<SourceCodeInfo | SourceCodeInfo[]>
    ): AsyncIterable<Uint8Array> {
      for await (const pkt of source) {
        if (globalThis.Array.isArray(pkt)) {
          for (const p of (pkt as any)) {
            yield* [SourceCodeInfo.encode(p).finish()]
          }
        } else {
          yield* [SourceCodeInfo.encode(pkt as any).finish()]
        }
      }
    },

// decodeTransform decodes a source of encoded messages.
    // Transform<Uint8Array, SourceCodeInfo>
    async *decodeTransform(
      source: AsyncIterable<Uint8Array | Uint8Array[]> | Iterable<Uint8Array | Uint8Array[]>
    ): AsyncIterable<SourceCodeInfo> {
      for await (const pkt of source) {
        if (globalThis.Array.isArray(pkt)) {
          for (const p of (pkt as any)) {
            yield* [SourceCodeInfo.decode(p)]
          }
        } else {
          yield* [SourceCodeInfo.decode(pkt as any)]
        }
      }
    },

fromJSON(object: any): SourceCodeInfo {
      return {
location: globalThis.Array.isArray(object?.location) ? object.location.map((e: any) => SourceCodeInfo_Location.fromJSON(e)): [],
};
},

toJSON(message: SourceCodeInfo): unknown {
      const obj: any = {};
if (message.location?.length) {
          obj.location = message.location.map(e => SourceCodeInfo_Location.toJSON(e));
        }
return obj;
},

create<I extends Exact<DeepPartial<SourceCodeInfo>, I>>(base?: I): SourceCodeInfo {
        return SourceCodeInfo.fromPartial(base ?? ({} as any));
      },
fromPartial<I extends Exact<DeepPartial<SourceCodeInfo>, I>>(object: I): SourceCodeInfo {
const message = createBaseSourceCodeInfo();
message.location = object.location?.map((e) => SourceCodeInfo_Location.fromPartial(e)) || [];
return message;
}
            };

function createBaseSourceCodeInfo_Location(): SourceCodeInfo_Location {
      return { path: [],span: [],leading_comments: "",trailing_comments: "",leading_detached_comments: [] };
    }

export const SourceCodeInfo_Location = {
              encode(
      message: SourceCodeInfo_Location,
      writer: _m0.Writer = _m0.Writer.create(),
    ): _m0.Writer {
writer.uint32(10).fork();
          for (const v of message.path) {
            writer.int32(v);
          }
          writer.ldelim();
writer.uint32(18).fork();
          for (const v of message.span) {
            writer.int32(v);
          }
          writer.ldelim();
if (message.leading_comments !== undefined  && message.leading_comments !== null && message.leading_comments !== "") {
          writer.uint32(26).string(message.leading_comments);
        }
if (message.trailing_comments !== undefined  && message.trailing_comments !== null && message.trailing_comments !== "") {
          writer.uint32(34).string(message.trailing_comments);
        }
for (const v of message.leading_detached_comments) {
            writer.uint32(50).string(v!);
          }
return writer;
},

decode(
      input: _m0.Reader | Uint8Array,
      length?: number,
    ): SourceCodeInfo_Location {
      const reader = input instanceof _m0.Reader ? input : _m0.Reader.create(input);
      let end = length === undefined ? reader.len : reader.pos + length;
const message = createBaseSourceCodeInfo_Location();
while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
case 1:
if (tag === 8) {
              
              message.path.push(reader.int32());

              continue;
            }

            if (tag === 10) {
              
              const end2 = reader.uint32() + reader.pos;
              while (reader.pos < end2) {
                message.path.push(reader.int32());
              }

              continue;
            }

            break;
case 2:
if (tag === 16) {
              
              message.span.push(reader.int32());

              continue;
            }

            if (tag === 18) {
              
              const end2 = reader.uint32() + reader.pos;
              while (reader.pos < end2) {
                message.span.push(reader.int32());
              }

              continue;
            }

            break;
case 3:
if (tag !== 26) {
        break;
      }
    
        message.leading_comments = reader.string();
continue;
case 4:
if (tag !== 34) {
        break;
      }
    
        message.trailing_comments = reader.string();
continue;
case 6:
if (tag !== 50) {
        break;
      }
    
            
            message.leading_detached_comments.push(reader.string());
continue;
}
if ((tag & 7) === 4 || tag === 0) {
        break;
      }
reader.skipType(tag & 7);
}
return message;
},

// encodeTransform encodes a source of message objects.
    // Transform<SourceCodeInfo_Location, Uint8Array>
    async *encodeTransform(
      source: AsyncIterable<SourceCodeInfo_Location | SourceCodeInfo_Location[]> | Iterable<SourceCodeInfo_Location | SourceCodeInfo_Location[]>
    ): AsyncIterable<Uint8Array> {
      for await (const pkt of source) {
        if (globalThis.Array.isArray(pkt)) {
          for (const p of (pkt as any)) {
            yield* [SourceCodeInfo_Location.encode(p).finish()]
          }
        } else {
          yield* [SourceCodeInfo_Location.encode(pkt as any).finish()]
        }
      }
    },

// decodeTransform decodes a source of encoded messages.
    // Transform<Uint8Array, SourceCodeInfo_Location>
    async *decodeTransform(
      source: AsyncIterable<Uint8Array | Uint8Array[]> | Iterable<Uint8Array | Uint8Array[]>
    ): AsyncIterable<SourceCodeInfo_Location> {
      for await (const pkt of source) {
        if (globalThis.Array.isArray(pkt)) {
          for (const p of (pkt as any)) {
            yield* [SourceCodeInfo_Location.decode(p)]
          }
        } else {
          yield* [SourceCodeInfo_Location.decode(pkt as any)]
        }
      }
    },

fromJSON(object: any): SourceCodeInfo_Location {
      return {
path: globalThis.Array.isArray(object?.path) ? object.path.map((e: any) => globalThis.Number(e)): [],
span: globalThis.Array.isArray(object?.span) ? object.span.map((e: any) => globalThis.Number(e)): [],
leading_comments: isSet(object.leading_comments)
          ? globalThis.String(object.leading_comments)
          : "",
trailing_comments: isSet(object.trailing_comments)
          ? globalThis.String(object.trailing_comments)
          : "",
leading_detached_comments: globalThis.Array.isArray(object?.leading_detached_comments) ? object.leading_detached_comments.map((e: any) => globalThis.String(e)): [],
};
},

toJSON(message: SourceCodeInfo_Location): unknown {
      const obj: any = {};
if (message.path?.length) {
          obj.path = message.path.map(e => Math.round(e));
        }
if (message.span?.length) {
          obj.span = message.span.map(e => Math.round(e));
        }
if (message.leading_comments !== undefined  && message.leading_comments !== null && message.leading_comments !== "") {
          obj.leading_comments = message.leading_comments;
        }
if (message.trailing_comments !== undefined  && message.trailing_comments !== null && message.trailing_comments !== "") {
          obj.trailing_comments = message.trailing_comments;
        }
if (message.leading_detached_comments?.length) {
          obj.leading_detached_comments = message.leading_detached_comments;
        }
return obj;
},

create<I extends Exact<DeepPartial<SourceCodeInfo_Location>, I>>(base?: I): SourceCodeInfo_Location {
        return SourceCodeInfo_Location.fromPartial(base ?? ({} as any));
      },
fromPartial<I extends Exact<DeepPartial<SourceCodeInfo_Location>, I>>(object: I): SourceCodeInfo_Location {
const message = createBaseSourceCodeInfo_Location();
message.path = object.path?.map((e) => e) || [];
message.span = object.span?.map((e) => e) || [];
message.leading_comments = object.leading_comments ?? "";
message.trailing_comments = object.trailing_comments ?? "";
message.leading_detached_comments = object.leading_detached_comments?.map((e) => e) || [];
return message;
}
            };

function createBaseGeneratedCodeInfo(): GeneratedCodeInfo {
      return { annotation: [] };
    }

export const GeneratedCodeInfo = {
              encode(
      message: GeneratedCodeInfo,
      writer: _m0.Writer = _m0.Writer.create(),
    ): _m0.Writer {
for (const v of message.annotation) {
            GeneratedCodeInfo_Annotation.encode(v!, writer.uint32(10).fork()).ldelim();
          }
return writer;
},

decode(
      input: _m0.Reader | Uint8Array,
      length?: number,
    ): GeneratedCodeInfo {
      const reader = input instanceof _m0.Reader ? input : _m0.Reader.create(input);
      let end = length === undefined ? reader.len : reader.pos + length;
const message = createBaseGeneratedCodeInfo();
while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
case 1:
if (tag !== 10) {
        break;
      }
    
            
            message.annotation.push(GeneratedCodeInfo_Annotation.decode(reader, reader.uint32()));
continue;
}
if ((tag & 7) === 4 || tag === 0) {
        break;
      }
reader.skipType(tag & 7);
}
return message;
},

// encodeTransform encodes a source of message objects.
    // Transform<GeneratedCodeInfo, Uint8Array>
    async *encodeTransform(
      source: AsyncIterable<GeneratedCodeInfo | GeneratedCodeInfo[]> | Iterable<GeneratedCodeInfo | GeneratedCodeInfo[]>
    ): AsyncIterable<Uint8Array> {
      for await (const pkt of source) {
        if (globalThis.Array.isArray(pkt)) {
          for (const p of (pkt as any)) {
            yield* [GeneratedCodeInfo.encode(p).finish()]
          }
        } else {
          yield* [GeneratedCodeInfo.encode(pkt as any).finish()]
        }
      }
    },

// decodeTransform decodes a source of encoded messages.
    // Transform<Uint8Array, GeneratedCodeInfo>
    async *decodeTransform(
      source: AsyncIterable<Uint8Array | Uint8Array[]> | Iterable<Uint8Array | Uint8Array[]>
    ): AsyncIterable<GeneratedCodeInfo> {
      for await (const pkt of source) {
        if (globalThis.Array.isArray(pkt)) {
          for (const p of (pkt as any)) {
            yield* [GeneratedCodeInfo.decode(p)]
          }
        } else {
          yield* [GeneratedCodeInfo.decode(pkt as any)]
        }
      }
    },

fromJSON(object: any): GeneratedCodeInfo {
      return {
annotation: globalThis.Array.isArray(object?.annotation) ? object.annotation.map((e: any) => GeneratedCodeInfo_Annotation.fromJSON(e)): [],
};
},

toJSON(message: GeneratedCodeInfo): unknown {
      const obj: any = {};
if (message.annotation?.length) {
          obj.annotation = message.annotation.map(e => GeneratedCodeInfo_Annotation.toJSON(e));
        }
return obj;
},

create<I extends Exact<DeepPartial<GeneratedCodeInfo>, I>>(base?: I): GeneratedCodeInfo {
        return GeneratedCodeInfo.fromPartial(base ?? ({} as any));
      },
fromPartial<I extends Exact<DeepPartial<GeneratedCodeInfo>, I>>(object: I): GeneratedCodeInfo {
const message = createBaseGeneratedCodeInfo();
message.annotation = object.annotation?.map((e) => GeneratedCodeInfo_Annotation.fromPartial(e)) || [];
return message;
}
            };

function createBaseGeneratedCodeInfo_Annotation(): GeneratedCodeInfo_Annotation {
      return { path: [],source_file: "",begin: 0,end: 0,semantic: GeneratedCodeInfo_Annotation_Semantic.NONE };
    }

export const GeneratedCodeInfo_Annotation = {
              encode(
      message: GeneratedCodeInfo_Annotation,
      writer: _m0.Writer = _m0.Writer.create(),
    ): _m0.Writer {
writer.uint32(10).fork();
          for (const v of message.path) {
            writer.int32(v);
          }
          writer.ldelim();
if (message.source_file !== undefined  && message.source_file !== null && message.source_file !== "") {
          writer.uint32(18).string(message.source_file);
        }
if (message.begin !== undefined  && message.begin !== null && message.begin !== 0) {
          writer.uint32(24).int32(message.begin);
        }
if (message.end !== undefined  && message.end !== null && message.end !== 0) {
          writer.uint32(32).int32(message.end);
        }
if (message.semantic !== undefined  && message.semantic !== null && message.semantic !== GeneratedCodeInfo_Annotation_Semantic.NONE) {
          writer.uint32(40).int32(generatedCodeInfo_Annotation_SemanticToNumber(message.semantic));
        }
return writer;
},

decode(
      input: _m0.Reader | Uint8Array,
      length?: number,
    ): GeneratedCodeInfo_Annotation {
      const reader = input instanceof _m0.Reader ? input : _m0.Reader.create(input);
      let end = length === undefined ? reader.len : reader.pos + length;
const message = createBaseGeneratedCodeInfo_Annotation();
while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
case 1:
if (tag === 8) {
              
              message.path.push(reader.int32());

              continue;
            }

            if (tag === 10) {
              
              const end2 = reader.uint32() + reader.pos;
              while (reader.pos < end2) {
                message.path.push(reader.int32());
              }

              continue;
            }

            break;
case 2:
if (tag !== 18) {
        break;
      }
    
        message.source_file = reader.string();
continue;
case 3:
if (tag !== 24) {
        break;
      }
    
        message.begin = reader.int32();
continue;
case 4:
if (tag !== 32) {
        break;
      }
    
        message.end = reader.int32();
continue;
case 5:
if (tag !== 40) {
        break;
      }
    
        message.semantic = generatedCodeInfo_Annotation_SemanticFromJSON(reader.int32());
continue;
}
if ((tag & 7) === 4 || tag === 0) {
        break;
      }
reader.skipType(tag & 7);
}
return message;
},

// encodeTransform encodes a source of message objects.
    // Transform<GeneratedCodeInfo_Annotation, Uint8Array>
    async *encodeTransform(
      source: AsyncIterable<GeneratedCodeInfo_Annotation | GeneratedCodeInfo_Annotation[]> | Iterable<GeneratedCodeInfo_Annotation | GeneratedCodeInfo_Annotation[]>
    ): AsyncIterable<Uint8Array> {
      for await (const pkt of source) {
        if (globalThis.Array.isArray(pkt)) {
          for (const p of (pkt as any)) {
            yield* [GeneratedCodeInfo_Annotation.encode(p).finish()]
          }
        } else {
          yield* [GeneratedCodeInfo_Annotation.encode(pkt as any).finish()]
        }
      }
    },

// decodeTransform decodes a source of encoded messages.
    // Transform<Uint8Array, GeneratedCodeInfo_Annotation>
    async *decodeTransform(
      source: AsyncIterable<Uint8Array | Uint8Array[]> | Iterable<Uint8Array | Uint8Array[]>
    ): AsyncIterable<GeneratedCodeInfo_Annotation> {
      for await (const pkt of source) {
        if (globalThis.Array.isArray(pkt)) {
          for (const p of (pkt as any)) {
            yield* [GeneratedCodeInfo_Annotation.decode(p)]
          }
        } else {
          yield* [GeneratedCodeInfo_Annotation.decode(pkt as any)]
        }
      }
    },

fromJSON(object: any): GeneratedCodeInfo_Annotation {
      return {
path: globalThis.Array.isArray(object?.path) ? object.path.map((e: any) => globalThis.Number(e)): [],
source_file: isSet(object.source_file)
          ? globalThis.String(object.source_file)
          : "",
begin: isSet(object.begin)
          ? globalThis.Number(object.begin)
          : 0,
end: isSet(object.end)
          ? globalThis.Number(object.end)
          : 0,
semantic: isSet(object.semantic)
          ? generatedCodeInfo_Annotation_SemanticFromJSON(object.semantic)
          : GeneratedCodeInfo_Annotation_Semantic.NONE,
};
},

toJSON(message: GeneratedCodeInfo_Annotation): unknown {
      const obj: any = {};
if (message.path?.length) {
          obj.path = message.path.map(e => Math.round(e));
        }
if (message.source_file !== undefined  && message.source_file !== null && message.source_file !== "") {
          obj.source_file = message.source_file;
        }
if (message.begin !== undefined  && message.begin !== null && message.begin !== 0) {
          obj.begin = Math.round(message.begin);
        }
if (message.end !== undefined  && message.end !== null && message.end !== 0) {
          obj.end = Math.round(message.end);
        }
if (message.semantic !== undefined  && message.semantic !== null && message.semantic !== GeneratedCodeInfo_Annotation_Semantic.NONE) {
          obj.semantic = generatedCodeInfo_Annotation_SemanticToJSON(message.semantic);
        }
return obj;
},

create<I extends Exact<DeepPartial<GeneratedCodeInfo_Annotation>, I>>(base?: I): GeneratedCodeInfo_Annotation {
        return GeneratedCodeInfo_Annotation.fromPartial(base ?? ({} as any));
      },
fromPartial<I extends Exact<DeepPartial<GeneratedCodeInfo_Annotation>, I>>(object: I): GeneratedCodeInfo_Annotation {
const message = createBaseGeneratedCodeInfo_Annotation();
message.path = object.path?.map((e) => e) || [];
message.source_file = object.source_file ?? "";
message.begin = object.begin ?? 0;
message.end = object.end ?? 0;
message.semantic = object.semantic ?? GeneratedCodeInfo_Annotation_Semantic.NONE;
return message;
}
            };

export interface DataLoaderOptions {
      cache?: boolean;
    }

export interface DataLoaders {
      rpcDataLoaderOptions?: DataLoaderOptions;
      getDataLoader<T>(identifier: string, constructorFn: () => T): T;
    }



function bytesFromBase64(b64: string): Uint8Array {
        
      return Uint8Array.from(globalThis.Buffer.from(b64, 'base64'));
    
      }

function base64FromBytes(arr: Uint8Array): string {
        
      return globalThis.Buffer.from(arr).toString('base64');
    
      }

type Builtin = Date | Function | Uint8Array | string | number | boolean | bigint | undefined;

export type DeepPartial<T> =  T extends Builtin
        ? T
        
        : T extends globalThis.Array<infer U>
        ? globalThis.Array<DeepPartial<U>>
        : T extends ReadonlyArray<infer U>
        ? ReadonlyArray<DeepPartial<U>>
      : T extends { $case: string }
      ? { [K in keyof Omit<T, '$case'>]?: DeepPartial<T[K]> } & { $case: T['$case'] }
    
        : T extends {}
        ? { [K in keyof T]?: DeepPartial<T[K]> }
        : Partial<T>;

type KeysOfUnion<T> = T extends T ? keyof T : never;
      export type Exact<P, I extends P> = P extends Builtin
        ? P
        : P &
        { [K in keyof P]: Exact<P[K], I[K]> } & { [K in Exclude<keyof I, KeysOfUnion<P> >]: never };



















function longToBigint(long: Long) {
        return BigInt(long.toString());
      }

if (_m0.util.Long !== Long) {
        _m0.util.Long = Long as any;
        _m0.configure();
      }



function isSet(value: any): boolean {
      return value !== null && value !== undefined;
    }







